+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD b34751b7ed02b2cfcc36037fb729d4360480a299
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit b34751b7ed02b2cfcc36037fb729d4360480a299
Author: Guillaume Lemaitre <g.lemaitre58@gmail.com>
Date:   Mon May 6 09:41:46 2019 +0200

    [MRG] MAINT: add fixture for init and clean-up with matplotlib (#13708)

diff --git a/azure-pipelines.yml b/azure-pipelines.yml
index ae27828dd2..c31385dd3e 100644
--- a/azure-pipelines.yml
+++ b/azure-pipelines.yml
@@ -22,6 +22,7 @@ jobs:
         SCIPY_VERSION: '0.17.0'
         CYTHON_VERSION: '*'
         PILLOW_VERSION: '4.0.0'
+        MATPLOTLIB_VERSION: '1.5.1'
         # later version of joblib are not packaged in conda for Python 3.5
         JOBLIB_VERSION: '0.12.3'
         COVERAGE: 'true'
diff --git a/build_tools/azure/install.cmd b/build_tools/azure/install.cmd
index 97f5cb4f7e..a53cd61b34 100644
--- a/build_tools/azure/install.cmd
+++ b/build_tools/azure/install.cmd
@@ -11,7 +11,7 @@ IF "%PYTHON_ARCH%"=="64" (
     call deactivate
     @rem Clean up any left-over from a previous build
     conda remove --all -q -y -n %VIRTUALENV%
-    conda create -n %VIRTUALENV% -q -y python=%PYTHON_VERSION% numpy scipy cython pytest wheel pillow joblib
+    conda create -n %VIRTUALENV% -q -y python=%PYTHON_VERSION% numpy scipy cython matplotlib pytest wheel pillow joblib
 
     call activate %VIRTUALENV%
 ) else (
diff --git a/doc/developers/contributing.rst b/doc/developers/contributing.rst
index 45ca89a801..69e7f0b2b4 100644
--- a/doc/developers/contributing.rst
+++ b/doc/developers/contributing.rst
@@ -626,7 +626,7 @@ reviewing pull requests, you may find :ref:`this tip
 .. _testing_coverage:
 
 Testing and improving test coverage
-------------------------------------
+-----------------------------------
 
 High-quality `unit testing <https://en.wikipedia.org/wiki/Unit_testing>`_
 is a corner-stone of the scikit-learn development process. For this
@@ -641,22 +641,42 @@ the corresponding subpackages.
 
 We expect code coverage of new features to be at least around 90%.
 
-.. note:: **Workflow to improve test coverage**
+For guidelines on how to use ``pytest`` efficiently, see the
+:ref:`pytest_tips`.
 
-   To test code coverage, you need to install the `coverage
-   <https://pypi.org/project/coverage/>`_ package in addition to pytest.
+Writing matplotlib related tests
+................................
 
-   1. Run 'make test-coverage'. The output lists for each file the line
-      numbers that are not tested.
+Test fixtures ensure that a set of tests will be executing with the appropriate
+initialization and cleanup. The scikit-learn test suite implements a fixture
+which can be used with ``matplotlib``.
 
-   2. Find a low hanging fruit, looking at which lines are not tested,
-      write or adapt a test specifically for these lines.
+``pyplot``
+    The ``pyplot`` fixture should be used when a test function is dealing with
+    ``matplotlib``. ``matplotlib`` is a soft dependency and is not required.
+    This fixture is in charge of skipping the tests if ``matplotlib`` is not
+    installed. In addition, figures created during the tests will be
+    automatically closed once the test function has been executed.
 
-   3. Loop.
+To use this fixture in a test function, one needs to pass it as an
+argument::
 
-For guidelines on how to use ``pytest`` efficiently, see the
-:ref:`pytest_tips`.
+    def test_requiring_mpl_fixture(pyplot):
+        # you can now safely use matplotlib
+
+Workflow to improve test coverage
+.................................
+
+To test code coverage, you need to install the `coverage
+<https://pypi.org/project/coverage/>`_ package in addition to pytest.
+
+1. Run 'make test-coverage'. The output lists for each file the line
+    numbers that are not tested.
+
+2. Find a low hanging fruit, looking at which lines are not tested,
+    write or adapt a test specifically for these lines.
 
+3. Loop.
 
 Developers web site
 -------------------
diff --git a/sklearn/conftest.py b/sklearn/conftest.py
new file mode 100644
index 0000000000..d38e45f57b
--- /dev/null
+++ b/sklearn/conftest.py
@@ -0,0 +1,21 @@
+import pytest
+
+
+@pytest.fixture(scope='function')
+def pyplot():
+    """Setup and teardown fixture for matplotlib.
+
+    This fixture checks if we can import matplotlib. If not, the tests will be
+    skipped. Otherwise, we setup matplotlib backend and close the figures
+    after running the functions.
+
+    Returns
+    -------
+    pyplot : module
+        The ``matplotlib.pyplot`` module.
+    """
+    matplotlib = pytest.importorskip('matplotlib')
+    matplotlib.use('agg', warn=False, force=True)
+    pyplot = pytest.importorskip('matplotlib.pyplot')
+    yield pyplot
+    pyplot.close('all')
diff --git a/sklearn/ensemble/tests/test_partial_dependence.py b/sklearn/ensemble/tests/test_partial_dependence.py
index a40fea2ff0..dc0e0419e8 100644
--- a/sklearn/ensemble/tests/test_partial_dependence.py
+++ b/sklearn/ensemble/tests/test_partial_dependence.py
@@ -7,14 +7,12 @@ import numpy as np
 from numpy.testing import assert_array_equal, assert_allclose
 
 from sklearn.utils.testing import assert_raises
-from sklearn.utils.testing import if_matplotlib
 from sklearn.ensemble.partial_dependence import partial_dependence
 from sklearn.ensemble.partial_dependence import plot_partial_dependence
 from sklearn.ensemble import GradientBoostingClassifier
 from sklearn.ensemble import GradientBoostingRegressor
 from sklearn import datasets
 from sklearn.utils.testing import ignore_warnings
-from sklearn.utils.testing import assert_warns_message
 
 
 # toy sample
@@ -156,8 +154,7 @@ def test_partial_dependecy_input():
 @ignore_warnings(category=DeprecationWarning)
 @pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
 # matplotlib Python3.7 warning
-@if_matplotlib
-def test_plot_partial_dependence():
+def test_plot_partial_dependence(pyplot):
     # Test partial dependence plot function.
     clf = GradientBoostingRegressor(n_estimators=10, random_state=1)
     clf.fit(boston.data, boston.target)
@@ -190,9 +187,8 @@ def test_plot_partial_dependence():
 
 @pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
 # matplotlib Python3.7 warning
-@if_matplotlib
 @ignore_warnings(category=DeprecationWarning)
-def test_plot_partial_dependence_input():
+def test_plot_partial_dependence_input(pyplot):
     # Test partial dependence plot function input checks.
     clf = GradientBoostingClassifier(n_estimators=10, random_state=1)
 
@@ -228,9 +224,8 @@ def test_plot_partial_dependence_input():
 
 @pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
 # matplotlib Python3.7 warning
-@if_matplotlib
 @ignore_warnings(category=DeprecationWarning)
-def test_plot_partial_dependence_multiclass():
+def test_plot_partial_dependence_multiclass(pyplot):
     # Test partial dependence plot function on multi-class input.
     clf = GradientBoostingClassifier(n_estimators=10, random_state=1)
     clf.fit(iris.data, iris.target)
@@ -265,30 +260,18 @@ def test_plot_partial_dependence_multiclass():
                   grid_resolution=grid_resolution)
 
 
-def test_warning_raised_partial_dependence():
-    # Test that deprecation warning is raised
-
-    clf = GradientBoostingRegressor(n_estimators=10, random_state=1)
-    clf.fit(boston.data, boston.target)
-    grid_resolution = 25
-
-    assert_warns_message(DeprecationWarning, "The function "
-                         "ensemble.partial_dependence has been deprecated ",
-                         partial_dependence, clf, [0], X=boston.data,
-                         grid_resolution=grid_resolution)
-
-
-@if_matplotlib
-def test_warning_raised_partial_dependence_plot():
-    # Test that deprecation warning is raised
-
+@pytest.mark.parametrize(
+    "func, params",
+    [(partial_dependence, {'target_variables': [0], 'X': boston.data}),
+     (plot_partial_dependence, {'X': boston.data, 'features': [0, 1, (0, 1)]})]
+)
+def test_raise_deprecation_warning(pyplot, func, params):
     clf = GradientBoostingRegressor(n_estimators=10, random_state=1)
     clf.fit(boston.data, boston.target)
     grid_resolution = 25
 
-    assert_warns_message(DeprecationWarning, "The function "
-                         "ensemble.plot_partial_dependence has been "
-                         "deprecated",
-                         plot_partial_dependence, clf, boston.data,
-                         [0, 1, (0, 1)], grid_resolution=grid_resolution,
-                         feature_names=boston.feature_names)
+    warn_msg = "The function ensemble.{} has been deprecated".format(
+        func.__name__
+    )
+    with pytest.warns(DeprecationWarning, match=warn_msg):
+        func(clf, **params, grid_resolution=grid_resolution)
diff --git a/sklearn/inspection/tests/test_partial_dependence.py b/sklearn/inspection/tests/test_partial_dependence.py
index d2d3c7818e..b90b76c422 100644
--- a/sklearn/inspection/tests/test_partial_dependence.py
+++ b/sklearn/inspection/tests/test_partial_dependence.py
@@ -27,7 +27,6 @@ from sklearn.dummy import DummyClassifier
 from sklearn.base import BaseEstimator, ClassifierMixin
 from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_array_equal
-from sklearn.utils.testing import if_matplotlib
 
 
 # toy sample
@@ -396,11 +395,8 @@ def test_partial_dependence_sample_weight():
     assert np.corrcoef(pdp, values)[0, 1] > 0.99
 
 
-@if_matplotlib
-def test_plot_partial_dependence():
+def test_plot_partial_dependence(pyplot):
     # Test partial dependence plot function.
-    import matplotlib.pyplot as plt  # noqa
-
     boston = load_boston()
     clf = GradientBoostingRegressor(n_estimators=10, random_state=1)
     clf.fit(boston.data, boston.target)
@@ -409,7 +405,7 @@ def test_plot_partial_dependence():
     plot_partial_dependence(clf, boston.data, [0, 1, (0, 1)],
                             grid_resolution=grid_resolution,
                             feature_names=boston.feature_names)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 3
     assert all(ax.has_data for ax in axs)
@@ -420,7 +416,7 @@ def test_plot_partial_dependence():
                             grid_resolution=grid_resolution,
                             feature_names=boston.feature_names)
 
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 3
     assert all(ax.has_data for ax in axs)
@@ -431,18 +427,14 @@ def test_plot_partial_dependence():
                                                ('CRIM', 'ZN')],
                             grid_resolution=grid_resolution,
                             feature_names=feature_names)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 3
     assert all(ax.has_data for ax in axs)
 
-    plt.close('all')
-
 
-@if_matplotlib
-def test_plot_partial_dependence_multiclass():
+def test_plot_partial_dependence_multiclass(pyplot):
     # Test partial dependence plot function on multi-class input.
-    import matplotlib.pyplot as plt  # noqa
     iris = load_iris()
     clf = GradientBoostingClassifier(n_estimators=10, random_state=1)
     clf.fit(iris.data, iris.target)
@@ -451,7 +443,7 @@ def test_plot_partial_dependence_multiclass():
     plot_partial_dependence(clf, iris.data, [0, 1],
                             target=0,
                             grid_resolution=grid_resolution)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 2
     assert all(ax.has_data for ax in axs)
@@ -465,18 +457,14 @@ def test_plot_partial_dependence_multiclass():
     plot_partial_dependence(clf, iris.data, [0, 1],
                             target='setosa',
                             grid_resolution=grid_resolution)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 2
     assert all(ax.has_data for ax in axs)
 
-    plt.close('all')
 
-
-@if_matplotlib
-def test_plot_partial_dependence_multioutput():
+def test_plot_partial_dependence_multioutput(pyplot):
     # Test partial dependence plot function on multi-output input.
-    import matplotlib.pyplot as plt  # noqa
     (X, y), _ = multioutput_regression_data
     clf = LinearRegression()
     clf.fit(X, y)
@@ -485,7 +473,7 @@ def test_plot_partial_dependence_multioutput():
     plot_partial_dependence(clf, X, [0, 1],
                             target=0,
                             grid_resolution=grid_resolution)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 2
     assert all(ax.has_data for ax in axs)
@@ -493,15 +481,12 @@ def test_plot_partial_dependence_multioutput():
     plot_partial_dependence(clf, X, [0, 1],
                             target=1,
                             grid_resolution=grid_resolution)
-    fig = plt.gcf()
+    fig = pyplot.gcf()
     axs = fig.get_axes()
     assert len(axs) == 2
     assert all(ax.has_data for ax in axs)
 
-    plt.close('all')
-
 
-@if_matplotlib
 @pytest.mark.parametrize(
     "data, params, err_msg",
     [(multioutput_regression_data[0], {"target": None, 'features': [0]},
@@ -531,32 +516,23 @@ def test_plot_partial_dependence_multioutput():
 )
 @pytest.mark.filterwarnings('ignore:Default solver will be changed ')  # 0.22
 @pytest.mark.filterwarnings('ignore:Default multi_class will be')  # 0.22
-def test_plot_partial_dependence_error(data, params, err_msg):
-    import matplotlib.pyplot as plt  # noqa
+def test_plot_partial_dependence_error(pyplot, data, params, err_msg):
     X, y = data
     estimator = LinearRegression().fit(X, y)
 
     with pytest.raises(ValueError, match=err_msg):
         plot_partial_dependence(estimator, X, **params)
 
-    plt.close()
 
-
-@if_matplotlib
-def test_plot_partial_dependence_fig():
+def test_plot_partial_dependence_fig(pyplot):
     # Make sure fig object is correctly used if not None
-
-    import matplotlib.pyplot as plt
-
     (X, y), _ = regression_data
     clf = LinearRegression()
     clf.fit(X, y)
 
-    fig = plt.figure()
+    fig = pyplot.figure()
     grid_resolution = 25
     plot_partial_dependence(
         clf, X, [0, 1], target=0, grid_resolution=grid_resolution, fig=fig)
 
-    assert plt.gcf() is fig
-
-    plt.close()
+    assert pyplot.gcf() is fig
diff --git a/sklearn/tests/test_common.py b/sklearn/tests/test_common.py
index fc3c7f3985..660b38c1ae 100644
--- a/sklearn/tests/test_common.py
+++ b/sklearn/tests/test_common.py
@@ -215,7 +215,7 @@ def test_import_all_consistency():
 
 
 def test_root_import_all_completeness():
-    EXCEPTIONS = ('utils', 'tests', 'base', 'setup')
+    EXCEPTIONS = ('utils', 'tests', 'base', 'setup', 'conftest')
     for _, modname, _ in pkgutil.walk_packages(path=sklearn.__path__,
                                                onerror=lambda _: None):
         if '.' in modname or modname.startswith('_') or modname in EXCEPTIONS:
diff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py
index 65b0a201be..eed9be7bcb 100644
--- a/sklearn/tree/tests/test_export.py
+++ b/sklearn/tree/tests/test_export.py
@@ -399,9 +399,8 @@ def test_export_text():
     assert export_text(reg, decimals=1, show_weights=True) == expected_report
 
 
-def test_plot_tree():
+def test_plot_tree(pyplot):
     # mostly smoke tests
-    pytest.importorskip("matplotlib.pyplot")
     # Check correctness of export_graphviz
     clf = DecisionTreeClassifier(max_depth=3,
                                  min_samples_split=2,
diff --git a/sklearn/utils/testing.py b/sklearn/utils/testing.py
index 65bed4c7ec..babf0b8658 100644
--- a/sklearn/utils/testing.py
+++ b/sklearn/utils/testing.py
@@ -714,28 +714,6 @@ def set_random_state(estimator, random_state=0):
         estimator.set_params(random_state=random_state)
 
 
-def if_matplotlib(func):
-    """Test decorator that skips test if matplotlib not installed.
-
-    Parameters
-    ----------
-    func
-    """
-    @wraps(func)
-    def run_test(*args, **kwargs):
-        try:
-            import matplotlib
-            matplotlib.use('Agg', warn=False)
-            # this fails if no $DISPLAY specified
-            import matplotlib.pyplot as plt
-            plt.figure()
-        except ImportError:
-            raise SkipTest('Matplotlib not available.')
-        else:
-            return func(*args, **kwargs)
-    return run_test
-
-
 try:
     import pytest
 
@@ -1024,21 +1002,3 @@ def assert_run_python_script(source_code, timeout=60):
                                % e.output.decode('utf-8'))
     finally:
         os.unlink(source_file)
-
-
-def close_figure(fig=None):
-    """Close a matplotlibt figure.
-
-    Parameters
-    ----------
-    fig : int or str or Figure, optional (default=None)
-        The figure, figure number or figure name to close. If ``None``, all
-        current figures are closed.
-    """
-    from matplotlib.pyplot import get_fignums, close as _close  # noqa
-
-    if fig is None:
-        for fig in get_fignums():
-            _close(fig)
-    else:
-        _close(fig)
+ git diff b34751b7ed02b2cfcc36037fb729d4360480a299
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-iz6bdhqg/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.5.2)
Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.1.1)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.22.dev0
    Uninstalling scikit-learn-0.22.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.22.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    blas_opt_info:
    blas_mkl_info:
    customize UnixCCompiler
      libraries mkl_rt not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    blis_info:
      libraries blis not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    openblas_info:
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    creating /tmp/tmpsoasdhdw/tmp
    creating /tmp/tmpsoasdhdw/tmp/tmpsoasdhdw
    compile options: '-c'
    gcc: /tmp/tmpsoasdhdw/source.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ /tmp/tmpsoasdhdw/tmp/tmpsoasdhdw/source.o -L/opt/miniconda3/envs/testbed/lib -lopenblas -o /tmp/tmpsoasdhdw/a.out
      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    compile options: '-c'
    extra options: '-fopenmp'
    gcc: test_openmp.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ objects/test_openmp.o -o test_openmp -fopenmp
    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.histogram" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.splitting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._binning" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._predictor" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._loss" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.types" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.utils" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.lgamma" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn._isotonic" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.22.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.22.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git apply -v -
Checking patch sklearn/ensemble/voting.py...
Applied patch sklearn/ensemble/voting.py cleanly.
+ git apply -v -
<stdin>:16: trailing whitespace.
    
<stdin>:21: trailing whitespace.
    
<stdin>:24: trailing whitespace.
    
<stdin>:27: trailing whitespace.
    
Checking patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13779.py...
Applied patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13779.py cleanly.
warning: 4 lines add whitespace errors.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(sklearn/ensemble/voting\.py)' -m pytest --no-header -rA -p no:cacheprovider sklearn/tests/test_coverup_scikit-learn__scikit-learn-13779.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(sklearn/ensemble/voting\\.py)']
============================= test session starts ==============================
collected 1 item

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13779.py .         [100%]

==================================== PASSES ====================================
__________________ test_voting_classifier_with_none_estimator __________________
----------------------------- Captured stdout call -----------------------------
0.80 /testbed/sklearn/ensemble/voting.py(236):         self.estimators = estimators
0.80 /testbed/sklearn/ensemble/voting.py(237):         self.voting = voting
0.80 /testbed/sklearn/ensemble/voting.py(238):         self.weights = weights
0.80 /testbed/sklearn/ensemble/voting.py(239):         self.n_jobs = n_jobs
0.80 /testbed/sklearn/ensemble/voting.py(240):         self.flatten_transform = flatten_transform
0.80 /testbed/sklearn/ensemble/voting.py(263):         if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:
0.80 /testbed/sklearn/ensemble/voting.py(267):         if self.voting not in ('soft', 'hard'):
0.80 /testbed/sklearn/ensemble/voting.py(271):         self.le_ = LabelEncoder().fit(y)
0.80 /testbed/sklearn/ensemble/voting.py(272):         self.classes_ = self.le_.classes_
0.80 /testbed/sklearn/ensemble/voting.py(273):         transformed_y = self.le_.transform(y)
0.80 /testbed/sklearn/ensemble/voting.py(275):         return super().fit(X, transformed_y, sample_weight)
0.80 /testbed/sklearn/ensemble/voting.py(68):         if self.estimators is None or len(self.estimators) == 0:
0.80 /testbed/sklearn/ensemble/voting.py(73):         if (self.weights is not None and
0.80 /testbed/sklearn/ensemble/voting.py(79):         if sample_weight is not None:
0.80 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.80 /testbed/sklearn/ensemble/voting.py(81):                 if step is None:
0.80 /testbed/sklearn/ensemble/voting.py(83):                 if not has_fit_parameter(step, 'sample_weight'):
0.80 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.80 /testbed/sklearn/ensemble/voting.py(81):                 if step is None:
0.80 /testbed/sklearn/ensemble/voting.py(83):                 if not has_fit_parameter(step, 'sample_weight'):
0.80 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.80 /testbed/sklearn/ensemble/voting.py(87):         names, clfs = zip(*self.estimators)
0.80 /testbed/sklearn/ensemble/voting.py(88):         self._validate_names(names)
0.80 /testbed/sklearn/ensemble/voting.py(137):         return self._get_params('estimators', deep=deep)
0.80 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.80 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.80 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.80 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.80 /testbed/sklearn/ensemble/voting.py(91):         if n_isnone == len(self.estimators):
0.80 /testbed/sklearn/ensemble/voting.py(95):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
0.80 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.80 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.80 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.80 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.80 /testbed/sklearn/ensemble/voting.py(32):     if sample_weight is not None:
0.80 /testbed/sklearn/ensemble/voting.py(33):         estimator.fit(X, y, sample_weight=sample_weight)
0.80 /testbed/sklearn/ensemble/voting.py(36):     return estimator
0.80 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.80 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.80 /testbed/sklearn/ensemble/voting.py(32):     if sample_weight is not None:
0.80 /testbed/sklearn/ensemble/voting.py(33):         estimator.fit(X, y, sample_weight=sample_weight)
0.82 /testbed/sklearn/ensemble/voting.py(36):     return estimator
0.82 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.82 /testbed/sklearn/ensemble/voting.py(100):         self.named_estimators_ = Bunch()
0.82 /testbed/sklearn/ensemble/voting.py(101):         for k, e in zip(self.estimators, self.estimators_):
0.82 /testbed/sklearn/ensemble/voting.py(102):             self.named_estimators_[k[0]] = e
0.82 /testbed/sklearn/ensemble/voting.py(101):         for k, e in zip(self.estimators, self.estimators_):
0.82 /testbed/sklearn/ensemble/voting.py(102):             self.named_estimators_[k[0]] = e
0.82 /testbed/sklearn/ensemble/voting.py(101):         for k, e in zip(self.estimators, self.estimators_):
0.82 /testbed/sklearn/ensemble/voting.py(103):         return self
0.82 /testbed/sklearn/ensemble/voting.py(126):         return self._set_params('estimators', **params)
0.82 /testbed/sklearn/ensemble/voting.py(263):         if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:
0.82 /testbed/sklearn/ensemble/voting.py(267):         if self.voting not in ('soft', 'hard'):
0.82 /testbed/sklearn/ensemble/voting.py(271):         self.le_ = LabelEncoder().fit(y)
0.82 /testbed/sklearn/ensemble/voting.py(272):         self.classes_ = self.le_.classes_
0.82 /testbed/sklearn/ensemble/voting.py(273):         transformed_y = self.le_.transform(y)
0.82 /testbed/sklearn/ensemble/voting.py(275):         return super().fit(X, transformed_y, sample_weight)
0.82 /testbed/sklearn/ensemble/voting.py(68):         if self.estimators is None or len(self.estimators) == 0:
0.82 /testbed/sklearn/ensemble/voting.py(73):         if (self.weights is not None and
0.82 /testbed/sklearn/ensemble/voting.py(79):         if sample_weight is not None:
0.82 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.82 /testbed/sklearn/ensemble/voting.py(81):                 if step is None:
0.82 /testbed/sklearn/ensemble/voting.py(82):                     continue
0.82 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.82 /testbed/sklearn/ensemble/voting.py(81):                 if step is None:
0.82 /testbed/sklearn/ensemble/voting.py(83):                 if not has_fit_parameter(step, 'sample_weight'):
0.82 /testbed/sklearn/ensemble/voting.py(80):             for name, step in self.estimators:
0.82 /testbed/sklearn/ensemble/voting.py(87):         names, clfs = zip(*self.estimators)
0.82 /testbed/sklearn/ensemble/voting.py(88):         self._validate_names(names)
0.82 /testbed/sklearn/ensemble/voting.py(137):         return self._get_params('estimators', deep=deep)
0.82 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.82 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.82 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.82 /testbed/sklearn/ensemble/voting.py(90):         n_isnone = np.sum([clf is None for _, clf in self.estimators])
0.82 /testbed/sklearn/ensemble/voting.py(91):         if n_isnone == len(self.estimators):
0.82 /testbed/sklearn/ensemble/voting.py(95):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
0.82 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.82 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.82 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.82 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.82 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.82 /testbed/sklearn/ensemble/voting.py(98):                 for clf in clfs if clf is not None)
0.82 /testbed/sklearn/ensemble/voting.py(32):     if sample_weight is not None:
0.82 /testbed/sklearn/ensemble/voting.py(33):         estimator.fit(X, y, sample_weight=sample_weight)
0.83 /testbed/sklearn/ensemble/voting.py(36):     return estimator
0.83 /testbed/sklearn/ensemble/voting.py(96):                 delayed(_parallel_fit_estimator)(clone(clf), X, y,
0.83 /testbed/sklearn/ensemble/voting.py(100):         self.named_estimators_ = Bunch()
0.83 /testbed/sklearn/ensemble/voting.py(101):         for k, e in zip(self.estimators, self.estimators_):
0.83 /testbed/sklearn/ensemble/voting.py(102):             self.named_estimators_[k[0]] = e
0.83 /testbed/sklearn/ensemble/voting.py(101):         for k, e in zip(self.estimators, self.estimators_):
0.83 /testbed/sklearn/ensemble/voting.py(103):         return self
=========================== short test summary info ============================
PASSED sklearn/tests/test_coverup_scikit-learn__scikit-learn-13779.py::test_voting_classifier_with_none_estimator
======================== 1 passed, 5 warnings in 0.45s =========================
+ cat coverage.cover
{"/testbed/sklearn/ensemble/voting.py": {"16": 1, "17": 1, "19": 1, "20": 1, "21": 1, "22": 1, "23": 1, "24": 1, "25": 1, "26": 1, "27": 1, "30": 1, "39": 2, "140": 2, "370": 2, "32": 3, "33": 3, "35": 0, "36": 3, "45": 1, "47": 1, "51": 1, "59": 1, "63": 1, "64": 1, "105": 1, "128": 1, "49": 0, "54": 0, "55": 0, "56": 0, "57": 0, "61": 0, "68": 2, "69": 0, "73": 2, "74": 0, "75": 0, "77": 0, "79": 2, "80": 6, "81": 4, "82": 1, "83": 3, "84": 0, "85": 0, "87": 2, "88": 2, "90": 8, "91": 2, "92": 0, "95": 2, "96": 8, "98": 6, "100": 2, "101": 5, "102": 3, "103": 2, "126": 1, "137": 2, "235": 1, "242": 1, "277": 1, "306": 1, "310": 1, "320": 1, "336": 1, "236": 1, "237": 1, "238": 1, "239": 1, "240": 1, "263": 2, "264": 0, "267": 2, "268": 0, "269": 0, "271": 2, "272": 2, "273": 2, "275": 2, "291": 0, "292": 0, "293": 0, "296": 0, "297": 0, "298": 0, "300": 0, "302": 0, "304": 0, "299": 0, "308": 0, "312": 0, "313": 0, "314": 0, "315": 0, "316": 0, "317": 0, "318": 0, "334": 0, "358": 0, "360": 0, "361": 0, "362": 0, "363": 0, "364": 0, "367": 0, "427": 1, "432": 1, "455": 1, "475": 1, "428": 0, "429": 0, "430": 0, "453": 0, "471": 0, "472": 0, "473": 0, "489": 0, "490": 0}}
+ git checkout b34751b7ed02b2cfcc36037fb729d4360480a299
Note: switching to 'b34751b7ed02b2cfcc36037fb729d4360480a299'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at b34751b7ed [MRG] MAINT: add fixture for init and clean-up with matplotlib (#13708)
M	sklearn/ensemble/voting.py
+ git apply /root/pre_state.patch
error: unrecognized input
