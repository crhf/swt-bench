+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD a061ada48efccf0845acae17009553e01764452b
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit a061ada48efccf0845acae17009553e01764452b
Author: Giuseppe Vettigli <giuseppe.vettigli@hivehome.com>
Date:   Mon Feb 11 23:23:48 2019 +0000

    FEA Print Decision Trees in ASCII format (#9424)

diff --git a/doc/modules/classes.rst b/doc/modules/classes.rst
index 75f355fc8e..88201ba8f2 100644
--- a/doc/modules/classes.rst
+++ b/doc/modules/classes.rst
@@ -1399,6 +1399,7 @@ Low-level methods
 
    tree.export_graphviz
    tree.plot_tree
+   tree.export_text
 
 
 .. _utils_ref:
diff --git a/doc/modules/tree.rst b/doc/modules/tree.rst
index 45b71d13b8..70ab013f33 100644
--- a/doc/modules/tree.rst
+++ b/doc/modules/tree.rst
@@ -182,6 +182,29 @@ render these plots inline automatically::
    :align: center
    :scale: 75
 
+Alternatively, the tree can also be exported in textual format with the
+function :func:`export_text`. This method doesn't require the installation
+of external libraries and is more compact:
+
+    >>> from sklearn.datasets import load_iris
+    >>> from sklearn.tree import DecisionTreeClassifier
+    >>> from sklearn.tree.export import export_text
+    >>> iris = load_iris()
+    >>> X = iris['data']
+    >>> y = iris['target']
+    >>> decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)
+    >>> decision_tree = decision_tree.fit(X, y)
+    >>> r = export_text(decision_tree, feature_names=iris['feature_names'])
+    >>> print(r)
+    |--- petal width (cm) <= 0.80
+    |   |--- class: 0
+    |--- petal width (cm) >  0.80
+    |   |--- petal width (cm) <= 1.75
+    |   |   |--- class: 1
+    |   |--- petal width (cm) >  1.75
+    |   |   |--- class: 2
+    <BLANKLINE>
+
 .. topic:: Examples:
 
  * :ref:`sphx_glr_auto_examples_tree_plot_iris_dtc.py`
diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index 7bc4389e51..3bbd9f3189 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -260,6 +260,10 @@ Support for Python 3.4 and below has been officially dropped.
   :func:`tree.plot_tree` without relying on the ``dot`` library,
   removing a hard-to-install dependency. :issue:`8508` by `Andreas MÃ¼ller`_.
 
+- |Feature| Decision Trees can now be exported in a human readable
+  textual format using :func:`tree.export.export_text`.
+  :issue:`6261` by `Giuseppe Vettigli <JustGlowing>`.
+
 - |Feature| ``get_n_leaves()`` and ``get_depth()`` have been added to
   :class:`tree.BaseDecisionTree` and consequently all estimators based
   on it, including :class:`tree.DecisionTreeClassifier`,
diff --git a/sklearn/tree/__init__.py b/sklearn/tree/__init__.py
index b3abe30d01..e91540bed8 100644
--- a/sklearn/tree/__init__.py
+++ b/sklearn/tree/__init__.py
@@ -7,8 +7,8 @@ from .tree import DecisionTreeClassifier
 from .tree import DecisionTreeRegressor
 from .tree import ExtraTreeClassifier
 from .tree import ExtraTreeRegressor
-from .export import export_graphviz, plot_tree
+from .export import export_graphviz, plot_tree, export_text
 
 __all__ = ["DecisionTreeClassifier", "DecisionTreeRegressor",
            "ExtraTreeClassifier", "ExtraTreeRegressor", "export_graphviz",
-           "plot_tree"]
+           "plot_tree",  "export_text"]
diff --git a/sklearn/tree/export.py b/sklearn/tree/export.py
index d0c336a1c5..02aa68b8af 100644
--- a/sklearn/tree/export.py
+++ b/sklearn/tree/export.py
@@ -9,6 +9,7 @@ This module defines export functions for decision trees.
 #          Satrajit Gosh <satrajit.ghosh@gmail.com>
 #          Trevor Stephens <trev.stephens@gmail.com>
 #          Li Li <aiki.nogard@gmail.com>
+#          Giuseppe Vettigli <vettigli@gmail.com>
 # License: BSD 3 clause
 import warnings
 from io import StringIO
@@ -22,6 +23,7 @@ from ..utils.validation import check_is_fitted
 from . import _criterion
 from . import _tree
 from ._reingold_tilford import buchheim, Tree
+from . import DecisionTreeClassifier
 
 
 def _color_brew(n):
@@ -778,3 +780,178 @@ def export_graphviz(decision_tree, out_file=None, max_depth=None,
     finally:
         if own_file:
             out_file.close()
+
+
+def _compute_depth(tree, node):
+    """
+    Returns the depth of the subtree rooted in node.
+    """
+    def compute_depth_(current_node, current_depth,
+                       children_left, children_right, depths):
+        depths += [current_depth]
+        left = children_left[current_node]
+        right = children_right[current_node]
+        if left != -1 and right != -1:
+            compute_depth_(left, current_depth+1,
+                           children_left, children_right, depths)
+            compute_depth_(right, current_depth+1,
+                           children_left, children_right, depths)
+
+    depths = []
+    compute_depth_(node, 1, tree.children_left, tree.children_right, depths)
+    return max(depths)
+
+
+def export_text(decision_tree, feature_names=None, max_depth=10,
+                spacing=3, decimals=2, show_weights=False):
+    """Build a text report showing the rules of a decision tree.
+
+    Note that backwards compatibility may not be supported.
+
+    Parameters
+    ----------
+    decision_tree : object
+        The decision tree estimator to be exported.
+        It can be an instance of
+        DecisionTreeClassifier or DecisionTreeRegressor.
+
+    feature_names : list, optional (default=None)
+        A list of length n_features containing the feature names.
+        If None generic names will be used ("feature_0", "feature_1", ...).
+
+    max_depth : int, optional (default=10)
+        Only the first max_depth levels of the tree are exported.
+        Truncated branches will be marked with "...".
+
+    spacing : int, optional (default=3)
+        Number of spaces between edges. The higher it is, the wider the result.
+
+    decimals : int, optional (default=2)
+        Number of decimal digits to display.
+
+    show_weights : bool, optional (default=False)
+        If true the classification weights will be exported on each leaf.
+        The classification weights are the number of samples each class.
+
+    Returns
+    -------
+    report : string
+        Text summary of all the rules in the decision tree.
+
+    Examples
+    -------
+
+    >>> from sklearn.datasets import load_iris
+    >>> from sklearn.tree import DecisionTreeClassifier
+    >>> from sklearn.tree.export import export_text
+    >>> iris = load_iris()
+    >>> X = iris['data']
+    >>> y = iris['target']
+    >>> decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)
+    >>> decision_tree = decision_tree.fit(X, y)
+    >>> r = export_text(decision_tree, feature_names=iris['feature_names'])
+    >>> print(r)
+    |--- petal width (cm) <= 0.80
+    |   |--- class: 0
+    |--- petal width (cm) >  0.80
+    |   |--- petal width (cm) <= 1.75
+    |   |   |--- class: 1
+    |   |--- petal width (cm) >  1.75
+    |   |   |--- class: 2
+    ...
+    """
+    check_is_fitted(decision_tree, 'tree_')
+    tree_ = decision_tree.tree_
+    class_names = decision_tree.classes_
+    right_child_fmt = "{} {} <= {}\n"
+    left_child_fmt = "{} {} >  {}\n"
+    truncation_fmt = "{} {}\n"
+
+    if max_depth < 0:
+        raise ValueError("max_depth bust be >= 0, given %d" % max_depth)
+
+    if (feature_names is not None and
+            len(feature_names) != tree_.n_features):
+        raise ValueError("feature_names must contain "
+                         "%d elements, got %d" % (tree_.n_features,
+                                                  len(feature_names)))
+
+    if spacing <= 0:
+        raise ValueError("spacing must be > 0, given %d" % spacing)
+
+    if decimals < 0:
+        raise ValueError("decimals must be >= 0, given %d" % decimals)
+
+    if isinstance(decision_tree, DecisionTreeClassifier):
+        value_fmt = "{}{} weights: {}\n"
+        if not show_weights:
+            value_fmt = "{}{}{}\n"
+    else:
+        value_fmt = "{}{} value: {}\n"
+
+    if feature_names:
+        feature_names_ = [feature_names[i] for i in tree_.feature]
+    else:
+        feature_names_ = ["feature_{}".format(i) for i in tree_.feature]
+
+    export_text.report = ""
+
+    def _add_leaf(value, class_name, indent):
+        val = ''
+        is_classification = isinstance(decision_tree,
+                                       DecisionTreeClassifier)
+        if show_weights or not is_classification:
+            val = ["{1:.{0}f}, ".format(decimals, v) for v in value]
+            val = '['+''.join(val)[:-2]+']'
+        if is_classification:
+            val += ' class: ' + str(class_name)
+        export_text.report += value_fmt.format(indent, '', val)
+
+    def print_tree_recurse(node, depth):
+        indent = ("|" + (" " * spacing)) * depth
+        indent = indent[:-spacing] + "-" * spacing
+
+        value = None
+        if tree_.n_outputs == 1:
+            value = tree_.value[node][0]
+        else:
+            value = tree_.value[node].T[0]
+        class_name = np.argmax(value)
+
+        if (tree_.n_classes[0] != 1 and
+                tree_.n_outputs == 1):
+            class_name = class_names[class_name]
+
+        if depth <= max_depth+1:
+            info_fmt = ""
+            info_fmt_left = info_fmt
+            info_fmt_right = info_fmt
+
+            if tree_.feature[node] != _tree.TREE_UNDEFINED:
+                name = feature_names_[node]
+                threshold = tree_.threshold[node]
+                threshold = "{1:.{0}f}".format(decimals, threshold)
+                export_text.report += right_child_fmt.format(indent,
+                                                             name,
+                                                             threshold)
+                export_text.report += info_fmt_left
+                print_tree_recurse(tree_.children_left[node], depth+1)
+
+                export_text.report += left_child_fmt.format(indent,
+                                                            name,
+                                                            threshold)
+                export_text.report += info_fmt_right
+                print_tree_recurse(tree_.children_right[node], depth+1)
+            else:  # leaf
+                _add_leaf(value, class_name, indent)
+        else:
+            subtree_depth = _compute_depth(tree_, node)
+            if subtree_depth == 1:
+                _add_leaf(value, class_name, indent)
+            else:
+                trunc_report = 'truncated branch of depth %d' % subtree_depth
+                export_text.report += truncation_fmt.format(indent,
+                                                            trunc_report)
+
+    print_tree_recurse(0, 1)
+    return export_text.report
diff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py
index 6c765675fa..65b0a201be 100644
--- a/sklearn/tree/tests/test_export.py
+++ b/sklearn/tree/tests/test_export.py
@@ -4,13 +4,14 @@ Testing for export functions of decision trees (sklearn.tree.export).
 import pytest
 
 from re import finditer, search
+from textwrap import dedent
 
 from numpy.random import RandomState
 
 from sklearn.base import is_classifier
 from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
 from sklearn.ensemble import GradientBoostingClassifier
-from sklearn.tree import export_graphviz, plot_tree
+from sklearn.tree import export_graphviz, plot_tree, export_text
 from io import StringIO
 from sklearn.utils.testing import (assert_in, assert_equal, assert_raises,
                                    assert_less_equal, assert_raises_regex,
@@ -311,6 +312,93 @@ def test_precision():
                              precision + 1)
 
 
+def test_export_text_errors():
+    clf = DecisionTreeClassifier(max_depth=2, random_state=0)
+    clf.fit(X, y)
+
+    assert_raise_message(ValueError,
+                         "max_depth bust be >= 0, given -1",
+                         export_text, clf, max_depth=-1)
+    assert_raise_message(ValueError,
+                         "feature_names must contain 2 elements, got 1",
+                         export_text, clf, feature_names=['a'])
+    assert_raise_message(ValueError,
+                         "decimals must be >= 0, given -1",
+                         export_text, clf, decimals=-1)
+    assert_raise_message(ValueError,
+                         "spacing must be > 0, given 0",
+                         export_text, clf, spacing=0)
+
+
+def test_export_text():
+    clf = DecisionTreeClassifier(max_depth=2, random_state=0)
+    clf.fit(X, y)
+
+    expected_report = dedent("""
+    |--- feature_1 <= 0.00
+    |   |--- class: -1
+    |--- feature_1 >  0.00
+    |   |--- class: 1
+    """).lstrip()
+
+    assert export_text(clf) == expected_report
+    # testing that leaves at level 1 are not truncated
+    assert export_text(clf, max_depth=0) == expected_report
+    # testing that the rest of the tree is truncated
+    assert export_text(clf, max_depth=10) == expected_report
+
+    expected_report = dedent("""
+    |--- b <= 0.00
+    |   |--- class: -1
+    |--- b >  0.00
+    |   |--- class: 1
+    """).lstrip()
+    assert export_text(clf, feature_names=['a', 'b']) == expected_report
+
+    expected_report = dedent("""
+    |--- feature_1 <= 0.00
+    |   |--- weights: [3.00, 0.00] class: -1
+    |--- feature_1 >  0.00
+    |   |--- weights: [0.00, 3.00] class: 1
+    """).lstrip()
+    assert export_text(clf, show_weights=True) == expected_report
+
+    expected_report = dedent("""
+    |- feature_1 <= 0.00
+    | |- class: -1
+    |- feature_1 >  0.00
+    | |- class: 1
+    """).lstrip()
+    assert export_text(clf, spacing=1) == expected_report
+
+    X_l = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [-1, 1]]
+    y_l = [-1, -1, -1, 1, 1, 1, 2]
+    clf = DecisionTreeClassifier(max_depth=4, random_state=0)
+    clf.fit(X_l, y_l)
+    expected_report = dedent("""
+    |--- feature_1 <= 0.00
+    |   |--- class: -1
+    |--- feature_1 >  0.00
+    |   |--- truncated branch of depth 2
+    """).lstrip()
+    assert export_text(clf, max_depth=0) == expected_report
+
+    X_mo = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]
+    y_mo = [[-1, -1], [-1, -1], [-1, -1], [1, 1], [1, 1], [1, 1]]
+
+    reg = DecisionTreeRegressor(max_depth=2, random_state=0)
+    reg.fit(X_mo, y_mo)
+
+    expected_report = dedent("""
+    |--- feature_1 <= 0.0
+    |   |--- value: [-1.0, -1.0]
+    |--- feature_1 >  0.0
+    |   |--- value: [1.0, 1.0]
+    """).lstrip()
+    assert export_text(reg, decimals=1) == expected_report
+    assert export_text(reg, decimals=1, show_weights=True) == expected_report
+
+
 def test_plot_tree():
     # mostly smoke tests
     pytest.importorskip("matplotlib.pyplot")
+ git diff a061ada48efccf0845acae17009553e01764452b
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-t2xn7stv/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.21.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.21.dev0) (1.5.2)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.21.dev0
    Uninstalling scikit-learn-0.21.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.21.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    blas_opt_info:
    blas_mkl_info:
    customize UnixCCompiler
      libraries mkl_rt not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    blis_info:
      libraries blis not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    openblas_info:
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    creating /tmp/tmpctfmqbvg/tmp
    creating /tmp/tmpctfmqbvg/tmp/tmpctfmqbvg
    compile options: '-c'
    gcc: /tmp/tmpctfmqbvg/source.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ /tmp/tmpctfmqbvg/tmp/tmpctfmqbvg/source.o -L/opt/miniconda3/envs/testbed/lib -lopenblas -o /tmp/tmpctfmqbvg/a.out
      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn._isotonic" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.lgamma" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    resetting extension 'sklearn.svm.liblinear' language from 'c' to 'c++'.
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.21.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.21.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git apply -v -
<stdin>:16: trailing whitespace.
    
Checking patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py...
Applied patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py cleanly.
warning: 1 line adds whitespace errors.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(sklearn/preprocessing/_discretization\.py)' -m pytest --no-header -rA -p no:cacheprovider sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(sklearn/preprocessing/_discretization\\.py)']
============================= test session starts ==============================
collected 1 item

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py F         [100%]

=================================== FAILURES ===================================
___________________ test_kmeans_strategy_unsorted_bin_edges ____________________

    def test_kmeans_strategy_unsorted_bin_edges():
        # Test setup
        X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
        n_bins = 5
        est = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans', encode='ordinal')
    
        # Test that no ValueError is raised when bin_edges are sorted correctly
        try:
>           est.fit_transform(X)

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py:13: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KBinsDiscretizer(encode='ordinal', n_bins=5, strategy='kmeans')
X = array([[ 0. ],
       [ 0.5],
       [ 2. ],
       [ 3. ],
       [ 9. ],
       [10. ]])
y = None, fit_params = {}

    def fit_transform(self, X, y=None, **fit_params):
        """Fit to data, then transform it.
    
        Fits transformer to X and y with optional parameters fit_params
        and returns a transformed version of X.
    
        Parameters
        ----------
        X : numpy array of shape [n_samples, n_features]
            Training set.
    
        y : numpy array of shape [n_samples]
            Target values.
    
        Returns
        -------
        X_new : numpy array of shape [n_samples, n_features_new]
            Transformed array.
    
        """
        # non-optimized default implementation; override when a better
        # method is possible for a given clustering algorithm
        if y is None:
            # fit method of arity 1 (unsupervised transformation)
>           return self.fit(X, **fit_params).transform(X)

sklearn/base.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KBinsDiscretizer(encode='ordinal', n_bins=5, strategy='kmeans')
X = array([[ 0. ],
       [ 0.5],
       [ 2. ],
       [ 3. ],
       [ 9. ],
       [10. ]])

    def transform(self, X):
        """Discretizes the data.
    
        Parameters
        ----------
        X : numeric array-like, shape (n_samples, n_features)
            Data to be discretized.
    
        Returns
        -------
        Xt : numeric array-like or sparse matrix
            Data in the binned space.
        """
        check_is_fitted(self, ["bin_edges_"])
    
        Xt = check_array(X, copy=True, dtype=FLOAT_DTYPES)
        n_features = self.n_bins_.shape[0]
        if Xt.shape[1] != n_features:
            raise ValueError("Incorrect number of features. Expecting {}, "
                             "received {}.".format(n_features, Xt.shape[1]))
    
        bin_edges = self.bin_edges_
        for jj in range(Xt.shape[1]):
            # Values which are close to a bin edge are susceptible to numeric
            # instability. Add eps to X so these values are binned correctly
            # with respect to their decimal truncation. See documentation of
            # numpy.isclose for an explanation of ``rtol`` and ``atol``.
            rtol = 1.e-5
            atol = 1.e-8
            eps = atol + rtol * np.abs(Xt[:, jj])
>           Xt[:, jj] = np.digitize(Xt[:, jj] + eps, bin_edges[jj][1:])

sklearn/preprocessing/_discretization.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([1.00000000e-08, 5.00005010e-01, 2.00002001e+00, 3.00003001e+00,
       9.00009001e+00, 1.00001000e+01]), array([ 1.625,  6.5  ,  6.   ,  5.5  , 10.   ]))
kwargs = {}
relevant_args = (array([1.00000000e-08, 5.00005010e-01, 2.00002001e+00, 3.00003001e+00,
       9.00009001e+00, 1.00001000e+01]), array([ 1.625,  6.5  ,  6.   ,  5.5  , 10.   ]))

>   ???

<__array_function__ internals>:6: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1.00000000e-08, 5.00005010e-01, 2.00002001e+00, 3.00003001e+00,
       9.00009001e+00, 1.00001000e+01])
bins = array([ 1.625,  6.5  ,  6.   ,  5.5  , 10.   ]), right = False

    @array_function_dispatch(_digitize_dispatcher)
    def digitize(x, bins, right=False):
        """
        Return the indices of the bins to which each value in input array belongs.
    
        =========  =============  ============================
        `right`    order of bins  returned index `i` satisfies
        =========  =============  ============================
        ``False``  increasing     ``bins[i-1] <= x < bins[i]``
        ``True``   increasing     ``bins[i-1] < x <= bins[i]``
        ``False``  decreasing     ``bins[i-1] > x >= bins[i]``
        ``True``   decreasing     ``bins[i-1] >= x > bins[i]``
        =========  =============  ============================
    
        If values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is
        returned as appropriate.
    
        Parameters
        ----------
        x : array_like
            Input array to be binned. Prior to NumPy 1.10.0, this array had to
            be 1-dimensional, but can now have any shape.
        bins : array_like
            Array of bins. It has to be 1-dimensional and monotonic.
        right : bool, optional
            Indicating whether the intervals include the right or the left bin
            edge. Default behavior is (right==False) indicating that the interval
            does not include the right edge. The left bin end is open in this
            case, i.e., bins[i-1] <= x < bins[i] is the default behavior for
            monotonically increasing bins.
    
        Returns
        -------
        indices : ndarray of ints
            Output array of indices, of same shape as `x`.
    
        Raises
        ------
        ValueError
            If `bins` is not monotonic.
        TypeError
            If the type of the input is complex.
    
        See Also
        --------
        bincount, histogram, unique, searchsorted
    
        Notes
        -----
        If values in `x` are such that they fall outside the bin range,
        attempting to index `bins` with the indices that `digitize` returns
        will result in an IndexError.
    
        .. versionadded:: 1.10.0
    
        `np.digitize` is  implemented in terms of `np.searchsorted`. This means
        that a binary search is used to bin the values, which scales much better
        for larger number of bins than the previous linear search. It also removes
        the requirement for the input array to be 1-dimensional.
    
        For monotonically _increasing_ `bins`, the following are equivalent::
    
            np.digitize(x, bins, right=True)
            np.searchsorted(bins, x, side='left')
    
        Note that as the order of the arguments are reversed, the side must be too.
        The `searchsorted` call is marginally faster, as it does not do any
        monotonicity checks. Perhaps more importantly, it supports all dtypes.
    
        Examples
        --------
        >>> x = np.array([0.2, 6.4, 3.0, 1.6])
        >>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])
        >>> inds = np.digitize(x, bins)
        >>> inds
        array([1, 4, 3, 2])
        >>> for n in range(x.size):
        ...   print(bins[inds[n]-1], "<=", x[n], "<", bins[inds[n]])
        ...
        0.0 <= 0.2 < 1.0
        4.0 <= 6.4 < 10.0
        2.5 <= 3.0 < 4.0
        1.0 <= 1.6 < 2.5
    
        >>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])
        >>> bins = np.array([0, 5, 10, 15, 20])
        >>> np.digitize(x,bins,right=True)
        array([1, 2, 3, 4, 4])
        >>> np.digitize(x,bins,right=False)
        array([1, 3, 3, 4, 5])
        """
        x = _nx.asarray(x)
        bins = _nx.asarray(bins)
    
        # here for compatibility, searchsorted below is happy to take this
        if np.issubdtype(x.dtype, _nx.complexfloating):
            raise TypeError("x may not be complex")
    
        mono = _monotonicity(bins)
        if mono == 0:
>           raise ValueError("bins must be monotonically increasing or decreasing")
E           ValueError: bins must be monotonically increasing or decreasing

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/lib/function_base.py:4778: ValueError

During handling of the above exception, another exception occurred:

    def test_kmeans_strategy_unsorted_bin_edges():
        # Test setup
        X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
        n_bins = 5
        est = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans', encode='ordinal')
    
        # Test that no ValueError is raised when bin_edges are sorted correctly
        try:
            est.fit_transform(X)
        except ValueError as e:
>           assert False, f"Unexpected ValueError raised: {e}"
E           AssertionError: Unexpected ValueError raised: bins must be monotonically increasing or decreasing
E           assert False

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py:15: AssertionError
----------------------------- Captured stdout call -----------------------------
0.70 /testbed/sklearn/preprocessing/_discretization.py(112):         self.n_bins = n_bins
0.70 /testbed/sklearn/preprocessing/_discretization.py(113):         self.encode = encode
0.70 /testbed/sklearn/preprocessing/_discretization.py(114):         self.strategy = strategy
0.70 /testbed/sklearn/preprocessing/_discretization.py(130):         X = check_array(X, dtype='numeric')
0.70 /testbed/sklearn/preprocessing/_discretization.py(132):         valid_encode = ('onehot', 'onehot-dense', 'ordinal')
0.70 /testbed/sklearn/preprocessing/_discretization.py(133):         if self.encode not in valid_encode:
0.70 /testbed/sklearn/preprocessing/_discretization.py(137):         valid_strategy = ('uniform', 'quantile', 'kmeans')
0.70 /testbed/sklearn/preprocessing/_discretization.py(138):         if self.strategy not in valid_strategy:
0.70 /testbed/sklearn/preprocessing/_discretization.py(143):         n_features = X.shape[1]
0.70 /testbed/sklearn/preprocessing/_discretization.py(144):         n_bins = self._validate_n_bins(n_features)
0.70 /testbed/sklearn/preprocessing/_discretization.py(194):         orig_bins = self.n_bins
0.70 /testbed/sklearn/preprocessing/_discretization.py(195):         if isinstance(orig_bins, numbers.Number):
0.70 /testbed/sklearn/preprocessing/_discretization.py(196):             if not isinstance(orig_bins, (numbers.Integral, np.integer)):
0.70 /testbed/sklearn/preprocessing/_discretization.py(201):             if orig_bins < 2:
0.70 /testbed/sklearn/preprocessing/_discretization.py(205):             return np.full(n_features, orig_bins, dtype=np.int)
0.70 /testbed/sklearn/preprocessing/_discretization.py(146):         bin_edges = np.zeros(n_features, dtype=object)
0.70 /testbed/sklearn/preprocessing/_discretization.py(147):         for jj in range(n_features):
0.70 /testbed/sklearn/preprocessing/_discretization.py(148):             column = X[:, jj]
0.70 /testbed/sklearn/preprocessing/_discretization.py(149):             col_min, col_max = column.min(), column.max()
0.70 /testbed/sklearn/preprocessing/_discretization.py(151):             if col_min == col_max:
0.70 /testbed/sklearn/preprocessing/_discretization.py(158):             if self.strategy == 'uniform':
0.70 /testbed/sklearn/preprocessing/_discretization.py(161):             elif self.strategy == 'quantile':
0.70 /testbed/sklearn/preprocessing/_discretization.py(165):             elif self.strategy == 'kmeans':
0.70 /testbed/sklearn/preprocessing/_discretization.py(166):                 from ..cluster import KMeans  # fixes import loops
0.85 /testbed/sklearn/preprocessing/_discretization.py(169):                 uniform_edges = np.linspace(col_min, col_max, n_bins[jj] + 1)
0.85 /testbed/sklearn/preprocessing/_discretization.py(170):                 init = (uniform_edges[1:] + uniform_edges[:-1])[:, None] * 0.5
0.85 /testbed/sklearn/preprocessing/_discretization.py(173):                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)
0.85 /testbed/sklearn/preprocessing/_discretization.py(174):                 centers = km.fit(column[:, None]).cluster_centers_[:, 0]
0.85 /testbed/sklearn/preprocessing/_discretization.py(175):                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5
0.85 /testbed/sklearn/preprocessing/_discretization.py(176):                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]
0.85 /testbed/sklearn/preprocessing/_discretization.py(147):         for jj in range(n_features):
0.85 /testbed/sklearn/preprocessing/_discretization.py(178):         self.bin_edges_ = bin_edges
0.85 /testbed/sklearn/preprocessing/_discretization.py(179):         self.n_bins_ = n_bins
0.85 /testbed/sklearn/preprocessing/_discretization.py(181):         if 'onehot' in self.encode:
0.85 /testbed/sklearn/preprocessing/_discretization.py(189):         return self
0.85 /testbed/sklearn/preprocessing/_discretization.py(238):         check_is_fitted(self, ["bin_edges_"])
0.85 /testbed/sklearn/preprocessing/_discretization.py(240):         Xt = check_array(X, copy=True, dtype=FLOAT_DTYPES)
0.85 /testbed/sklearn/preprocessing/_discretization.py(241):         n_features = self.n_bins_.shape[0]
0.85 /testbed/sklearn/preprocessing/_discretization.py(242):         if Xt.shape[1] != n_features:
0.85 /testbed/sklearn/preprocessing/_discretization.py(246):         bin_edges = self.bin_edges_
0.85 /testbed/sklearn/preprocessing/_discretization.py(247):         for jj in range(Xt.shape[1]):
0.85 /testbed/sklearn/preprocessing/_discretization.py(252):             rtol = 1.e-5
0.85 /testbed/sklearn/preprocessing/_discretization.py(253):             atol = 1.e-8
0.85 /testbed/sklearn/preprocessing/_discretization.py(254):             eps = atol + rtol * np.abs(Xt[:, jj])
0.85 /testbed/sklearn/preprocessing/_discretization.py(255):             Xt[:, jj] = np.digitize(Xt[:, jj] + eps, bin_edges[jj][1:])
=========================== short test summary info ============================
FAILED sklearn/tests/test_coverup_scikit-learn__scikit-learn-13135.py::test_kmeans_strategy_unsorted_bin_edges
============================== 1 failed in 0.89s ===============================
+ cat coverage.cover
{"/testbed/sklearn/preprocessing/_discretization.py": {"9": 1, "10": 1, "11": 1, "13": 1, "15": 1, "16": 1, "17": 1, "18": 1, "21": 2, "111": 1, "116": 1, "191": 1, "225": 1, "263": 1, "112": 1, "113": 1, "114": 1, "130": 1, "132": 1, "133": 1, "134": 0, "136": 0, "137": 1, "138": 1, "139": 0, "141": 0, "143": 1, "144": 1, "146": 1, "147": 2, "148": 1, "149": 1, "151": 1, "152": 0, "153": 0, "154": 0, "155": 0, "156": 0, "158": 1, "159": 0, "161": 1, "162": 0, "163": 0, "165": 1, "166": 1, "169": 1, "170": 1, "173": 1, "174": 1, "175": 1, "176": 1, "178": 1, "179": 1, "181": 1, "182": 0, "183": 0, "184": 0, "187": 0, "189": 1, "194": 1, "195": 1, "196": 1, "197": 0, "199": 0, "200": 0, "201": 1, "202": 0, "204": 0, "205": 1, "207": 0, "208": 0, "210": 0, "211": 0, "214": 0, "216": 0, "217": 0, "218": 0, "219": 0, "222": 0, "223": 0, "238": 1, "240": 1, "241": 1, "242": 1, "243": 0, "244": 0, "246": 1, "247": 1, "252": 1, "253": 1, "254": 1, "255": 1, "256": 0, "258": 0, "259": 0, "261": 0, "279": 0, "281": 0, "282": 0, "284": 0, "285": 0, "286": 0, "287": 0, "288": 0, "290": 0, "291": 0, "292": 0, "293": 0, "295": 0}}
+ git checkout a061ada48efccf0845acae17009553e01764452b
Note: switching to 'a061ada48efccf0845acae17009553e01764452b'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at a061ada48e FEA Print Decision Trees in ASCII format (#9424)
+ git apply /root/pre_state.patch
error: unrecognized input
