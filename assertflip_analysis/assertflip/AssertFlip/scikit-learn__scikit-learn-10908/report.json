{
    "scikit-learn__scikit-learn-10908": {
        "patch_is_None": false,
        "patch_exists": true,
        "patch_successfully_applied": true,
        "resolved": true,
        "coverage_pred": 0.0,
        "coverage_gold": 1.0,
        "coverage_base": 0.0,
        "coverage_delta_pred": 0.0,
        "coverage_delta_gold": 1.0,
        "added_f2p": 1,
        "tests_base": {
            "FAIL_TO_PASS": [],
            "PASS_TO_PASS": [],
            "FAIL_TO_FAIL": [
                "file"
            ],
            "PASS_TO_FAIL": [],
            "UNMATCHED": []
        },
        "tests_pred": {
            "FAIL_TO_PASS": [
                "sklearn/tests/test_coverup_scikit-learn__scikit-learn-10908.py::test_get_feature_names_with_vocabulary_does_not_raise_not_fitted_error"
            ],
            "PASS_TO_PASS": [],
            "FAIL_TO_FAIL": [],
            "PASS_TO_FAIL": [],
            "UNMATCHED": []
        },
        "tests_gold": {
            "FAIL_TO_PASS": [
                "sklearn/feature_extraction/tests/test_text.py::test_feature_names"
            ],
            "PASS_TO_PASS": [
                "sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams",
                "sklearn/feature_extraction/tests/test_text.py::test_non_unique_vocab",
                "sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_pipeline_grid_selection",
                "sklearn/feature_extraction/tests/test_text.py::test_hashingvectorizer_nan_in_docs",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1]",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_stop_words",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform",
                "sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_with_fixed_vocabulary",
                "sklearn/feature_extraction/tests/test_text.py::test_strip_accents",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_gap_index",
                "sklearn/feature_extraction/tests/test_text.py::test_tfidf_no_smoothing",
                "sklearn/feature_extraction/tests/test_text.py::test_word_ngram_analyzer",
                "sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams_and_bigrams",
                "sklearn/feature_extraction/tests/test_text.py::test_stop_words_removal",
                "sklearn/feature_extraction/tests/test_text.py::test_sublinear_tf",
                "sklearn/feature_extraction/tests/test_text.py::test_char_ngram_analyzer",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_repeated_indices",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_pipeline",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_empty_vocabulary",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_unicode",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_grid_selection",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer",
                "sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setters",
                "sklearn/feature_extraction/tests/test_text.py::test_hashing_vectorizer",
                "sklearn/feature_extraction/tests/test_text.py::test_count_binary_occurrences",
                "sklearn/feature_extraction/tests/test_text.py::test_pickling_vectorizer",
                "sklearn/feature_extraction/tests/test_text.py::test_fit_countvectorizer_twice",
                "sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_binary",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_df",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input",
                "sklearn/feature_extraction/tests/test_text.py::test_pickling_transformer",
                "sklearn/feature_extraction/tests/test_text.py::test_tf_idf_smoothing",
                "sklearn/feature_extraction/tests/test_text.py::test_char_wb_ngram_analyzer",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec0]",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_vocab_clone",
                "sklearn/feature_extraction/tests/test_text.py::test_unicode_decode_error",
                "sklearn/feature_extraction/tests/test_text.py::test_hashed_binary_occurrences",
                "sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_max_features",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_sets_when_pickling",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_min_df",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_dicts_when_pickling",
                "sklearn/feature_extraction/tests/test_text.py::test_to_ascii",
                "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_cross_validation",
                "sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_export_idf",
                "sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2]"
            ],
            "FAIL_TO_FAIL": [],
            "PASS_TO_FAIL": [],
            "UNMATCHED": []
        }
    }
}