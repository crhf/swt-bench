+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD 3eacf948e0f95ef957862568d87ce082f378e186
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit 3eacf948e0f95ef957862568d87ce082f378e186
Author: Stephen Tierney <sjtrny@gmail.com>
Date:   Mon Aug 12 22:23:07 2019 +1000

    Set diagonal of precomputed matrix to zero in silhoutte_samples (#12258)

diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst
index 188e52a27d..7be27894ab 100644
--- a/doc/whats_new/v0.22.rst
+++ b/doc/whats_new/v0.22.rst
@@ -224,8 +224,15 @@ Changelog
   to return root mean squared error.
   :pr:`13467` by :user:`Urvang Patel <urvang96>`.
 
+:mod:`sklearn.metrics`
+......................
+
+- |Fix| Raise a ValueError in :func:`metrics.silhouette_score` when a
+  precomputed distance matrix contains non-zero diagonal entries.
+  :pr:`12258` by :user:`Stephen Tierney <sjtrny>`.
+
 :mod:`sklearn.model_selection`
-...............................
+..............................
 
 - |Enhancement| :class:`model_selection.learning_curve` now accepts parameter
   ``return_times`` which can be used to retrieve computation times in order to
diff --git a/sklearn/metrics/cluster/tests/test_unsupervised.py b/sklearn/metrics/cluster/tests/test_unsupervised.py
index 02a4e85501..8e88247db7 100644
--- a/sklearn/metrics/cluster/tests/test_unsupervised.py
+++ b/sklearn/metrics/cluster/tests/test_unsupervised.py
@@ -168,6 +168,22 @@ def test_non_numpy_labels():
         silhouette_score(list(X), list(y)) == silhouette_score(X, y))
 
 
+def test_silhouette_nonzero_diag():
+    # Construct a zero-diagonal matrix
+    dists = pairwise_distances(
+        np.array([[0.2, 0.1, 0.12, 1.34, 1.11, 1.6]]).transpose())
+
+    # Construct a nonzero-diagonal distance matrix
+    diag_dists = dists.copy()
+    np.fill_diagonal(diag_dists, 1)
+
+    labels = [0, 0, 0, 1, 1, 1]
+
+    assert_raise_message(ValueError, "distance matrix contains non-zero",
+                         silhouette_samples,
+                         diag_dists, labels, metric='precomputed')
+
+
 def assert_raises_on_only_one_label(func):
     """Assert message when there is only one label"""
     rng = np.random.RandomState(seed=0)
diff --git a/sklearn/metrics/cluster/unsupervised.py b/sklearn/metrics/cluster/unsupervised.py
index 05206ab42a..0e12c06b41 100644
--- a/sklearn/metrics/cluster/unsupervised.py
+++ b/sklearn/metrics/cluster/unsupervised.py
@@ -185,7 +185,8 @@ def silhouette_samples(X, labels, metric='euclidean', **kwds):
         The metric to use when calculating distance between instances in a
         feature array. If metric is a string, it must be one of the options
         allowed by :func:`sklearn.metrics.pairwise.pairwise_distances`. If X is
-        the distance array itself, use "precomputed" as the metric.
+        the distance array itself, use "precomputed" as the metric. Precomputed
+        distance matrices must have 0 along the diagonal.
 
     `**kwds` : optional keyword parameters
         Any further parameters are passed directly to the distance function.
@@ -210,6 +211,15 @@ def silhouette_samples(X, labels, metric='euclidean', **kwds):
 
     """
     X, labels = check_X_y(X, labels, accept_sparse=['csc', 'csr'])
+
+    # Check for diagonal entries in precomputed distance matrix
+    if metric == 'precomputed':
+        if np.any(np.diagonal(X)):
+            raise ValueError(
+                'The precomputed distance matrix contains non-zero '
+                'elements on the diagonal. Use np.fill_diagonal(X, 0).'
+            )
+
     le = LabelEncoder()
     labels = le.fit_transform(labels)
     n_samples = len(labels)
+ git diff 3eacf948e0f95ef957862568d87ce082f378e186
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-i0ns8b41/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.5.2)
Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.1.1)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.22.dev0
    Uninstalling scikit-learn-0.22.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.22.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    compile options: '-c'
    extra options: '-fopenmp'
    gcc: test_openmp.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ objects/test_openmp.o -o test_openmp -fopenmp
    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.histogram" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.splitting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._binning" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._predictor" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._loss" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.types" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.utils" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn._isotonic" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.22.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.22.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git apply -v -
Checking patch sklearn/cluster/k_means_.py...
Applied patch sklearn/cluster/k_means_.py cleanly.
+ git apply -v -
Checking patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-9288.py...
Applied patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-9288.py cleanly.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(sklearn/cluster/k_means_\.py)' -m pytest --no-header -rA -p no:cacheprovider sklearn/tests/test_coverup_scikit-learn__scikit-learn-9288.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(sklearn/cluster/k_means_\\.py)']
============================= test session starts ==============================
collected 1 item

sklearn/tests/test_coverup_scikit-learn__scikit-learn-9288.py .          [100%]

==================================== PASSES ====================================
__________________ test_kmeans_inertia_with_different_n_jobs ___________________
----------------------------- Captured stdout call -----------------------------
0.79 k_means_.py(913):         self.n_clusters = n_clusters
0.79 k_means_.py(914):         self.init = init
0.79 k_means_.py(915):         self.max_iter = max_iter
0.79 k_means_.py(916):         self.tol = tol
0.79 k_means_.py(917):         self.precompute_distances = precompute_distances
0.79 k_means_.py(918):         self.n_init = n_init
0.79 k_means_.py(919):         self.verbose = verbose
0.79 k_means_.py(920):         self.random_state = random_state
0.79 k_means_.py(921):         self.copy_x = copy_x
0.79 k_means_.py(922):         self.n_jobs = n_jobs
0.79 k_means_.py(923):         self.algorithm = algorithm
0.79 k_means_.py(954):         random_state = check_random_state(self.random_state)
0.79 k_means_.py(957):             k_means(
0.79 k_means_.py(958):                 X, n_clusters=self.n_clusters, sample_weight=sample_weight,
0.79 k_means_.py(959):                 init=self.init, n_init=self.n_init,
0.79 k_means_.py(960):                 max_iter=self.max_iter, verbose=self.verbose,
0.79 k_means_.py(961):                 precompute_distances=self.precompute_distances,
0.79 k_means_.py(962):                 tol=self.tol, random_state=random_state, copy_x=self.copy_x,
0.79 k_means_.py(963):                 n_jobs=self.n_jobs, algorithm=self.algorithm,
0.79 k_means_.py(964):                 return_n_iter=True)
0.79 k_means_.py(291):     if n_init <= 0:
0.79 k_means_.py(294):     random_state = check_random_state(random_state)
0.79 k_means_.py(296):     if max_iter <= 0:
0.79 k_means_.py(301):     order = "C" if copy_x else None
0.79 k_means_.py(302):     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],
0.79 k_means_.py(303):                     order=order, copy=copy_x)
0.79 k_means_.py(305):     if _num_samples(X) < n_clusters:
0.79 k_means_.py(309):     tol = _tolerance(X, tol)
0.79 k_means_.py(156):     if sp.issparse(X):
0.79 k_means_.py(159):         variances = np.var(X, axis=0)
0.79 k_means_.py(160):     return np.mean(variances) * tol
0.79 k_means_.py(315):     if precompute_distances == 'auto':
0.79 k_means_.py(316):         n_samples = X.shape[0]
0.79 k_means_.py(317):         precompute_distances = (n_clusters * n_samples) < 12e6
0.79 k_means_.py(326):     if hasattr(init, '__array__'):
0.79 k_means_.py(338):     if not sp.issparse(X):
0.79 k_means_.py(339):         X_mean = X.mean(axis=0)
0.79 k_means_.py(341):         X -= X_mean
0.79 k_means_.py(343):         if hasattr(init, '__array__'):
0.79 k_means_.py(347):     x_squared_norms = row_norms(X, squared=True)
0.79 k_means_.py(349):     best_labels, best_inertia, best_centers = None, None, None
0.79 k_means_.py(350):     if n_clusters == 1:
0.79 k_means_.py(354):     if algorithm == "auto":
0.79 k_means_.py(355):         algorithm = "full" if sp.issparse(X) else 'elkan'
0.79 k_means_.py(356):     if algorithm == "full":
0.79 k_means_.py(358):     elif algorithm == "elkan":
0.79 k_means_.py(359):         kmeans_single = _kmeans_single_elkan
0.79 k_means_.py(364):     seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
0.79 k_means_.py(365):     if effective_n_jobs(n_jobs) == 1:
0.79 k_means_.py(368):         for seed in seeds:
0.79 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.79 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.79 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.79 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.79 k_means_.py(374):                 random_state=seed)
0.79 k_means_.py(422):     if sp.issparse(X):
0.79 k_means_.py(424):     random_state = check_random_state(random_state)
0.79 k_means_.py(425):     if x_squared_norms is None:
0.79 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.79 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.79 k_means_.py(718):     random_state = check_random_state(random_state)
0.79 k_means_.py(719):     n_samples = X.shape[0]
0.79 k_means_.py(721):     if x_squared_norms is None:
0.79 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.79 k_means_.py(735):     elif n_samples < k:
0.79 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.79 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.79 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.79 k_means_.py(77):     n_samples, n_features = X.shape
0.79 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.79 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.79 k_means_.py(84):     if n_local_trials is None:
0.79 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.79 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.79 k_means_.py(92):     if sp.issparse(X):
0.79 k_means_.py(95):         centers[0] = X[center_id]
0.79 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.79 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.79 k_means_.py(100):         squared=True)
0.79 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.79 k_means_.py(104):     for c in range(1, n_clusters):
0.79 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.79 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.79 k_means_.py(109):                                         rand_vals)
0.79 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.79 k_means_.py(112):                 out=candidate_ids)
0.79 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.79 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.79 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.79 k_means_.py(120):                    out=distance_to_candidates)
0.79 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.79 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.79 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.79 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.79 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.79 k_means_.py(130):         if sp.issparse(X):
0.79 k_means_.py(133):             centers[c] = X[best_candidate]
0.79 k_means_.py(104):     for c in range(1, n_clusters):
0.79 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.79 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.79 k_means_.py(109):                                         rand_vals)
0.79 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.79 k_means_.py(112):                 out=candidate_ids)
0.79 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.79 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.79 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.79 k_means_.py(120):                    out=distance_to_candidates)
0.79 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.79 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.79 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.79 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.79 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.79 k_means_.py(130):         if sp.issparse(X):
0.79 k_means_.py(133):             centers[c] = X[best_candidate]
0.79 k_means_.py(104):     for c in range(1, n_clusters):
0.79 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.79 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.79 k_means_.py(109):                                         rand_vals)
0.79 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.79 k_means_.py(112):                 out=candidate_ids)
0.79 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.79 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.79 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.79 k_means_.py(120):                    out=distance_to_candidates)
0.79 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.79 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.79 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.79 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.79 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.79 k_means_.py(130):         if sp.issparse(X):
0.79 k_means_.py(133):             centers[c] = X[best_candidate]
0.79 k_means_.py(104):     for c in range(1, n_clusters):
0.79 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.79 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.79 k_means_.py(109):                                         rand_vals)
0.79 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.79 k_means_.py(112):                 out=candidate_ids)
0.79 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.79 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.79 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.79 k_means_.py(120):                    out=distance_to_candidates)
0.79 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.79 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.79 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.79 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.79 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.79 k_means_.py(130):         if sp.issparse(X):
0.79 k_means_.py(133):             centers[c] = X[best_candidate]
0.79 k_means_.py(104):     for c in range(1, n_clusters):
0.79 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.79 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.79 k_means_.py(109):                                         rand_vals)
0.79 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.79 k_means_.py(112):                 out=candidate_ids)
0.79 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.79 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.80 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.80 k_means_.py(120):                    out=distance_to_candidates)
0.80 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.80 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.80 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.80 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.80 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.80 k_means_.py(130):         if sp.issparse(X):
0.80 k_means_.py(133):             centers[c] = X[best_candidate]
0.80 k_means_.py(104):     for c in range(1, n_clusters):
0.80 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.80 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.80 k_means_.py(109):                                         rand_vals)
0.80 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.80 k_means_.py(112):                 out=candidate_ids)
0.80 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.80 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.80 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.80 k_means_.py(120):                    out=distance_to_candidates)
0.80 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.80 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.80 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.80 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.80 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.80 k_means_.py(130):         if sp.issparse(X):
0.80 k_means_.py(133):             centers[c] = X[best_candidate]
0.80 k_means_.py(104):     for c in range(1, n_clusters):
0.80 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.80 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.80 k_means_.py(109):                                         rand_vals)
0.80 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.80 k_means_.py(112):                 out=candidate_ids)
0.80 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.80 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.80 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.80 k_means_.py(120):                    out=distance_to_candidates)
0.80 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.80 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.80 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.80 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.80 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.80 k_means_.py(130):         if sp.issparse(X):
0.80 k_means_.py(133):             centers[c] = X[best_candidate]
0.80 k_means_.py(104):     for c in range(1, n_clusters):
0.80 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.80 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.80 k_means_.py(109):                                         rand_vals)
0.80 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.80 k_means_.py(112):                 out=candidate_ids)
0.80 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.80 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.80 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.80 k_means_.py(120):                    out=distance_to_candidates)
0.80 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.80 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.80 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.80 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.80 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.80 k_means_.py(130):         if sp.issparse(X):
0.80 k_means_.py(133):             centers[c] = X[best_candidate]
0.80 k_means_.py(104):     for c in range(1, n_clusters):
0.80 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.80 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.80 k_means_.py(109):                                         rand_vals)
0.80 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.80 k_means_.py(112):                 out=candidate_ids)
0.80 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.80 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.80 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.80 k_means_.py(120):                    out=distance_to_candidates)
0.80 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.80 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.80 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.80 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.80 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.80 k_means_.py(130):         if sp.issparse(X):
0.80 k_means_.py(133):             centers[c] = X[best_candidate]
0.80 k_means_.py(104):     for c in range(1, n_clusters):
0.80 k_means_.py(135):     return centers
0.80 k_means_.py(757):     if sp.issparse(centers):
0.80 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.80 k_means_.py(143):     if len(centers) != n_centers:
0.80 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.80 k_means_.py(761):     return centers
0.80 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.80 k_means_.py(431):     if verbose:
0.80 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.80 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.80 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.80 k_means_.py(169):     if not sample_weight_was_none:
0.80 k_means_.py(175):     return sample_weight
0.80 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.80 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.80 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.81 k_means_.py(438):     if sample_weight is None:
0.81 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.81 k_means_.py(444):     return labels, inertia, centers, n_iter
0.81 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.81 k_means_.py(377):                 best_labels = labels.copy()
0.81 k_means_.py(378):                 best_centers = centers.copy()
0.81 k_means_.py(379):                 best_inertia = inertia
0.81 k_means_.py(380):                 best_n_iter = n_iter_
0.81 k_means_.py(368):         for seed in seeds:
0.81 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.81 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.81 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.81 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.81 k_means_.py(374):                 random_state=seed)
0.81 k_means_.py(422):     if sp.issparse(X):
0.81 k_means_.py(424):     random_state = check_random_state(random_state)
0.81 k_means_.py(425):     if x_squared_norms is None:
0.81 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.81 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.81 k_means_.py(718):     random_state = check_random_state(random_state)
0.81 k_means_.py(719):     n_samples = X.shape[0]
0.81 k_means_.py(721):     if x_squared_norms is None:
0.81 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.81 k_means_.py(735):     elif n_samples < k:
0.81 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.81 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.81 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.81 k_means_.py(77):     n_samples, n_features = X.shape
0.81 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.81 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.81 k_means_.py(84):     if n_local_trials is None:
0.81 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.81 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.81 k_means_.py(92):     if sp.issparse(X):
0.81 k_means_.py(95):         centers[0] = X[center_id]
0.81 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.81 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.81 k_means_.py(100):         squared=True)
0.81 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.81 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.81 k_means_.py(120):                    out=distance_to_candidates)
0.81 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.81 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.81 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.81 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.81 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.81 k_means_.py(130):         if sp.issparse(X):
0.81 k_means_.py(133):             centers[c] = X[best_candidate]
0.81 k_means_.py(104):     for c in range(1, n_clusters):
0.81 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.81 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.81 k_means_.py(109):                                         rand_vals)
0.81 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.81 k_means_.py(112):                 out=candidate_ids)
0.81 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.81 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.82 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.82 k_means_.py(120):                    out=distance_to_candidates)
0.82 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.82 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.82 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.82 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.82 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.82 k_means_.py(130):         if sp.issparse(X):
0.82 k_means_.py(133):             centers[c] = X[best_candidate]
0.82 k_means_.py(104):     for c in range(1, n_clusters):
0.82 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.82 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.82 k_means_.py(109):                                         rand_vals)
0.82 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.82 k_means_.py(112):                 out=candidate_ids)
0.82 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.82 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.82 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.82 k_means_.py(120):                    out=distance_to_candidates)
0.82 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.82 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.82 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.82 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.82 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.82 k_means_.py(130):         if sp.issparse(X):
0.82 k_means_.py(133):             centers[c] = X[best_candidate]
0.82 k_means_.py(104):     for c in range(1, n_clusters):
0.82 k_means_.py(135):     return centers
0.82 k_means_.py(757):     if sp.issparse(centers):
0.82 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.82 k_means_.py(143):     if len(centers) != n_centers:
0.82 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.82 k_means_.py(761):     return centers
0.82 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.82 k_means_.py(431):     if verbose:
0.82 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.82 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.82 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.82 k_means_.py(169):     if not sample_weight_was_none:
0.82 k_means_.py(175):     return sample_weight
0.82 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.82 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.82 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.83 k_means_.py(438):     if sample_weight is None:
0.83 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.83 k_means_.py(444):     return labels, inertia, centers, n_iter
0.83 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.83 k_means_.py(368):         for seed in seeds:
0.83 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.83 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.83 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.83 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.83 k_means_.py(374):                 random_state=seed)
0.83 k_means_.py(422):     if sp.issparse(X):
0.83 k_means_.py(424):     random_state = check_random_state(random_state)
0.83 k_means_.py(425):     if x_squared_norms is None:
0.83 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.83 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.83 k_means_.py(718):     random_state = check_random_state(random_state)
0.83 k_means_.py(719):     n_samples = X.shape[0]
0.83 k_means_.py(721):     if x_squared_norms is None:
0.83 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.83 k_means_.py(735):     elif n_samples < k:
0.83 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.83 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.83 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.83 k_means_.py(77):     n_samples, n_features = X.shape
0.83 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.83 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.83 k_means_.py(84):     if n_local_trials is None:
0.83 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.83 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.83 k_means_.py(92):     if sp.issparse(X):
0.83 k_means_.py(95):         centers[0] = X[center_id]
0.83 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.83 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.83 k_means_.py(100):         squared=True)
0.83 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.83 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.83 k_means_.py(120):                    out=distance_to_candidates)
0.83 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.83 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.83 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.83 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.83 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.83 k_means_.py(130):         if sp.issparse(X):
0.83 k_means_.py(133):             centers[c] = X[best_candidate]
0.83 k_means_.py(104):     for c in range(1, n_clusters):
0.83 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.83 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.83 k_means_.py(109):                                         rand_vals)
0.83 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.83 k_means_.py(112):                 out=candidate_ids)
0.83 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.83 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.84 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.84 k_means_.py(120):                    out=distance_to_candidates)
0.84 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.84 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.84 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.84 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.84 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.84 k_means_.py(130):         if sp.issparse(X):
0.84 k_means_.py(133):             centers[c] = X[best_candidate]
0.84 k_means_.py(104):     for c in range(1, n_clusters):
0.84 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.84 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.84 k_means_.py(109):                                         rand_vals)
0.84 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.84 k_means_.py(112):                 out=candidate_ids)
0.84 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.84 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.84 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.84 k_means_.py(120):                    out=distance_to_candidates)
0.84 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.84 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.84 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.84 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.84 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.84 k_means_.py(130):         if sp.issparse(X):
0.84 k_means_.py(133):             centers[c] = X[best_candidate]
0.84 k_means_.py(104):     for c in range(1, n_clusters):
0.84 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.84 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.84 k_means_.py(109):                                         rand_vals)
0.84 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.84 k_means_.py(112):                 out=candidate_ids)
0.84 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.84 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.84 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.84 k_means_.py(120):                    out=distance_to_candidates)
0.84 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.84 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.84 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.84 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.84 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.84 k_means_.py(130):         if sp.issparse(X):
0.84 k_means_.py(133):             centers[c] = X[best_candidate]
0.84 k_means_.py(104):     for c in range(1, n_clusters):
0.84 k_means_.py(135):     return centers
0.84 k_means_.py(757):     if sp.issparse(centers):
0.84 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.84 k_means_.py(143):     if len(centers) != n_centers:
0.84 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.84 k_means_.py(761):     return centers
0.84 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.84 k_means_.py(431):     if verbose:
0.84 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.84 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.84 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.84 k_means_.py(169):     if not sample_weight_was_none:
0.84 k_means_.py(175):     return sample_weight
0.84 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.84 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.84 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.85 k_means_.py(438):     if sample_weight is None:
0.85 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.85 k_means_.py(444):     return labels, inertia, centers, n_iter
0.85 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.85 k_means_.py(368):         for seed in seeds:
0.85 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.85 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.85 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.85 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.85 k_means_.py(374):                 random_state=seed)
0.85 k_means_.py(422):     if sp.issparse(X):
0.85 k_means_.py(424):     random_state = check_random_state(random_state)
0.85 k_means_.py(425):     if x_squared_norms is None:
0.85 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.85 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.85 k_means_.py(718):     random_state = check_random_state(random_state)
0.85 k_means_.py(719):     n_samples = X.shape[0]
0.85 k_means_.py(721):     if x_squared_norms is None:
0.85 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.85 k_means_.py(735):     elif n_samples < k:
0.85 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.85 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.85 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.85 k_means_.py(77):     n_samples, n_features = X.shape
0.85 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.85 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.85 k_means_.py(84):     if n_local_trials is None:
0.85 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.85 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.85 k_means_.py(92):     if sp.issparse(X):
0.85 k_means_.py(95):         centers[0] = X[center_id]
0.85 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.85 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.85 k_means_.py(100):         squared=True)
0.85 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.85 k_means_.py(104):     for c in range(1, n_clusters):
0.85 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.85 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.85 k_means_.py(109):                                         rand_vals)
0.85 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.85 k_means_.py(112):                 out=candidate_ids)
0.85 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.85 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.85 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.85 k_means_.py(120):                    out=distance_to_candidates)
0.85 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.85 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.85 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.85 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.85 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.85 k_means_.py(130):         if sp.issparse(X):
0.85 k_means_.py(133):             centers[c] = X[best_candidate]
0.85 k_means_.py(104):     for c in range(1, n_clusters):
0.85 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.85 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.85 k_means_.py(109):                                         rand_vals)
0.85 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.85 k_means_.py(112):                 out=candidate_ids)
0.85 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.85 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.85 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.85 k_means_.py(120):                    out=distance_to_candidates)
0.85 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.85 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.85 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.85 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.85 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.85 k_means_.py(130):         if sp.issparse(X):
0.85 k_means_.py(133):             centers[c] = X[best_candidate]
0.85 k_means_.py(104):     for c in range(1, n_clusters):
0.85 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.85 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.85 k_means_.py(109):                                         rand_vals)
0.85 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.85 k_means_.py(112):                 out=candidate_ids)
0.85 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.85 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.86 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.86 k_means_.py(109):                                         rand_vals)
0.86 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.86 k_means_.py(112):                 out=candidate_ids)
0.86 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.86 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.86 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.86 k_means_.py(120):                    out=distance_to_candidates)
0.86 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.86 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.86 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.86 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.86 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.86 k_means_.py(130):         if sp.issparse(X):
0.86 k_means_.py(133):             centers[c] = X[best_candidate]
0.86 k_means_.py(104):     for c in range(1, n_clusters):
0.86 k_means_.py(135):     return centers
0.86 k_means_.py(757):     if sp.issparse(centers):
0.86 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.86 k_means_.py(143):     if len(centers) != n_centers:
0.86 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.86 k_means_.py(761):     return centers
0.86 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.86 k_means_.py(431):     if verbose:
0.86 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.86 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.86 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.86 k_means_.py(169):     if not sample_weight_was_none:
0.86 k_means_.py(175):     return sample_weight
0.86 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.86 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.86 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.89 k_means_.py(438):     if sample_weight is None:
0.89 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.89 k_means_.py(444):     return labels, inertia, centers, n_iter
0.89 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.89 k_means_.py(368):         for seed in seeds:
0.89 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.89 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.89 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.89 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.89 k_means_.py(374):                 random_state=seed)
0.89 k_means_.py(422):     if sp.issparse(X):
0.89 k_means_.py(424):     random_state = check_random_state(random_state)
0.89 k_means_.py(425):     if x_squared_norms is None:
0.89 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.89 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.89 k_means_.py(718):     random_state = check_random_state(random_state)
0.89 k_means_.py(719):     n_samples = X.shape[0]
0.89 k_means_.py(721):     if x_squared_norms is None:
0.89 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.89 k_means_.py(735):     elif n_samples < k:
0.89 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.89 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.89 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.89 k_means_.py(77):     n_samples, n_features = X.shape
0.89 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.89 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.89 k_means_.py(84):     if n_local_trials is None:
0.89 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.89 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.89 k_means_.py(92):     if sp.issparse(X):
0.89 k_means_.py(95):         centers[0] = X[center_id]
0.89 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.89 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.89 k_means_.py(100):         squared=True)
0.89 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.89 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.89 k_means_.py(120):                    out=distance_to_candidates)
0.89 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.89 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.89 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.89 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.89 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.89 k_means_.py(130):         if sp.issparse(X):
0.89 k_means_.py(133):             centers[c] = X[best_candidate]
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.89 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.89 k_means_.py(120):                    out=distance_to_candidates)
0.89 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.89 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.89 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.89 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.89 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.89 k_means_.py(130):         if sp.issparse(X):
0.89 k_means_.py(133):             centers[c] = X[best_candidate]
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.89 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.89 k_means_.py(120):                    out=distance_to_candidates)
0.89 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.89 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.89 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.89 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.89 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.89 k_means_.py(130):         if sp.issparse(X):
0.89 k_means_.py(133):             centers[c] = X[best_candidate]
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.89 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.89 k_means_.py(120):                    out=distance_to_candidates)
0.89 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.89 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.89 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.89 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.89 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.89 k_means_.py(130):         if sp.issparse(X):
0.89 k_means_.py(133):             centers[c] = X[best_candidate]
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.89 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.89 k_means_.py(120):                    out=distance_to_candidates)
0.89 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.89 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.89 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.89 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.89 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.89 k_means_.py(130):         if sp.issparse(X):
0.89 k_means_.py(133):             centers[c] = X[best_candidate]
0.89 k_means_.py(104):     for c in range(1, n_clusters):
0.89 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.89 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.89 k_means_.py(109):                                         rand_vals)
0.89 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.89 k_means_.py(112):                 out=candidate_ids)
0.89 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.89 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.90 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.90 k_means_.py(120):                    out=distance_to_candidates)
0.90 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.90 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.90 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.90 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.90 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.90 k_means_.py(130):         if sp.issparse(X):
0.90 k_means_.py(133):             centers[c] = X[best_candidate]
0.90 k_means_.py(104):     for c in range(1, n_clusters):
0.90 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.90 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.90 k_means_.py(109):                                         rand_vals)
0.90 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.90 k_means_.py(112):                 out=candidate_ids)
0.90 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.90 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.90 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.90 k_means_.py(120):                    out=distance_to_candidates)
0.90 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.90 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.90 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.90 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.90 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.90 k_means_.py(130):         if sp.issparse(X):
0.90 k_means_.py(133):             centers[c] = X[best_candidate]
0.90 k_means_.py(104):     for c in range(1, n_clusters):
0.90 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.90 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.90 k_means_.py(109):                                         rand_vals)
0.90 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.90 k_means_.py(112):                 out=candidate_ids)
0.90 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.90 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.90 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.90 k_means_.py(120):                    out=distance_to_candidates)
0.90 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.90 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.90 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.90 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.90 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.90 k_means_.py(130):         if sp.issparse(X):
0.90 k_means_.py(133):             centers[c] = X[best_candidate]
0.90 k_means_.py(104):     for c in range(1, n_clusters):
0.90 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.90 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.90 k_means_.py(109):                                         rand_vals)
0.90 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.90 k_means_.py(112):                 out=candidate_ids)
0.90 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.90 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.90 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.90 k_means_.py(120):                    out=distance_to_candidates)
0.90 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.90 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.90 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.90 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.90 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.90 k_means_.py(130):         if sp.issparse(X):
0.90 k_means_.py(133):             centers[c] = X[best_candidate]
0.90 k_means_.py(104):     for c in range(1, n_clusters):
0.90 k_means_.py(135):     return centers
0.90 k_means_.py(757):     if sp.issparse(centers):
0.90 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.90 k_means_.py(143):     if len(centers) != n_centers:
0.90 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.90 k_means_.py(761):     return centers
0.90 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.90 k_means_.py(431):     if verbose:
0.90 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.90 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.90 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.90 k_means_.py(169):     if not sample_weight_was_none:
0.90 k_means_.py(175):     return sample_weight
0.90 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.90 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.90 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.91 k_means_.py(438):     if sample_weight is None:
0.91 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.91 k_means_.py(444):     return labels, inertia, centers, n_iter
0.91 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.91 k_means_.py(377):                 best_labels = labels.copy()
0.91 k_means_.py(378):                 best_centers = centers.copy()
0.91 k_means_.py(379):                 best_inertia = inertia
0.91 k_means_.py(380):                 best_n_iter = n_iter_
0.91 k_means_.py(368):         for seed in seeds:
0.91 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.91 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.91 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.91 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.91 k_means_.py(374):                 random_state=seed)
0.91 k_means_.py(422):     if sp.issparse(X):
0.91 k_means_.py(424):     random_state = check_random_state(random_state)
0.91 k_means_.py(425):     if x_squared_norms is None:
0.91 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.91 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.91 k_means_.py(718):     random_state = check_random_state(random_state)
0.91 k_means_.py(719):     n_samples = X.shape[0]
0.91 k_means_.py(721):     if x_squared_norms is None:
0.91 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.91 k_means_.py(735):     elif n_samples < k:
0.91 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.91 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.91 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.91 k_means_.py(77):     n_samples, n_features = X.shape
0.91 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.91 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.91 k_means_.py(84):     if n_local_trials is None:
0.91 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.91 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.91 k_means_.py(92):     if sp.issparse(X):
0.91 k_means_.py(95):         centers[0] = X[center_id]
0.91 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.91 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.91 k_means_.py(100):         squared=True)
0.91 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.91 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.91 k_means_.py(120):                    out=distance_to_candidates)
0.91 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.91 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.91 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.91 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.91 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.91 k_means_.py(130):         if sp.issparse(X):
0.91 k_means_.py(133):             centers[c] = X[best_candidate]
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.91 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.91 k_means_.py(120):                    out=distance_to_candidates)
0.91 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.91 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.91 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.91 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.91 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.91 k_means_.py(130):         if sp.issparse(X):
0.91 k_means_.py(133):             centers[c] = X[best_candidate]
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.91 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.91 k_means_.py(120):                    out=distance_to_candidates)
0.91 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.91 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.91 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.91 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.91 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.91 k_means_.py(130):         if sp.issparse(X):
0.91 k_means_.py(133):             centers[c] = X[best_candidate]
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.91 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.91 k_means_.py(120):                    out=distance_to_candidates)
0.91 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.91 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.91 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.91 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.91 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.91 k_means_.py(130):         if sp.issparse(X):
0.91 k_means_.py(133):             centers[c] = X[best_candidate]
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.91 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.91 k_means_.py(120):                    out=distance_to_candidates)
0.91 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.91 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.91 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.91 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.91 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.91 k_means_.py(130):         if sp.issparse(X):
0.91 k_means_.py(133):             centers[c] = X[best_candidate]
0.91 k_means_.py(104):     for c in range(1, n_clusters):
0.91 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.91 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.91 k_means_.py(109):                                         rand_vals)
0.91 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.91 k_means_.py(112):                 out=candidate_ids)
0.91 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.91 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.92 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.92 k_means_.py(120):                    out=distance_to_candidates)
0.92 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.92 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.92 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.92 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.92 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.92 k_means_.py(130):         if sp.issparse(X):
0.92 k_means_.py(133):             centers[c] = X[best_candidate]
0.92 k_means_.py(104):     for c in range(1, n_clusters):
0.92 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.92 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.92 k_means_.py(109):                                         rand_vals)
0.92 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.92 k_means_.py(112):                 out=candidate_ids)
0.92 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.92 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.92 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.92 k_means_.py(120):                    out=distance_to_candidates)
0.92 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.92 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.92 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.92 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.92 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.92 k_means_.py(130):         if sp.issparse(X):
0.92 k_means_.py(133):             centers[c] = X[best_candidate]
0.92 k_means_.py(104):     for c in range(1, n_clusters):
0.92 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.92 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.92 k_means_.py(109):                                         rand_vals)
0.92 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.92 k_means_.py(112):                 out=candidate_ids)
0.92 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.92 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.92 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.92 k_means_.py(120):                    out=distance_to_candidates)
0.92 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.92 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.92 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.92 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.92 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.92 k_means_.py(130):         if sp.issparse(X):
0.92 k_means_.py(133):             centers[c] = X[best_candidate]
0.92 k_means_.py(104):     for c in range(1, n_clusters):
0.92 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.92 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.92 k_means_.py(109):                                         rand_vals)
0.92 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.92 k_means_.py(112):                 out=candidate_ids)
0.92 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.92 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.92 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.92 k_means_.py(120):                    out=distance_to_candidates)
0.92 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.92 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.92 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.92 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.92 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.92 k_means_.py(130):         if sp.issparse(X):
0.92 k_means_.py(133):             centers[c] = X[best_candidate]
0.92 k_means_.py(104):     for c in range(1, n_clusters):
0.92 k_means_.py(135):     return centers
0.92 k_means_.py(757):     if sp.issparse(centers):
0.92 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.92 k_means_.py(143):     if len(centers) != n_centers:
0.92 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.92 k_means_.py(761):     return centers
0.92 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.92 k_means_.py(431):     if verbose:
0.92 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.92 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.92 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.92 k_means_.py(169):     if not sample_weight_was_none:
0.92 k_means_.py(175):     return sample_weight
0.92 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.92 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.92 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.93 k_means_.py(438):     if sample_weight is None:
0.93 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.93 k_means_.py(444):     return labels, inertia, centers, n_iter
0.93 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.93 k_means_.py(368):         for seed in seeds:
0.93 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.93 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.93 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.93 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.93 k_means_.py(374):                 random_state=seed)
0.93 k_means_.py(422):     if sp.issparse(X):
0.93 k_means_.py(424):     random_state = check_random_state(random_state)
0.93 k_means_.py(425):     if x_squared_norms is None:
0.93 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.93 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.93 k_means_.py(718):     random_state = check_random_state(random_state)
0.93 k_means_.py(719):     n_samples = X.shape[0]
0.93 k_means_.py(721):     if x_squared_norms is None:
0.93 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.93 k_means_.py(735):     elif n_samples < k:
0.93 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.93 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.93 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.93 k_means_.py(77):     n_samples, n_features = X.shape
0.93 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.93 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.93 k_means_.py(84):     if n_local_trials is None:
0.93 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.93 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.93 k_means_.py(92):     if sp.issparse(X):
0.93 k_means_.py(95):         centers[0] = X[center_id]
0.93 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.93 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.93 k_means_.py(100):         squared=True)
0.93 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.93 k_means_.py(104):     for c in range(1, n_clusters):
0.93 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.93 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.93 k_means_.py(109):                                         rand_vals)
0.93 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.93 k_means_.py(112):                 out=candidate_ids)
0.93 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.93 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.93 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.93 k_means_.py(120):                    out=distance_to_candidates)
0.93 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.93 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.93 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.93 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.93 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.93 k_means_.py(130):         if sp.issparse(X):
0.93 k_means_.py(133):             centers[c] = X[best_candidate]
0.93 k_means_.py(104):     for c in range(1, n_clusters):
0.93 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.93 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.93 k_means_.py(109):                                         rand_vals)
0.93 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.93 k_means_.py(112):                 out=candidate_ids)
0.93 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.93 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.93 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.93 k_means_.py(120):                    out=distance_to_candidates)
0.93 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.94 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.94 k_means_.py(109):                                         rand_vals)
0.94 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.94 k_means_.py(112):                 out=candidate_ids)
0.94 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.94 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.94 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.94 k_means_.py(120):                    out=distance_to_candidates)
0.94 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.94 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.94 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.94 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.94 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.94 k_means_.py(130):         if sp.issparse(X):
0.94 k_means_.py(133):             centers[c] = X[best_candidate]
0.94 k_means_.py(104):     for c in range(1, n_clusters):
0.94 k_means_.py(135):     return centers
0.94 k_means_.py(757):     if sp.issparse(centers):
0.94 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.94 k_means_.py(143):     if len(centers) != n_centers:
0.94 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.94 k_means_.py(761):     return centers
0.94 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.94 k_means_.py(431):     if verbose:
0.94 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.94 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.94 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.94 k_means_.py(169):     if not sample_weight_was_none:
0.94 k_means_.py(175):     return sample_weight
0.94 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.94 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.94 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.97 k_means_.py(438):     if sample_weight is None:
0.97 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.97 k_means_.py(444):     return labels, inertia, centers, n_iter
0.97 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.97 k_means_.py(368):         for seed in seeds:
0.97 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.97 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.97 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.97 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.97 k_means_.py(374):                 random_state=seed)
0.97 k_means_.py(422):     if sp.issparse(X):
0.97 k_means_.py(424):     random_state = check_random_state(random_state)
0.97 k_means_.py(425):     if x_squared_norms is None:
0.97 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.97 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.97 k_means_.py(718):     random_state = check_random_state(random_state)
0.97 k_means_.py(719):     n_samples = X.shape[0]
0.97 k_means_.py(721):     if x_squared_norms is None:
0.97 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.97 k_means_.py(735):     elif n_samples < k:
0.97 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.97 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.97 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.97 k_means_.py(77):     n_samples, n_features = X.shape
0.97 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.97 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.97 k_means_.py(84):     if n_local_trials is None:
0.97 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.97 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.97 k_means_.py(92):     if sp.issparse(X):
0.97 k_means_.py(95):         centers[0] = X[center_id]
0.97 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.97 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.97 k_means_.py(100):         squared=True)
0.97 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.97 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.97 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.97 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.97 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.97 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.97 k_means_.py(130):         if sp.issparse(X):
0.97 k_means_.py(133):             centers[c] = X[best_candidate]
0.97 k_means_.py(104):     for c in range(1, n_clusters):
0.97 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.97 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.97 k_means_.py(109):                                         rand_vals)
0.97 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.97 k_means_.py(112):                 out=candidate_ids)
0.97 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.97 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.97 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.97 k_means_.py(120):                    out=distance_to_candidates)
0.98 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.98 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.98 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.98 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.98 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.98 k_means_.py(130):         if sp.issparse(X):
0.98 k_means_.py(133):             centers[c] = X[best_candidate]
0.98 k_means_.py(104):     for c in range(1, n_clusters):
0.98 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.98 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.98 k_means_.py(109):                                         rand_vals)
0.98 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.98 k_means_.py(112):                 out=candidate_ids)
0.98 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.98 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.98 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.98 k_means_.py(120):                    out=distance_to_candidates)
0.98 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.98 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.98 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.98 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.98 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.98 k_means_.py(130):         if sp.issparse(X):
0.98 k_means_.py(133):             centers[c] = X[best_candidate]
0.98 k_means_.py(104):     for c in range(1, n_clusters):
0.98 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.98 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.98 k_means_.py(109):                                         rand_vals)
0.98 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.98 k_means_.py(112):                 out=candidate_ids)
0.98 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.98 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.98 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.98 k_means_.py(120):                    out=distance_to_candidates)
0.98 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.98 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.98 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.98 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.98 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.98 k_means_.py(130):         if sp.issparse(X):
0.98 k_means_.py(133):             centers[c] = X[best_candidate]
0.98 k_means_.py(104):     for c in range(1, n_clusters):
0.98 k_means_.py(135):     return centers
0.98 k_means_.py(757):     if sp.issparse(centers):
0.98 k_means_.py(760):     _validate_center_shape(X, k, centers)
0.98 k_means_.py(143):     if len(centers) != n_centers:
0.98 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
0.98 k_means_.py(761):     return centers
0.98 k_means_.py(430):     centers = np.ascontiguousarray(centers)
0.98 k_means_.py(431):     if verbose:
0.98 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
0.98 k_means_.py(166):     sample_weight_was_none = sample_weight is None
0.98 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
0.98 k_means_.py(169):     if not sample_weight_was_none:
0.98 k_means_.py(175):     return sample_weight
0.98 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
0.98 k_means_.py(436):                                             n_clusters, centers, tol=tol,
0.98 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
0.99 k_means_.py(438):     if sample_weight is None:
0.99 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
0.99 k_means_.py(444):     return labels, inertia, centers, n_iter
0.99 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
0.99 k_means_.py(368):         for seed in seeds:
0.99 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
0.99 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
0.99 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
0.99 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
0.99 k_means_.py(374):                 random_state=seed)
0.99 k_means_.py(422):     if sp.issparse(X):
0.99 k_means_.py(424):     random_state = check_random_state(random_state)
0.99 k_means_.py(425):     if x_squared_norms is None:
0.99 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
0.99 k_means_.py(429):                               x_squared_norms=x_squared_norms)
0.99 k_means_.py(718):     random_state = check_random_state(random_state)
0.99 k_means_.py(719):     n_samples = X.shape[0]
0.99 k_means_.py(721):     if x_squared_norms is None:
0.99 k_means_.py(724):     if init_size is not None and init_size < n_samples:
0.99 k_means_.py(735):     elif n_samples < k:
0.99 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
0.99 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
0.99 k_means_.py(741):                           x_squared_norms=x_squared_norms)
0.99 k_means_.py(77):     n_samples, n_features = X.shape
0.99 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
0.99 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
0.99 k_means_.py(84):     if n_local_trials is None:
0.99 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
0.99 k_means_.py(91):     center_id = random_state.randint(n_samples)
0.99 k_means_.py(92):     if sp.issparse(X):
0.99 k_means_.py(95):         centers[0] = X[center_id]
0.99 k_means_.py(98):     closest_dist_sq = euclidean_distances(
0.99 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
0.99 k_means_.py(100):         squared=True)
0.99 k_means_.py(101):     current_pot = closest_dist_sq.sum()
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
0.99 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
0.99 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
0.99 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
0.99 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
0.99 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
0.99 k_means_.py(130):         if sp.issparse(X):
0.99 k_means_.py(133):             centers[c] = X[best_candidate]
0.99 k_means_.py(104):     for c in range(1, n_clusters):
0.99 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
0.99 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
0.99 k_means_.py(109):                                         rand_vals)
0.99 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
0.99 k_means_.py(112):                 out=candidate_ids)
0.99 k_means_.py(115):         distance_to_candidates = euclidean_distances(
0.99 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
0.99 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
0.99 k_means_.py(120):                    out=distance_to_candidates)
1.00 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.00 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.00 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.00 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.00 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.00 k_means_.py(130):         if sp.issparse(X):
1.00 k_means_.py(133):             centers[c] = X[best_candidate]
1.00 k_means_.py(104):     for c in range(1, n_clusters):
1.00 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.00 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.00 k_means_.py(109):                                         rand_vals)
1.00 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.00 k_means_.py(112):                 out=candidate_ids)
1.00 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.00 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.00 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.00 k_means_.py(120):                    out=distance_to_candidates)
1.00 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.00 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.00 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.00 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.00 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.00 k_means_.py(130):         if sp.issparse(X):
1.00 k_means_.py(133):             centers[c] = X[best_candidate]
1.00 k_means_.py(104):     for c in range(1, n_clusters):
1.00 k_means_.py(135):     return centers
1.00 k_means_.py(757):     if sp.issparse(centers):
1.00 k_means_.py(760):     _validate_center_shape(X, k, centers)
1.00 k_means_.py(143):     if len(centers) != n_centers:
1.00 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
1.00 k_means_.py(761):     return centers
1.00 k_means_.py(430):     centers = np.ascontiguousarray(centers)
1.00 k_means_.py(431):     if verbose:
1.00 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
1.00 k_means_.py(166):     sample_weight_was_none = sample_weight is None
1.00 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
1.00 k_means_.py(169):     if not sample_weight_was_none:
1.00 k_means_.py(175):     return sample_weight
1.00 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
1.00 k_means_.py(436):                                             n_clusters, centers, tol=tol,
1.00 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
1.01 k_means_.py(438):     if sample_weight is None:
1.01 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
1.01 k_means_.py(444):     return labels, inertia, centers, n_iter
1.01 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
1.01 k_means_.py(368):         for seed in seeds:
1.01 k_means_.py(370):             labels, inertia, centers, n_iter_ = kmeans_single(
1.01 k_means_.py(371):                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
1.01 k_means_.py(372):                 verbose=verbose, precompute_distances=precompute_distances,
1.01 k_means_.py(373):                 tol=tol, x_squared_norms=x_squared_norms,
1.01 k_means_.py(374):                 random_state=seed)
1.01 k_means_.py(422):     if sp.issparse(X):
1.01 k_means_.py(424):     random_state = check_random_state(random_state)
1.01 k_means_.py(425):     if x_squared_norms is None:
1.01 k_means_.py(428):     centers = _init_centroids(X, n_clusters, init, random_state=random_state,
1.01 k_means_.py(429):                               x_squared_norms=x_squared_norms)
1.01 k_means_.py(718):     random_state = check_random_state(random_state)
1.01 k_means_.py(719):     n_samples = X.shape[0]
1.01 k_means_.py(721):     if x_squared_norms is None:
1.01 k_means_.py(724):     if init_size is not None and init_size < n_samples:
1.01 k_means_.py(735):     elif n_samples < k:
1.01 k_means_.py(739):     if isinstance(init, str) and init == 'k-means++':
1.01 k_means_.py(740):         centers = _k_init(X, k, random_state=random_state,
1.01 k_means_.py(741):                           x_squared_norms=x_squared_norms)
1.01 k_means_.py(77):     n_samples, n_features = X.shape
1.01 k_means_.py(79):     centers = np.empty((n_clusters, n_features), dtype=X.dtype)
1.01 k_means_.py(81):     assert x_squared_norms is not None, 'x_squared_norms None in _k_init'
1.01 k_means_.py(84):     if n_local_trials is None:
1.01 k_means_.py(88):         n_local_trials = 2 + int(np.log(n_clusters))
1.01 k_means_.py(91):     center_id = random_state.randint(n_samples)
1.01 k_means_.py(92):     if sp.issparse(X):
1.01 k_means_.py(95):         centers[0] = X[center_id]
1.01 k_means_.py(98):     closest_dist_sq = euclidean_distances(
1.01 k_means_.py(99):         centers[0, np.newaxis], X, Y_norm_squared=x_squared_norms,
1.01 k_means_.py(100):         squared=True)
1.01 k_means_.py(101):     current_pot = closest_dist_sq.sum()
1.01 k_means_.py(104):     for c in range(1, n_clusters):
1.01 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.01 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.01 k_means_.py(109):                                         rand_vals)
1.01 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.01 k_means_.py(112):                 out=candidate_ids)
1.01 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.01 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.01 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.01 k_means_.py(120):                    out=distance_to_candidates)
1.01 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.01 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.01 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.01 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.01 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.01 k_means_.py(130):         if sp.issparse(X):
1.01 k_means_.py(133):             centers[c] = X[best_candidate]
1.01 k_means_.py(104):     for c in range(1, n_clusters):
1.01 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.01 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(107):         rand_vals = random_state.random_sample(n_local_trials) * current_pot
1.02 k_means_.py(108):         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq),
1.02 k_means_.py(109):                                         rand_vals)
1.02 k_means_.py(111):         np.clip(candidate_ids, None, closest_dist_sq.size - 1,
1.02 k_means_.py(112):                 out=candidate_ids)
1.02 k_means_.py(115):         distance_to_candidates = euclidean_distances(
1.02 k_means_.py(116):             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)
1.02 k_means_.py(119):         np.minimum(closest_dist_sq, distance_to_candidates,
1.02 k_means_.py(120):                    out=distance_to_candidates)
1.02 k_means_.py(121):         candidates_pot = distance_to_candidates.sum(axis=1)
1.02 k_means_.py(124):         best_candidate = np.argmin(candidates_pot)
1.02 k_means_.py(125):         current_pot = candidates_pot[best_candidate]
1.02 k_means_.py(126):         closest_dist_sq = distance_to_candidates[best_candidate]
1.02 k_means_.py(127):         best_candidate = candidate_ids[best_candidate]
1.02 k_means_.py(130):         if sp.issparse(X):
1.02 k_means_.py(133):             centers[c] = X[best_candidate]
1.02 k_means_.py(104):     for c in range(1, n_clusters):
1.02 k_means_.py(135):     return centers
1.02 k_means_.py(757):     if sp.issparse(centers):
1.02 k_means_.py(760):     _validate_center_shape(X, k, centers)
1.02 k_means_.py(143):     if len(centers) != n_centers:
1.02 k_means_.py(147):     if centers.shape[1] != X.shape[1]:
1.02 k_means_.py(761):     return centers
1.02 k_means_.py(430):     centers = np.ascontiguousarray(centers)
1.02 k_means_.py(431):     if verbose:
1.02 k_means_.py(434):     checked_sample_weight = _check_normalize_sample_weight(sample_weight, X)
1.02 k_means_.py(166):     sample_weight_was_none = sample_weight is None
1.02 k_means_.py(168):     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
1.02 k_means_.py(169):     if not sample_weight_was_none:
1.02 k_means_.py(175):     return sample_weight
1.02 k_means_.py(435):     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,
1.02 k_means_.py(436):                                             n_clusters, centers, tol=tol,
1.02 k_means_.py(437):                                             max_iter=max_iter, verbose=verbose)
1.03 k_means_.py(438):     if sample_weight is None:
1.03 k_means_.py(439):         inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)
1.03 k_means_.py(444):     return labels, inertia, centers, n_iter
1.03 k_means_.py(376):             if best_inertia is None or inertia < best_inertia:
1.03 k_means_.py(368):         for seed in seeds:
1.03 k_means_.py(400):     if not sp.issparse(X):
1.03 k_means_.py(401):         if not copy_x:
1.03 k_means_.py(403):         best_centers += X_mean
1.03 k_means_.py(405):     distinct_clusters = len(set(best_labels))
1.03 k_means_.py(406):     if distinct_clusters < n_clusters:
1.03 k_means_.py(412):     if return_n_iter:
1.03 k_means_.py(413):         return best_centers, best_labels, best_inertia, best_n_iter
1.03 k_means_.py(965):         return self
1.03 k_means_.py(913):         self.n_clusters = n_clusters
1.03 k_means_.py(914):         self.init = init
1.03 k_means_.py(915):         self.max_iter = max_iter
1.03 k_means_.py(916):         self.tol = tol
1.03 k_means_.py(917):         self.precompute_distances = precompute_distances
1.03 k_means_.py(918):         self.n_init = n_init
1.03 k_means_.py(919):         self.verbose = verbose
1.03 k_means_.py(920):         self.random_state = random_state
1.03 k_means_.py(921):         self.copy_x = copy_x
1.03 k_means_.py(922):         self.n_jobs = n_jobs
1.03 k_means_.py(923):         self.algorithm = algorithm
1.03 k_means_.py(954):         random_state = check_random_state(self.random_state)
1.03 k_means_.py(957):             k_means(
1.03 k_means_.py(958):                 X, n_clusters=self.n_clusters, sample_weight=sample_weight,
1.03 k_means_.py(959):                 init=self.init, n_init=self.n_init,
1.03 k_means_.py(960):                 max_iter=self.max_iter, verbose=self.verbose,
1.03 k_means_.py(961):                 precompute_distances=self.precompute_distances,
1.03 k_means_.py(962):                 tol=self.tol, random_state=random_state, copy_x=self.copy_x,
1.03 k_means_.py(963):                 n_jobs=self.n_jobs, algorithm=self.algorithm,
1.03 k_means_.py(964):                 return_n_iter=True)
1.03 k_means_.py(291):     if n_init <= 0:
1.03 k_means_.py(294):     random_state = check_random_state(random_state)
1.03 k_means_.py(296):     if max_iter <= 0:
1.03 k_means_.py(301):     order = "C" if copy_x else None
1.03 k_means_.py(302):     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],
1.03 k_means_.py(303):                     order=order, copy=copy_x)
1.03 k_means_.py(305):     if _num_samples(X) < n_clusters:
1.03 k_means_.py(309):     tol = _tolerance(X, tol)
1.03 k_means_.py(156):     if sp.issparse(X):
1.03 k_means_.py(159):         variances = np.var(X, axis=0)
1.03 k_means_.py(160):     return np.mean(variances) * tol
1.03 k_means_.py(315):     if precompute_distances == 'auto':
1.03 k_means_.py(316):         n_samples = X.shape[0]
1.03 k_means_.py(317):         precompute_distances = (n_clusters * n_samples) < 12e6
1.03 k_means_.py(326):     if hasattr(init, '__array__'):
1.03 k_means_.py(338):     if not sp.issparse(X):
1.03 k_means_.py(339):         X_mean = X.mean(axis=0)
1.03 k_means_.py(341):         X -= X_mean
1.03 k_means_.py(343):         if hasattr(init, '__array__'):
1.03 k_means_.py(347):     x_squared_norms = row_norms(X, squared=True)
1.03 k_means_.py(349):     best_labels, best_inertia, best_centers = None, None, None
1.03 k_means_.py(350):     if n_clusters == 1:
1.03 k_means_.py(354):     if algorithm == "auto":
1.03 k_means_.py(355):         algorithm = "full" if sp.issparse(X) else 'elkan'
1.03 k_means_.py(356):     if algorithm == "full":
1.03 k_means_.py(358):     elif algorithm == "elkan":
1.03 k_means_.py(359):         kmeans_single = _kmeans_single_elkan
1.03 k_means_.py(364):     seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
1.03 k_means_.py(365):     if effective_n_jobs(n_jobs) == 1:
1.03 k_means_.py(383):         results = Parallel(n_jobs=n_jobs, verbose=0)(
1.03 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.03 k_means_.py(391):             for seed in seeds)
1.04 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.04 k_means_.py(391):             for seed in seeds)
1.04 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.04 k_means_.py(391):             for seed in seeds)
1.06 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.06 k_means_.py(391):             for seed in seeds)
1.06 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.06 k_means_.py(391):             for seed in seeds)
1.52 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.52 k_means_.py(391):             for seed in seeds)
1.52 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.52 k_means_.py(391):             for seed in seeds)
1.57 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.57 k_means_.py(391):             for seed in seeds)
1.57 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.57 k_means_.py(391):             for seed in seeds)
1.60 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.60 k_means_.py(391):             for seed in seeds)
1.60 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.60 k_means_.py(391):             for seed in seeds)
1.63 k_means_.py(384):             delayed(kmeans_single)(X, sample_weight, n_clusters,
1.67 k_means_.py(393):         labels, inertia, centers, n_iters = zip(*results)
1.67 k_means_.py(394):         best = np.argmin(inertia)
1.67 k_means_.py(395):         best_labels = labels[best]
1.67 k_means_.py(396):         best_inertia = inertia[best]
1.67 k_means_.py(397):         best_centers = centers[best]
1.67 k_means_.py(398):         best_n_iter = n_iters[best]
1.67 k_means_.py(400):     if not sp.issparse(X):
1.67 k_means_.py(401):         if not copy_x:
1.67 k_means_.py(403):         best_centers += X_mean
1.67 k_means_.py(405):     distinct_clusters = len(set(best_labels))
1.67 k_means_.py(406):     if distinct_clusters < n_clusters:
1.67 k_means_.py(412):     if return_n_iter:
1.67 k_means_.py(413):         return best_centers, best_labels, best_inertia, best_n_iter
1.67 k_means_.py(965):         return self
=========================== short test summary info ============================
PASSED sklearn/tests/test_coverup_scikit-learn__scikit-learn-9288.py::test_kmeans_inertia_with_different_n_jobs
========================= 1 passed, 1 warning in 1.30s =========================
+ cat coverage.cover
{"/testbed/sklearn/cluster/k_means_.py": {"14": 1, "16": 1, "17": 1, "18": 1, "20": 1, "21": 1, "22": 1, "23": 1, "24": 1, "25": 1, "26": 1, "27": 1, "28": 1, "29": 1, "30": 1, "31": 1, "32": 1, "33": 1, "34": 1, "41": 1, "141": 1, "154": 1, "163": 1, "181": 1, "421": 1, "450": 1, "576": 1, "625": 1, "685": 1, "764": 2, "1106": 1, "1248": 1, "1312": 2, "77": 10, "79": 10, "81": 10, "84": 10, "88": 10, "91": 10, "92": 10, "93": 0, "95": 10, "98": 10, "99": 10, "100": 10, "101": 10, "104": 100, "107": 90, "108": 90, "109": 90, "111": 90, "112": 90, "115": 90, "116": 90, "119": 90, "120": 90, "121": 90, "124": 90, "125": 90, "126": 90, "127": 90, "130": 90, "131": 0, "133": 90, "135": 10, "143": 10, "144": 0, "146": 0, "147": 10, "148": 0, "149": 0, "151": 0, "156": 2, "157": 0, "159": 2, "160": 2, "166": 10, "168": 10, "169": 10, "172": 0, "173": 0, "174": 0, "175": 10, "291": 2, "292": 0, "293": 0, "294": 2, "296": 2, "297": 0, "298": 0, "301": 2, "302": 2, "303": 2, "305": 2, "306": 0, "307": 0, "309": 2, "315": 2, "316": 2, "317": 2, "318": 0, "319": 0, "321": 0, "323": 0, "326": 2, "327": 0, "328": 0, "330": 0, "331": 0, "332": 0, "334": 0, "335": 0, "338": 2, "339": 2, "341": 2, "343": 2, "344": 0, "347": 2, "349": 2, "350": 2, "353": 0, "354": 2, "355": 2, "356": 2, "357": 0, "358": 2, "359": 2, "361": 0, "362": 0, "364": 2, "365": 2, "368": 11, "370": 10, "371": 10, "372": 10, "373": 10, "374": 10, "376": 10, "377": 2, "378": 2, "379": 2, "380": 2, "383": 1, "384": 12, "391": 11, "393": 1, "394": 1, "395": 1, "396": 1, "397": 1, "398": 1, "400": 2, "401": 2, "402": 0, "403": 2, "405": 2, "406": 2, "407": 0, "409": 0, "410": 0, "412": 2, "413": 2, "415": 0, "422": 10, "423": 0, "424": 10, "425": 10, "426": 0, "428": 10, "429": 10, "430": 10, "431": 10, "432": 0, "434": 10, "435": 10, "436": 10, "437": 10, "438": 10, "439": 10, "441": 0, "442": 0, "443": 0, "444": 10, "517": 0, "519": 0, "521": 0, "523": 0, "524": 0, "525": 0, "526": 0, "530": 0, "533": 0, "534": 0, "537": 0, "538": 0, "539": 0, "542": 0, "543": 0, "544": 0, "546": 0, "547": 0, "549": 0, "550": 0, "552": 0, "553": 0, "554": 0, "555": 0, "557": 0, "558": 0, "559": 0, "560": 0, "562": 0, "563": 0, "565": 0, "569": 0, "570": 0, "571": 0, "573": 0, "608": 0, "613": 0, "614": 0, "616": 0, "617": 0, "619": 0, "620": 0, "621": 0, "661": 0, "662": 0, "665": 0, "666": 0, "667": 0, "669": 0, "670": 0, "671": 0, "672": 0, "674": 0, "675": 0, "676": 0, "677": 0, "678": 0, "679": 0, "680": 0, "681": 0, "718": 10, "719": 10, "721": 10, "722": 0, "724": 10, "725": 0, "726": 0, "727": 0, "728": 0, "729": 0, "730": 0, "731": 0, "732": 0, "733": 0, "734": 0, "735": 10, "736": 0, "737": 0, "739": 10, "740": 10, "741": 10, "742": 0, "743": 0, "744": 0, "745": 0, "748": 0, "749": 0, "750": 0, "751": 0, "753": 0, "755": 0, "757": 10, "758": 0, "760": 10, "761": 10, "911": 1, "925": 1, "936": 1, "967": 1, "992": 1, "1020": 1, "1042": 1, "1046": 1, "1074": 1, "913": 2, "914": 2, "915": 2, "916": 2, "917": 2, "918": 2, "919": 2, "920": 2, "921": 2, "922": 2, "923": 2, "926": 0, "927": 0, "928": 0, "929": 0, "930": 0, "932": 0, "934": 0, "954": 2, "957": 2, "958": 2, "959": 2, "960": 2, "961": 2, "962": 2, "963": 2, "964": 2, "965": 2, "990": 0, "1018": 0, "1037": 0, "1039": 0, "1040": 0, "1044": 0, "1067": 0, "1069": 0, "1070": 0, "1071": 0, "1072": 0, "1094": 0, "1096": 0, "1097": 0, "1098": 0, "1099": 0, "1169": 0, "1170": 0, "1171": 0, "1173": 0, "1174": 0, "1176": 0, "1178": 0, "1180": 0, "1181": 0, "1182": 0, "1183": 0, "1185": 0, "1186": 0, "1187": 0, "1188": 0, "1189": 0, "1191": 0, "1192": 0, "1193": 0, "1194": 0, "1195": 0, "1197": 0, "1201": 0, "1205": 0, "1206": 0, "1207": 0, "1208": 0, "1211": 0, "1212": 0, "1213": 0, "1215": 0, "1216": 0, "1218": 0, "1219": 0, "1220": 0, "1223": 0, "1226": 0, "1227": 0, "1228": 0, "1231": 0, "1236": 0, "1239": 0, "1240": 0, "1241": 0, "1243": 0, "1252": 0, "1253": 0, "1259": 0, "1260": 0, "1261": 0, "1262": 0, "1263": 0, "1265": 0, "1266": 0, "1267": 0, "1268": 0, "1271": 0, "1273": 0, "1275": 0, "1276": 0, "1277": 0, "1281": 0, "1282": 0, "1283": 0, "1284": 0, "1285": 0, "1288": 0, "1289": 0, "1290": 0, "1291": 0, "1292": 0, "1294": 0, "1296": 0, "1297": 0, "1298": 0, "1299": 0, "1301": 0, "1302": 0, "1305": 0, "1306": 0, "1307": 0, "1308": 0, "1309": 0, "1454": 1, "1466": 1, "1617": 1, "1649": 1, "1716": 1, "1456": 0, "1457": 0, "1458": 0, "1460": 0, "1461": 0, "1462": 0, "1463": 0, "1464": 0, "1484": 0, "1485": 0, "1486": 0, "1487": 0, "1488": 0, "1489": 0, "1490": 0, "1492": 0, "1494": 0, "1495": 0, "1496": 0, "1497": 0, "1498": 0, "1499": 0, "1502": 0, "1503": 0, "1505": 0, "1507": 0, "1508": 0, "1513": 0, "1515": 0, "1518": 0, "1520": 0, "1521": 0, "1522": 0, "1524": 0, "1525": 0, "1526": 0, "1527": 0, "1528": 0, "1529": 0, "1531": 0, "1532": 0, "1533": 0, "1534": 0, "1537": 0, "1538": 0, "1539": 0, "1540": 0, "1541": 0, "1542": 0, "1549": 0, "1550": 0, "1551": 0, "1552": 0, "1553": 0, "1556": 0, "1557": 0, "1558": 0, "1559": 0, "1560": 0, "1564": 0, "1565": 0, "1566": 0, "1567": 0, "1568": 0, "1569": 0, "1570": 0, "1571": 0, "1572": 0, "1573": 0, "1576": 0, "1580": 0, "1582": 0, "1583": 0, "1586": 0, "1587": 0, "1588": 0, "1589": 0, "1590": 0, "1596": 0, "1597": 0, "1598": 0, "1599": 0, "1600": 0, "1603": 0, "1604": 0, "1605": 0, "1606": 0, "1607": 0, "1609": 0, "1611": 0, "1613": 0, "1615": 0, "1639": 0, "1640": 0, "1641": 0, "1642": 0, "1643": 0, "1644": 0, "1645": 0, "1646": 0, "1647": 0, "1667": 0, "1668": 0, "1669": 0, "1670": 0, "1671": 0, "1673": 0, "1674": 0, "1676": 0, "1678": 0, "1679": 0, "1680": 0, "1681": 0, "1682": 0, "1685": 0, "1686": 0, "1687": 0, "1688": 0, "1690": 0, "1691": 0, "1692": 0, "1693": 0, "1698": 0, "1699": 0, "1700": 0, "1702": 0, "1703": 0, "1704": 0, "1705": 0, "1706": 0, "1707": 0, "1708": 0, "1710": 0, "1711": 0, "1712": 0, "1714": 0, "1737": 0, "1739": 0, "1740": 0}}
+ git checkout 3eacf948e0f95ef957862568d87ce082f378e186
Note: switching to '3eacf948e0f95ef957862568d87ce082f378e186'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 3eacf948e0 Set diagonal of precomputed matrix to zero in silhoutte_samples (#12258)
M	sklearn/cluster/k_means_.py
+ git apply /root/pre_state.patch
error: unrecognized input
