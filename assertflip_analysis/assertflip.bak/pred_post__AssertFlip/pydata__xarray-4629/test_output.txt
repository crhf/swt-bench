+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh
+++ '[' -n '' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh
+++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/gdal ']'
+++ export GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ export GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ '[' '!' -d /opt/miniconda3/envs/testbed/lib/gdalplugins ']'
+++ export CPL_ZIP_ENCODING=UTF-8
+++ CPL_ZIP_ENCODING=UTF-8
+++ '[' -n '5.1.16(1)-release' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo ']'
+++ source /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo
++++ function_exists _get_comp_words_by_ref
++++ declare -f -F _get_comp_words_by_ref
++++ return 1
++++ return 0
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/epsg_csv ']'
+++ '[' -d /opt/miniconda3/envs/testbed/Library/share/epsg_csv ']'
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh
+++ '[' -n '' ']'
+++ _la_log 'Beginning libarrow activation.'
+++ '[' '' = 1 ']'
+++ _la_gdb_prefix=/opt/miniconda3/envs/testbed/share/gdb/auto-load
+++ '[' '!' -w /opt/miniconda3/envs/testbed/share/gdb/auto-load ']'
+++ _la_placeholder=replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX
+++ _la_symlink_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib
+++ _la_orig_install_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
+++ _la_log '          _la_gdb_prefix: /opt/miniconda3/envs/testbed/share/gdb/auto-load'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_placeholder: replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_symlink_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib'
+++ '[' '' = 1 ']'
+++ _la_log '    _la_orig_install_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib'
+++ '[' '' = 1 ']'
+++ _la_log '  content of that folder:'
+++ '[' '' = 1 ']'
++++ ls -al /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
++++ sed 's/^/      /'
+++ _la_log '      total 12
      drwxr-xr-x 2 root root 4096 Aug 25 05:38 .
      drwxr-xr-x 3 root root 4096 Aug 25 05:38 ..
      -rw-r--r-- 1 root root  971 Aug 25 05:38 libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ for _la_target in "$_la_orig_install_dir/"*.py
+++ '[' '!' -e /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ basename /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_symlink=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_log '   _la_target: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ _la_log '  _la_symlink: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ '[' -L /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ readlink /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ '[' /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py = /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
+++ _la_log 'symlink $_la_symlink already exists and points to $_la_target, skipping.'
+++ '[' '' = 1 ']'
+++ continue
+++ _la_log 'Libarrow activation complete.'
+++ '[' '' = 1 ']'
+++ unset _la_gdb_prefix
+++ unset _la_log
+++ unset _la_orig_install_dir
+++ unset _la_placeholder
+++ unset _la_symlink
+++ unset _la_symlink_dir
+++ unset _la_target
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/opt/miniconda3/envs/testbed
+++ for pre in ${rem}
+++ test '' = /opt/miniconda3/envs/testbed
+++ conda_catalog_files=/opt/miniconda3/envs/testbed
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/proj ']'
+++ export PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ '[' -f /opt/miniconda3/envs/testbed/share/proj/copyright_and_licenses.csv ']'
+++ export PROJ_NETWORK=ON
+++ PROJ_NETWORK=ON
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/udunits ']'
+++ export UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+++ UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD a41edc7bf5302f2ea327943c0c48c532b12009bc
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit a41edc7bf5302f2ea327943c0c48c532b12009bc
Author: Mathias Hauser <mathause@users.noreply.github.com>
Date:   Tue Dec 1 10:06:30 2020 +0100

    weighted: de-parameterize tests (#4617)

diff --git a/xarray/tests/test_weighted.py b/xarray/tests/test_weighted.py
index 2366b982..c80d78a3 100644
--- a/xarray/tests/test_weighted.py
+++ b/xarray/tests/test_weighted.py
@@ -226,12 +226,28 @@ def expected_weighted(da, weights, dim, skipna, operation):
         return weighted_mean
 
 
+def check_weighted_operations(data, weights, dim, skipna):
+
+    # check sum of weights
+    result = data.weighted(weights).sum_of_weights(dim)
+    expected = expected_weighted(data, weights, dim, skipna, "sum_of_weights")
+    assert_allclose(expected, result)
+
+    # check weighted sum
+    result = data.weighted(weights).sum(dim, skipna=skipna)
+    expected = expected_weighted(data, weights, dim, skipna, "sum")
+    assert_allclose(expected, result)
+
+    # check weighted mean
+    result = data.weighted(weights).mean(dim, skipna=skipna)
+    expected = expected_weighted(data, weights, dim, skipna, "mean")
+    assert_allclose(expected, result)
+
+
 @pytest.mark.parametrize("dim", ("a", "b", "c", ("a", "b"), ("a", "b", "c"), None))
-@pytest.mark.parametrize("operation", ("sum_of_weights", "sum", "mean"))
 @pytest.mark.parametrize("add_nans", (True, False))
 @pytest.mark.parametrize("skipna", (None, True, False))
-@pytest.mark.parametrize("as_dataset", (True, False))
-def test_weighted_operations_3D(dim, operation, add_nans, skipna, as_dataset):
+def test_weighted_operations_3D(dim, add_nans, skipna):
 
     dims = ("a", "b", "c")
     coords = dict(a=[0, 1, 2, 3], b=[0, 1, 2, 3], c=[0, 1, 2, 3])
@@ -247,46 +263,29 @@ def test_weighted_operations_3D(dim, operation, add_nans, skipna, as_dataset):
 
     data = DataArray(data, dims=dims, coords=coords)
 
-    if as_dataset:
-        data = data.to_dataset(name="data")
-
-    if operation == "sum_of_weights":
-        result = data.weighted(weights).sum_of_weights(dim)
-    else:
-        result = getattr(data.weighted(weights), operation)(dim, skipna=skipna)
-
-    expected = expected_weighted(data, weights, dim, skipna, operation)
+    check_weighted_operations(data, weights, dim, skipna)
 
-    assert_allclose(expected, result)
+    data = data.to_dataset(name="data")
+    check_weighted_operations(data, weights, dim, skipna)
 
 
-@pytest.mark.parametrize("operation", ("sum_of_weights", "sum", "mean"))
-@pytest.mark.parametrize("as_dataset", (True, False))
-def test_weighted_operations_nonequal_coords(operation, as_dataset):
+def test_weighted_operations_nonequal_coords():
 
     weights = DataArray(np.random.randn(4), dims=("a",), coords=dict(a=[0, 1, 2, 3]))
     data = DataArray(np.random.randn(4), dims=("a",), coords=dict(a=[1, 2, 3, 4]))
 
-    if as_dataset:
-        data = data.to_dataset(name="data")
-
-    expected = expected_weighted(
-        data, weights, dim="a", skipna=None, operation=operation
-    )
-    result = getattr(data.weighted(weights), operation)(dim="a")
+    check_weighted_operations(data, weights, dim="a", skipna=None)
 
-    assert_allclose(expected, result)
+    data = data.to_dataset(name="data")
+    check_weighted_operations(data, weights, dim="a", skipna=None)
 
 
-@pytest.mark.parametrize("dim", ("dim_0", None))
 @pytest.mark.parametrize("shape_data", ((4,), (4, 4), (4, 4, 4)))
 @pytest.mark.parametrize("shape_weights", ((4,), (4, 4), (4, 4, 4)))
-@pytest.mark.parametrize("operation", ("sum_of_weights", "sum", "mean"))
 @pytest.mark.parametrize("add_nans", (True, False))
 @pytest.mark.parametrize("skipna", (None, True, False))
-@pytest.mark.parametrize("as_dataset", (True, False))
 def test_weighted_operations_different_shapes(
-    dim, shape_data, shape_weights, operation, add_nans, skipna, as_dataset
+    shape_data, shape_weights, add_nans, skipna
 ):
 
     weights = DataArray(np.random.randn(*shape_weights))
@@ -300,17 +299,12 @@ def test_weighted_operations_different_shapes(
 
     data = DataArray(data)
 
-    if as_dataset:
-        data = data.to_dataset(name="data")
-
-    if operation == "sum_of_weights":
-        result = getattr(data.weighted(weights), operation)(dim)
-    else:
-        result = getattr(data.weighted(weights), operation)(dim, skipna=skipna)
+    check_weighted_operations(data, weights, "dim_0", skipna)
+    check_weighted_operations(data, weights, None, skipna)
 
-    expected = expected_weighted(data, weights, dim, skipna, operation)
-
-    assert_allclose(expected, result)
+    data = data.to_dataset(name="data")
+    check_weighted_operations(data, weights, "dim_0", skipna)
+    check_weighted_operations(data, weights, None, skipna)
 
 
 @pytest.mark.parametrize("operation", ("sum_of_weights", "sum", "mean"))
+ git diff a41edc7bf5302f2ea327943c0c48c532b12009bc
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval '. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh
++++ unset UDUNITS2_XML_PATH
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh
++++ unset PROJ_DATA
++++ unset PROJ_NETWORK
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh
++++ test -n ''
++++ unset XML_CATALOG_FILES
++++ unset xml_catalog_files_libxml2
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh
++++ unset GEOTIFF_CSV
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh
++++ unset GDAL_DATA
++++ '[' -n '' ']'
++++ unset GDAL_DRIVER_PATH
++++ '[' -n '' ']'
++++ unset CPL_ZIP_ENCODING
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh
++++ unset ESMFMKFILE
++++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
++++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++++ unset _CONDA_SET_ESMFMKFILE
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh
++++ unset ESMFMKFILE
++++ '[' -n '' ']'
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh
+++ '[' -n '' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh
+++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/gdal ']'
+++ export GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ export GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ '[' '!' -d /opt/miniconda3/envs/testbed/lib/gdalplugins ']'
+++ export CPL_ZIP_ENCODING=UTF-8
+++ CPL_ZIP_ENCODING=UTF-8
+++ '[' -n '5.1.16(1)-release' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo ']'
+++ source /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo
++++ function_exists _get_comp_words_by_ref
++++ declare -f -F _get_comp_words_by_ref
++++ return 1
++++ return 0
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/epsg_csv ']'
+++ '[' -d /opt/miniconda3/envs/testbed/Library/share/epsg_csv ']'
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh
+++ '[' -n '' ']'
+++ _la_log 'Beginning libarrow activation.'
+++ '[' '' = 1 ']'
+++ _la_gdb_prefix=/opt/miniconda3/envs/testbed/share/gdb/auto-load
+++ '[' '!' -w /opt/miniconda3/envs/testbed/share/gdb/auto-load ']'
+++ _la_placeholder=replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX
+++ _la_symlink_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib
+++ _la_orig_install_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
+++ _la_log '          _la_gdb_prefix: /opt/miniconda3/envs/testbed/share/gdb/auto-load'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_placeholder: replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_symlink_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib'
+++ '[' '' = 1 ']'
+++ _la_log '    _la_orig_install_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib'
+++ '[' '' = 1 ']'
+++ _la_log '  content of that folder:'
+++ '[' '' = 1 ']'
++++ ls -al /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
++++ sed 's/^/      /'
+++ _la_log '      total 12
      drwxr-xr-x 2 root root 4096 Aug 25 05:38 .
      drwxr-xr-x 3 root root 4096 Aug 25 05:38 ..
      -rw-r--r-- 1 root root  971 Aug 25 05:38 libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ for _la_target in "$_la_orig_install_dir/"*.py
+++ '[' '!' -e /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ basename /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_symlink=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_log '   _la_target: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ _la_log '  _la_symlink: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ '[' -L /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ readlink /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ '[' /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py = /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
+++ _la_log 'symlink $_la_symlink already exists and points to $_la_target, skipping.'
+++ '[' '' = 1 ']'
+++ continue
+++ _la_log 'Libarrow activation complete.'
+++ '[' '' = 1 ']'
+++ unset _la_gdb_prefix
+++ unset _la_log
+++ unset _la_orig_install_dir
+++ unset _la_placeholder
+++ unset _la_symlink
+++ unset _la_symlink_dir
+++ unset _la_target
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/opt/miniconda3/envs/testbed
+++ for pre in ${rem}
+++ test '' = /opt/miniconda3/envs/testbed
+++ conda_catalog_files=/opt/miniconda3/envs/testbed
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/proj ']'
+++ export PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ '[' -f /opt/miniconda3/envs/testbed/share/proj/copyright_and_licenses.csv ']'
+++ export PROJ_NETWORK=ON
+++ PROJ_NETWORK=ON
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/udunits ']'
+++ export UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+++ UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -e .
Obtaining file:///testbed
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: numpy>=1.15 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.16.3.dev2+ga41edc7bf) (1.23.0)
Requirement already satisfied: pandas>=0.25 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.16.3.dev2+ga41edc7bf) (1.5.3)
Requirement already satisfied: setuptools>=38.4 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.16.3.dev2+ga41edc7bf) (68.0.0)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.25->xarray==0.16.3.dev2+ga41edc7bf) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.25->xarray==0.16.3.dev2+ga41edc7bf) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.25->xarray==0.16.3.dev2+ga41edc7bf) (1.16.0)
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.16.3.dev2+ga41edc7bf
    Uninstalling xarray-0.16.3.dev2+ga41edc7bf:
      Successfully uninstalled xarray-0.16.3.dev2+ga41edc7bf
  DEPRECATION: Legacy editable install of xarray==0.16.3.dev2+ga41edc7bf from file:///testbed (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457
  Running setup.py develop for xarray
Successfully installed xarray
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
+ git apply -v -
Checking patch xarray/core/merge.py...
Applied patch xarray/core/merge.py cleanly.
+ git apply -v -
Checking patch xarray/tests/test_coverup_pydata__xarray-4629.py...
Applied patch xarray/tests/test_coverup_pydata__xarray-4629.py cleanly.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(xarray/core/merge\.py)' -m pytest --no-header -rA -p no:cacheprovider xarray/tests/test_coverup_pydata__xarray-4629.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(xarray/core/merge\\.py)']
============================= test session starts ==============================
collected 1 item

xarray/tests/test_coverup_pydata__xarray-4629.py .                       [100%]

=============================== warnings summary ===============================
xarray/__init__.py:1
  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    import pkg_resources

xarray/core/dask_array_compat.py:61
xarray/core/dask_array_compat.py:61
  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) > LooseVersion("2.9.0"):

xarray/core/pdcompat.py:45
  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) < "0.25.0":

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    return version.LooseVersion(vstring)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
________________________ test_merge_override_attrs_bug _________________________
----------------------------- Captured stdout call -----------------------------
3.26 merge.py(464):     objects = [data, coords]
3.26 merge.py(465):     explicit_coords = coords.keys()
3.26 merge.py(466):     indexes = dict(_extract_indexes_from_coords(coords))
3.26 merge.py(474):     for name, variable in coords.items():
3.26 merge.py(467):     return merge_core(
3.26 merge.py(468):         objects, compat, join, explicit_coords=explicit_coords, indexes=indexes
3.26 merge.py(467):     return merge_core(
3.26 merge.py(585):     from .dataarray import DataArray
3.26 merge.py(586):     from .dataset import Dataset, calculate_dimensions
3.26 merge.py(588):     _assert_compat_valid(compat)
3.26 merge.py(154):     if compat not in _VALID_COMPAT:
3.26 merge.py(590):     coerced = coerce_pandas_values(objects)
3.26 merge.py(384):     from .dataarray import DataArray
3.26 merge.py(385):     from .dataset import Dataset
3.26 merge.py(387):     out = []
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(392):             variables = {}
3.26 merge.py(393):             if isinstance(obj, PANDAS_TYPES):
3.26 merge.py(395):             for k, v in obj.items():
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(392):             variables = {}
3.26 merge.py(393):             if isinstance(obj, PANDAS_TYPES):
3.26 merge.py(395):             for k, v in obj.items():
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(400):     return out
3.26 merge.py(591):     aligned = deep_align(
3.26 merge.py(592):         coerced, join=join, copy=False, indexes=indexes, fill_value=fill_value
3.26 merge.py(591):     aligned = deep_align(
3.26 merge.py(594):     collected = collect_variables_and_indexes(aligned)
3.26 merge.py(251):     from .dataarray import DataArray
3.26 merge.py(252):     from .dataset import Dataset
3.26 merge.py(254):     grouped: Dict[Hashable, List[Tuple[Variable, pd.Index]]] = {}
3.26 merge.py(256):     def append(name, variable, index):
3.26 merge.py(260):     def append_all(variables, indexes):
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(265):         if isinstance(mapping, Dataset):
3.26 merge.py(269):         for name, variable in mapping.items():
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(265):         if isinstance(mapping, Dataset):
3.26 merge.py(269):         for name, variable in mapping.items():
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(286):     return grouped
3.26 merge.py(596):     prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)
3.26 merge.py(425):     if priority_arg is None:
3.26 merge.py(426):         return {}
3.26 merge.py(597):     variables, out_indexes = merge_collected(collected, prioritized, compat=compat)
3.26 merge.py(183):     if prioritized is None:
3.26 merge.py(186):     _assert_compat_valid(compat)
3.26 merge.py(154):     if compat not in _VALID_COMPAT:
3.26 merge.py(188):     merged_vars: Dict[Hashable, Variable] = {}
3.26 merge.py(189):     merged_indexes: Dict[Hashable, pd.Index] = {}
3.26 merge.py(191):     for name, elements_list in grouped.items():
3.26 merge.py(236):     return merged_vars, merged_indexes
3.26 merge.py(598):     assert_unique_multiindex_level_names(variables)
3.26 merge.py(600):     dims = calculate_dimensions(variables)
3.26 merge.py(602):     coord_names, noncoord_names = determine_coords(coerced)
3.26 merge.py(349):     from .dataarray import DataArray
3.26 merge.py(350):     from .dataset import Dataset
3.26 merge.py(352):     coord_names: Set[Hashable] = set()
3.26 merge.py(353):     noncoord_names: Set[Hashable] = set()
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(356):         if isinstance(mapping, Dataset):
3.26 merge.py(360):             for name, var in mapping.items():
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(356):         if isinstance(mapping, Dataset):
3.26 merge.py(360):             for name, var in mapping.items():
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(367):     return coord_names, noncoord_names
3.26 merge.py(603):     if explicit_coords is not None:
3.26 merge.py(604):         assert_valid_explicit_coords(variables, dims, explicit_coords)
3.26 merge.py(486):     for coord_name in explicit_coords:
3.26 merge.py(605):         coord_names.update(explicit_coords)
3.26 merge.py(606):     for dim, size in dims.items():
3.26 merge.py(609):     ambiguous_coords = coord_names.intersection(noncoord_names)
3.26 merge.py(610):     if ambiguous_coords:
3.26 merge.py(616):     attrs = merge_attrs(
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(622):         combine_attrs,
3.26 merge.py(616):     attrs = merge_attrs(
3.26 merge.py(497):     if not variable_attrs:
3.26 merge.py(499):         return None
3.26 merge.py(625):     return _MergeResult(variables, coord_names, dims, out_indexes, attrs)
3.26 merge.py(464):     objects = [data, coords]
3.26 merge.py(465):     explicit_coords = coords.keys()
3.26 merge.py(466):     indexes = dict(_extract_indexes_from_coords(coords))
3.26 merge.py(474):     for name, variable in coords.items():
3.26 merge.py(467):     return merge_core(
3.26 merge.py(468):         objects, compat, join, explicit_coords=explicit_coords, indexes=indexes
3.26 merge.py(467):     return merge_core(
3.26 merge.py(585):     from .dataarray import DataArray
3.26 merge.py(586):     from .dataset import Dataset, calculate_dimensions
3.26 merge.py(588):     _assert_compat_valid(compat)
3.26 merge.py(154):     if compat not in _VALID_COMPAT:
3.26 merge.py(590):     coerced = coerce_pandas_values(objects)
3.26 merge.py(384):     from .dataarray import DataArray
3.26 merge.py(385):     from .dataset import Dataset
3.26 merge.py(387):     out = []
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(392):             variables = {}
3.26 merge.py(393):             if isinstance(obj, PANDAS_TYPES):
3.26 merge.py(395):             for k, v in obj.items():
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(392):             variables = {}
3.26 merge.py(393):             if isinstance(obj, PANDAS_TYPES):
3.26 merge.py(395):             for k, v in obj.items():
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(400):     return out
3.26 merge.py(591):     aligned = deep_align(
3.26 merge.py(592):         coerced, join=join, copy=False, indexes=indexes, fill_value=fill_value
3.26 merge.py(591):     aligned = deep_align(
3.26 merge.py(594):     collected = collect_variables_and_indexes(aligned)
3.26 merge.py(251):     from .dataarray import DataArray
3.26 merge.py(252):     from .dataset import Dataset
3.26 merge.py(254):     grouped: Dict[Hashable, List[Tuple[Variable, pd.Index]]] = {}
3.26 merge.py(256):     def append(name, variable, index):
3.26 merge.py(260):     def append_all(variables, indexes):
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(265):         if isinstance(mapping, Dataset):
3.26 merge.py(269):         for name, variable in mapping.items():
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(265):         if isinstance(mapping, Dataset):
3.26 merge.py(269):         for name, variable in mapping.items():
3.26 merge.py(264):     for mapping in list_of_mappings:
3.26 merge.py(286):     return grouped
3.26 merge.py(596):     prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)
3.26 merge.py(425):     if priority_arg is None:
3.26 merge.py(426):         return {}
3.26 merge.py(597):     variables, out_indexes = merge_collected(collected, prioritized, compat=compat)
3.26 merge.py(183):     if prioritized is None:
3.26 merge.py(186):     _assert_compat_valid(compat)
3.26 merge.py(154):     if compat not in _VALID_COMPAT:
3.26 merge.py(188):     merged_vars: Dict[Hashable, Variable] = {}
3.26 merge.py(189):     merged_indexes: Dict[Hashable, pd.Index] = {}
3.26 merge.py(191):     for name, elements_list in grouped.items():
3.26 merge.py(236):     return merged_vars, merged_indexes
3.26 merge.py(598):     assert_unique_multiindex_level_names(variables)
3.26 merge.py(600):     dims = calculate_dimensions(variables)
3.26 merge.py(602):     coord_names, noncoord_names = determine_coords(coerced)
3.26 merge.py(349):     from .dataarray import DataArray
3.26 merge.py(350):     from .dataset import Dataset
3.26 merge.py(352):     coord_names: Set[Hashable] = set()
3.26 merge.py(353):     noncoord_names: Set[Hashable] = set()
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(356):         if isinstance(mapping, Dataset):
3.26 merge.py(360):             for name, var in mapping.items():
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(356):         if isinstance(mapping, Dataset):
3.26 merge.py(360):             for name, var in mapping.items():
3.26 merge.py(355):     for mapping in list_of_mappings:
3.26 merge.py(367):     return coord_names, noncoord_names
3.26 merge.py(603):     if explicit_coords is not None:
3.26 merge.py(604):         assert_valid_explicit_coords(variables, dims, explicit_coords)
3.26 merge.py(486):     for coord_name in explicit_coords:
3.26 merge.py(605):         coord_names.update(explicit_coords)
3.26 merge.py(606):     for dim, size in dims.items():
3.26 merge.py(609):     ambiguous_coords = coord_names.intersection(noncoord_names)
3.26 merge.py(610):     if ambiguous_coords:
3.26 merge.py(616):     attrs = merge_attrs(
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(619):             for var in coerced
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.26 merge.py(617):         [
3.26 merge.py(617):         [
3.26 merge.py(622):         combine_attrs,
3.26 merge.py(616):     attrs = merge_attrs(
3.26 merge.py(497):     if not variable_attrs:
3.26 merge.py(499):         return None
3.26 merge.py(625):     return _MergeResult(variables, coord_names, dims, out_indexes, attrs)
3.26 merge.py(843):     from .dataarray import DataArray
3.26 merge.py(844):     from .dataset import Dataset
3.26 merge.py(846):     dict_like_objects = []
3.26 merge.py(847):     for obj in objects:
3.26 merge.py(848):         if not isinstance(obj, (DataArray, Dataset, dict)):
3.26 merge.py(854):         obj = obj.to_dataset(promote_attrs=True) if isinstance(obj, DataArray) else obj
3.26 merge.py(855):         dict_like_objects.append(obj)
3.26 merge.py(847):     for obj in objects:
3.26 merge.py(848):         if not isinstance(obj, (DataArray, Dataset, dict)):
3.26 merge.py(854):         obj = obj.to_dataset(promote_attrs=True) if isinstance(obj, DataArray) else obj
3.26 merge.py(855):         dict_like_objects.append(obj)
3.26 merge.py(847):     for obj in objects:
3.26 merge.py(857):     merge_result = merge_core(
3.26 merge.py(858):         dict_like_objects,
3.26 merge.py(859):         compat,
3.26 merge.py(860):         join,
3.26 merge.py(861):         combine_attrs=combine_attrs,
3.26 merge.py(862):         fill_value=fill_value,
3.26 merge.py(857):     merge_result = merge_core(
3.26 merge.py(585):     from .dataarray import DataArray
3.26 merge.py(586):     from .dataset import Dataset, calculate_dimensions
3.26 merge.py(588):     _assert_compat_valid(compat)
3.26 merge.py(154):     if compat not in _VALID_COMPAT:
3.26 merge.py(590):     coerced = coerce_pandas_values(objects)
3.26 merge.py(384):     from .dataarray import DataArray
3.26 merge.py(385):     from .dataset import Dataset
3.26 merge.py(387):     out = []
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(390):             variables: "DatasetLike" = obj
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(389):         if isinstance(obj, Dataset):
3.26 merge.py(390):             variables: "DatasetLike" = obj
3.26 merge.py(399):         out.append(variables)
3.26 merge.py(388):     for obj in objects:
3.26 merge.py(400):     return out
3.26 merge.py(591):     aligned = deep_align(
3.26 merge.py(592):         coerced, join=join, copy=False, indexes=indexes, fill_value=fill_value
3.27 merge.py(591):     aligned = deep_align(
3.27 merge.py(594):     collected = collect_variables_and_indexes(aligned)
3.27 merge.py(251):     from .dataarray import DataArray
3.27 merge.py(252):     from .dataset import Dataset
3.27 merge.py(254):     grouped: Dict[Hashable, List[Tuple[Variable, pd.Index]]] = {}
3.27 merge.py(256):     def append(name, variable, index):
3.27 merge.py(260):     def append_all(variables, indexes):
3.27 merge.py(264):     for mapping in list_of_mappings:
3.27 merge.py(265):         if isinstance(mapping, Dataset):
3.27 merge.py(266):             append_all(mapping.variables, mapping.indexes)
3.27 merge.py(261):         for name, variable in variables.items():
3.27 merge.py(267):             continue
3.27 merge.py(264):     for mapping in list_of_mappings:
3.27 merge.py(265):         if isinstance(mapping, Dataset):
3.27 merge.py(266):             append_all(mapping.variables, mapping.indexes)
3.27 merge.py(261):         for name, variable in variables.items():
3.27 merge.py(267):             continue
3.27 merge.py(264):     for mapping in list_of_mappings:
3.27 merge.py(286):     return grouped
3.27 merge.py(596):     prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)
3.27 merge.py(425):     if priority_arg is None:
3.27 merge.py(426):         return {}
3.27 merge.py(597):     variables, out_indexes = merge_collected(collected, prioritized, compat=compat)
3.27 merge.py(183):     if prioritized is None:
3.27 merge.py(186):     _assert_compat_valid(compat)
3.27 merge.py(154):     if compat not in _VALID_COMPAT:
3.27 merge.py(188):     merged_vars: Dict[Hashable, Variable] = {}
3.27 merge.py(189):     merged_indexes: Dict[Hashable, pd.Index] = {}
3.27 merge.py(191):     for name, elements_list in grouped.items():
3.27 merge.py(236):     return merged_vars, merged_indexes
3.27 merge.py(598):     assert_unique_multiindex_level_names(variables)
3.27 merge.py(600):     dims = calculate_dimensions(variables)
3.27 merge.py(602):     coord_names, noncoord_names = determine_coords(coerced)
3.27 merge.py(349):     from .dataarray import DataArray
3.27 merge.py(350):     from .dataset import Dataset
3.27 merge.py(352):     coord_names: Set[Hashable] = set()
3.27 merge.py(353):     noncoord_names: Set[Hashable] = set()
3.27 merge.py(355):     for mapping in list_of_mappings:
3.27 merge.py(356):         if isinstance(mapping, Dataset):
3.27 merge.py(357):             coord_names.update(mapping.coords)
3.27 merge.py(358):             noncoord_names.update(mapping.data_vars)
3.27 merge.py(355):     for mapping in list_of_mappings:
3.27 merge.py(356):         if isinstance(mapping, Dataset):
3.27 merge.py(357):             coord_names.update(mapping.coords)
3.27 merge.py(358):             noncoord_names.update(mapping.data_vars)
3.27 merge.py(355):     for mapping in list_of_mappings:
3.27 merge.py(367):     return coord_names, noncoord_names
3.27 merge.py(603):     if explicit_coords is not None:
3.27 merge.py(606):     for dim, size in dims.items():
3.27 merge.py(609):     ambiguous_coords = coord_names.intersection(noncoord_names)
3.27 merge.py(610):     if ambiguous_coords:
3.27 merge.py(616):     attrs = merge_attrs(
3.27 merge.py(617):         [
3.27 merge.py(619):             for var in coerced
3.27 merge.py(617):         [
3.27 merge.py(617):         [
3.27 merge.py(619):             for var in coerced
3.27 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.27 merge.py(617):         [
3.27 merge.py(618):             var.attrs
3.27 merge.py(617):         [
3.27 merge.py(617):         [
3.27 merge.py(619):             for var in coerced
3.27 merge.py(620):             if isinstance(var, Dataset) or isinstance(var, DataArray)
3.27 merge.py(617):         [
3.27 merge.py(618):             var.attrs
3.27 merge.py(617):         [
3.27 merge.py(617):         [
3.27 merge.py(622):         combine_attrs,
3.27 merge.py(616):     attrs = merge_attrs(
3.27 merge.py(497):     if not variable_attrs:
3.27 merge.py(501):     if combine_attrs == "drop":
3.27 merge.py(503):     elif combine_attrs == "override":
3.27 merge.py(504):         return dict(variable_attrs[0])
3.27 merge.py(625):     return _MergeResult(variables, coord_names, dims, out_indexes, attrs)
3.27 merge.py(864):     merged = Dataset._construct_direct(**merge_result._asdict())
3.27 merge.py(865):     return merged
=========================== short test summary info ============================
PASSED xarray/tests/test_coverup_pydata__xarray-4629.py::test_merge_override_attrs_bug
======================== 1 passed, 9 warnings in 4.09s =========================
+ cat coverage.cover
{"/testbed/xarray/core/merge.py": {"1": 1, "18": 1, "20": 1, "21": 1, "22": 1, "23": 1, "24": 1, "26": 1, "27": 0, "28": 0, "29": 0, "31": 0, "32": 0, "33": 0, "34": 0, "35": 0, "36": 0, "37": 0, "39": 0, "40": 0, "41": 0, "42": 0, "45": 1, "47": 2, "49": 1, "50": 1, "51": 1, "52": 1, "53": 1, "54": 1, "48": 1, "59": 1, "73": 2, "83": 2, "84": 2, "80": 6, "81": 1, "82": 1, "85": 1, "153": 1, "160": 1, "165": 2, "166": 2, "163": 5, "164": 1, "167": 1, "239": 3, "240": 1, "241": 1, "289": 3, "290": 1, "291": 1, "306": 2, "307": 2, "304": 5, "305": 1, "308": 1, "332": 3, "333": 1, "334": 1, "370": 1, "404": 4, "403": 5, "405": 1, "438": 2, "439": 2, "440": 2, "441": 2, "442": 2, "436": 8, "437": 1, "443": 1, "462": 1, "472": 1, "480": 1, "495": 1, "529": 2, "539": 2, "540": 2, "541": 2, "542": 2, "543": 2, "544": 2, "545": 2, "537": 10, "538": 1, "546": 1, "630": 2, "631": 2, "632": 2, "633": 2, "628": 7, "629": 1, "634": 1, "868": 8, "869": 1, "870": 1, "871": 1, "872": 1, "873": 1, "874": 1, "875": 1, "908": 4, "909": 2, "910": 1, "64": 0, "65": 0, "66": 0, "67": 0, "68": 0, "69": 0, "70": 0, "108": 0, "110": 0, "111": 0, "113": 0, "115": 0, "116": 0, "118": 0, "119": 0, "120": 0, "122": 0, "123": 0, "125": 0, "127": 0, "128": 0, "129": 0, "130": 0, "132": 0, "134": 0, "135": 0, "136": 0, "137": 0, "138": 0, "140": 0, "141": 0, "142": 0, "146": 0, "147": 0, "148": 0, "150": 0, "154": 6, "155": 0, "156": 0, "183": 3, "184": 0, "186": 3, "188": 3, "189": 3, "191": 3, "192": 0, "193": 0, "194": 0, "195": 0, "196": 0, "198": 0, "200": 0, "204": 0, "208": 0, "209": 0, "210": 0, "211": 0, "212": 0, "214": 0, "216": 0, "217": 0, "218": 0, "219": 0, "220": 0, "222": 0, "224": 0, "225": 0, "227": 0, "228": 0, "229": 0, "230": 0, "231": 0, "234": 0, "236": 3, "201": 0, "199": 0, "251": 3, "252": 3, "254": 3, "256": 3, "260": 3, "264": 9, "265": 6, "266": 2, "267": 2, "269": 4, "270": 0, "271": 0, "272": 0, "274": 0, "275": 0, "276": 0, "278": 0, "279": 0, "280": 0, "281": 0, "283": 0, "284": 0, "286": 3, "257": 0, "258": 0, "261": 2, "262": 0, "293": 0, "295": 0, "296": 0, "297": 0, "298": 0, "299": 0, "300": 0, "301": 0, "314": 0, "316": 0, "317": 0, "318": 0, "319": 0, "321": 0, "324": 0, "325": 0, "327": 0, "329": 0, "322": 0, "320": 0, "349": 3, "350": 3, "352": 3, "353": 3, "355": 9, "356": 6, "357": 2, "358": 2, "360": 4, "361": 0, "362": 0, "364": 0, "365": 0, "367": 3, "384": 3, "385": 3, "387": 3, "388": 9, "389": 6, "390": 2, "392": 4, "393": 4, "394": 0, "395": 4, "396": 0, "397": 0, "398": 0, "399": 6, "400": 3, "425": 3, "426": 3, "428": 0, "429": 0, "430": 0, "431": 0, "432": 0, "433": 0, "450": 0, "451": 0, "452": 0, "453": 0, "455": 0, "456": 0, "457": 0, "458": 0, "459": 0, "464": 2, "465": 2, "466": 2, "467": 4, "468": 2, "474": 2, "475": 0, "476": 0, "477": 0, "486": 2, "487": 0, "488": 0, "489": 0, "491": 0, "497": 3, "499": 2, "501": 1, "502": 0, "503": 1, "504": 1, "505": 0, "506": 0, "507": 0, "508": 0, "509": 0, "510": 0, "511": 0, "512": 0, "513": 0, "515": 0, "516": 0, "517": 0, "518": 0, "519": 0, "520": 0, "521": 0, "522": 0, "524": 0, "526": 0, "530": 1, "531": 1, "532": 1, "533": 1, "534": 1, "585": 3, "586": 3, "588": 3, "590": 3, "591": 6, "592": 3, "594": 3, "596": 3, "597": 3, "598": 3, "600": 3, "602": 3, "603": 3, "604": 2, "605": 2, "606": 3, "607": 0, "608": 0, "609": 3, "610": 3, "611": 0, "612": 0, "613": 0, "616": 6, "617": 27, "619": 9, "622": 3, "625": 3, "620": 10, "618": 2, "843": 1, "844": 1, "846": 1, "847": 3, "848": 2, "849": 0, "850": 0, "854": 2, "855": 2, "857": 2, "858": 1, "859": 1, "860": 1, "861": 1, "862": 1, "864": 1, "865": 1, "881": 0, "882": 0, "884": 0, "886": 0, "887": 0, "888": 0, "889": 0, "890": 0, "891": 0, "893": 0, "894": 0, "895": 0, "896": 0, "897": 0, "899": 0, "900": 0, "901": 0, "903": 0, "904": 0, "917": 0, "918": 0, "920": 0, "921": 0, "922": 0, "923": 0, "925": 0, "927": 0, "930": 0, "931": 0, "933": 0, "934": 0, "935": 0, "936": 0, "937": 0, "928": 0, "926": 0}}
+ git checkout a41edc7bf5302f2ea327943c0c48c532b12009bc
Note: switching to 'a41edc7bf5302f2ea327943c0c48c532b12009bc'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at a41edc7b weighted: de-parameterize tests (#4617)
M	xarray/core/merge.py
+ git apply /root/pre_state.patch
error: unrecognized input
