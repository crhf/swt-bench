+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD 4aded39b5663d943f6a4809abacfa9cae3d7fb6a
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit 4aded39b5663d943f6a4809abacfa9cae3d7fb6a
Author: Samesh Lakhotia <43701530+sameshl@users.noreply.github.com>
Date:   Wed Aug 14 10:15:59 2019 +0530

    MAINT Remove the use of assert_raises and assert_raises_regex (#14645)

diff --git a/sklearn/cluster/tests/test_hierarchical.py b/sklearn/cluster/tests/test_hierarchical.py
index c630ea5d2e..ca021fc30f 100644
--- a/sklearn/cluster/tests/test_hierarchical.py
+++ b/sklearn/cluster/tests/test_hierarchical.py
@@ -15,7 +15,6 @@ from scipy import sparse
 from scipy.cluster import hierarchy
 
 from sklearn.metrics.cluster.supervised import adjusted_rand_score
-from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import assert_almost_equal
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_raise_message
@@ -41,9 +40,14 @@ def test_linkage_misc():
     # Misc tests on linkage
     rng = np.random.RandomState(42)
     X = rng.normal(size=(5, 5))
-    assert_raises(ValueError, AgglomerativeClustering(linkage='foo').fit, X)
-    assert_raises(ValueError, linkage_tree, X, linkage='foo')
-    assert_raises(ValueError, linkage_tree, X, connectivity=np.ones((4, 4)))
+    with pytest.raises(ValueError):
+        AgglomerativeClustering(linkage='foo').fit(X)
+
+    with pytest.raises(ValueError):
+        linkage_tree(X, linkage='foo')
+
+    with pytest.raises(ValueError):
+        linkage_tree(X, connectivity=np.ones((4, 4)))
 
     # Smoke test FeatureAgglomeration
     FeatureAgglomeration().fit(X)
@@ -74,11 +78,11 @@ def test_structured_linkage_tree():
         assert len(children) + n_leaves == n_nodes
         # Check that ward_tree raises a ValueError with a connectivity matrix
         # of the wrong shape
-        assert_raises(ValueError,
-                      tree_builder, X.T, np.ones((4, 4)))
+        with pytest.raises(ValueError):
+            tree_builder(X.T, np.ones((4, 4)))
         # Check that fitting with no samples raises an error
-        assert_raises(ValueError,
-                      tree_builder, X.T[:0], connectivity)
+        with pytest.raises(ValueError):
+            tree_builder(X.T[:0], connectivity)
 
 
 def test_unstructured_linkage_tree():
@@ -124,7 +128,8 @@ def test_agglomerative_clustering_wrong_arg_memory():
     X = rng.randn(n_samples, 50)
     memory = 5
     clustering = AgglomerativeClustering(memory=memory)
-    assert_raises(ValueError, clustering.fit, X)
+    with pytest.raises(ValueError):
+        clustering.fit(X)
 
 
 def test_zero_cosine_linkage_tree():
@@ -179,7 +184,8 @@ def test_agglomerative_clustering():
             connectivity=sparse.lil_matrix(
                 connectivity.toarray()[:10, :10]),
             linkage=linkage)
-        assert_raises(ValueError, clustering.fit, X)
+        with pytest.raises(ValueError):
+            clustering.fit(X)
 
     # Test that using ward with another metric than euclidean raises an
     # exception
@@ -188,7 +194,8 @@ def test_agglomerative_clustering():
         connectivity=connectivity.toarray(),
         affinity="manhattan",
         linkage="ward")
-    assert_raises(ValueError, clustering.fit, X)
+    with pytest.raises(ValueError):
+        clustering.fit(X)
 
     # Test using another metric than euclidean works with linkage complete
     for affinity in PAIRED_DISTANCES.keys():
@@ -241,7 +248,8 @@ def test_ward_agglomeration():
     assert_array_almost_equal(agglo.transform(X_full), X_red)
 
     # Check that fitting with no samples raises a ValueError
-    assert_raises(ValueError, agglo.fit, X[:0])
+    with pytest.raises(ValueError):
+        agglo.fit(X[:0])
 
 
 def test_single_linkage_clustering():
@@ -302,7 +310,8 @@ def test_scikit_vs_scipy():
             assess_same_labelling(cut, cut_)
 
     # Test error management in _hc_cut
-    assert_raises(ValueError, _hc_cut, n_leaves + 1, children, n_leaves)
+    with pytest.raises(ValueError):
+        _hc_cut(n_leaves + 1, children, n_leaves)
 
 
 def test_identical_points():
+ git diff 4aded39b5663d943f6a4809abacfa9cae3d7fb6a
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-nyoqlidv/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.5.2)
Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.1.1)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.22.dev0
    Uninstalling scikit-learn-0.22.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.22.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    compile options: '-c'
    extra options: '-fopenmp'
    gcc: test_openmp.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ objects/test_openmp.o -o test_openmp -fopenmp
    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.histogram" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.splitting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._binning" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._predictor" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._loss" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.types" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.utils" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn._isotonic" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.22.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.22.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git apply -v -
Checking patch sklearn/multioutput.py...
Applied patch sklearn/multioutput.py cleanly.
+ git apply -v -
<stdin>:22: trailing whitespace.
    
Checking patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py...
Applied patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py cleanly.
warning: 1 line adds whitespace errors.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(sklearn/multioutput\.py)' -m pytest --no-header -rA -p no:cacheprovider sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(sklearn/multioutput\\.py)']
============================= test session starts ==============================
collected 1 item

sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py F         [100%]

=================================== FAILURES ===================================
_______ test_cross_val_predict_with_multioutputclassifier_predict_proba ________

    def test_cross_val_predict_with_multioutputclassifier_predict_proba():
        # Generate a multilabel classification dataset
        X, Y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=3, n_labels=2, random_state=42)
    
        # Initialize a MultiOutputClassifier with LinearDiscriminantAnalysis
        mo_lda = MultiOutputClassifier(LinearDiscriminantAnalysis())
    
        # Expect the function to run without errors and return an array of prediction probabilities
        pred_proba = cross_val_predict(mo_lda, X, Y, cv=5, method='predict_proba')
    
        # Check if the output is of the expected shape
>       assert pred_proba.shape == (100, 3, 2)
E       AttributeError: 'list' object has no attribute 'shape'

sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py:18: AttributeError
----------------------------- Captured stdout call -----------------------------
1.07 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.07 multioutput.py(67):         self.estimator = estimator
1.07 multioutput.py(68):         self.n_jobs = n_jobs
1.08 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.08 multioutput.py(67):         self.estimator = estimator
1.08 multioutput.py(68):         self.n_jobs = n_jobs
1.08 multioutput.py(346):         super().fit(X, Y, sample_weight)
1.08 multioutput.py(147):         if not hasattr(self.estimator, "fit"):
1.08 multioutput.py(151):         X, y = check_X_y(X, y,
1.08 multioutput.py(152):                          multi_output=True,
1.08 multioutput.py(153):                          accept_sparse=True)
1.08 multioutput.py(155):         if is_classifier(self):
1.08 multioutput.py(156):             check_classification_targets(y)
1.08 multioutput.py(158):         if y.ndim == 1:
1.08 multioutput.py(162):         if (sample_weight is not None and
1.08 multioutput.py(167):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(171):         return self
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(348):         return self
1.08 multioutput.py(369):         check_is_fitted(self)
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(376):                    self.estimators_]
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(377):         return results
1.08 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.08 multioutput.py(67):         self.estimator = estimator
1.08 multioutput.py(68):         self.n_jobs = n_jobs
1.08 multioutput.py(346):         super().fit(X, Y, sample_weight)
1.08 multioutput.py(147):         if not hasattr(self.estimator, "fit"):
1.08 multioutput.py(151):         X, y = check_X_y(X, y,
1.08 multioutput.py(152):                          multi_output=True,
1.08 multioutput.py(153):                          accept_sparse=True)
1.08 multioutput.py(155):         if is_classifier(self):
1.08 multioutput.py(156):             check_classification_targets(y)
1.08 multioutput.py(158):         if y.ndim == 1:
1.08 multioutput.py(162):         if (sample_weight is not None and
1.08 multioutput.py(167):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(170):             for i in range(y.shape[1]))
1.08 multioutput.py(36):     estimator = clone(estimator)
1.08 multioutput.py(37):     if sample_weight is not None:
1.08 multioutput.py(40):         estimator.fit(X, y)
1.08 multioutput.py(41):     return estimator
1.08 multioutput.py(168):             delayed(_fit_estimator)(
1.08 multioutput.py(171):         return self
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.08 multioutput.py(348):         return self
1.08 multioutput.py(369):         check_is_fitted(self)
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(371):                     for estimator in self.estimators_]):
1.08 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(376):                    self.estimators_]
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.08 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(377):         return results
1.09 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.09 multioutput.py(67):         self.estimator = estimator
1.09 multioutput.py(68):         self.n_jobs = n_jobs
1.09 multioutput.py(346):         super().fit(X, Y, sample_weight)
1.09 multioutput.py(147):         if not hasattr(self.estimator, "fit"):
1.09 multioutput.py(151):         X, y = check_X_y(X, y,
1.09 multioutput.py(152):                          multi_output=True,
1.09 multioutput.py(153):                          accept_sparse=True)
1.09 multioutput.py(155):         if is_classifier(self):
1.09 multioutput.py(156):             check_classification_targets(y)
1.09 multioutput.py(158):         if y.ndim == 1:
1.09 multioutput.py(162):         if (sample_weight is not None and
1.09 multioutput.py(167):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(171):         return self
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(348):         return self
1.09 multioutput.py(369):         check_is_fitted(self)
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(376):                    self.estimators_]
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(377):         return results
1.09 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.09 multioutput.py(67):         self.estimator = estimator
1.09 multioutput.py(68):         self.n_jobs = n_jobs
1.09 multioutput.py(346):         super().fit(X, Y, sample_weight)
1.09 multioutput.py(147):         if not hasattr(self.estimator, "fit"):
1.09 multioutput.py(151):         X, y = check_X_y(X, y,
1.09 multioutput.py(152):                          multi_output=True,
1.09 multioutput.py(153):                          accept_sparse=True)
1.09 multioutput.py(155):         if is_classifier(self):
1.09 multioutput.py(156):             check_classification_targets(y)
1.09 multioutput.py(158):         if y.ndim == 1:
1.09 multioutput.py(162):         if (sample_weight is not None and
1.09 multioutput.py(167):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(170):             for i in range(y.shape[1]))
1.09 multioutput.py(36):     estimator = clone(estimator)
1.09 multioutput.py(37):     if sample_weight is not None:
1.09 multioutput.py(40):         estimator.fit(X, y)
1.09 multioutput.py(41):     return estimator
1.09 multioutput.py(168):             delayed(_fit_estimator)(
1.09 multioutput.py(171):         return self
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.09 multioutput.py(348):         return self
1.09 multioutput.py(369):         check_is_fitted(self)
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(371):                     for estimator in self.estimators_]):
1.09 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(376):                    self.estimators_]
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.09 multioutput.py(377):         return results
1.09 multioutput.py(326):         super().__init__(estimator, n_jobs)
1.10 multioutput.py(67):         self.estimator = estimator
1.10 multioutput.py(68):         self.n_jobs = n_jobs
1.10 multioutput.py(346):         super().fit(X, Y, sample_weight)
1.10 multioutput.py(147):         if not hasattr(self.estimator, "fit"):
1.10 multioutput.py(151):         X, y = check_X_y(X, y,
1.10 multioutput.py(152):                          multi_output=True,
1.10 multioutput.py(153):                          accept_sparse=True)
1.10 multioutput.py(155):         if is_classifier(self):
1.10 multioutput.py(156):             check_classification_targets(y)
1.10 multioutput.py(158):         if y.ndim == 1:
1.10 multioutput.py(162):         if (sample_weight is not None and
1.10 multioutput.py(167):         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
1.10 multioutput.py(168):             delayed(_fit_estimator)(
1.10 multioutput.py(170):             for i in range(y.shape[1]))
1.10 multioutput.py(168):             delayed(_fit_estimator)(
1.10 multioutput.py(170):             for i in range(y.shape[1]))
1.10 multioutput.py(36):     estimator = clone(estimator)
1.10 multioutput.py(37):     if sample_weight is not None:
1.10 multioutput.py(40):         estimator.fit(X, y)
1.10 multioutput.py(41):     return estimator
1.10 multioutput.py(168):             delayed(_fit_estimator)(
1.10 multioutput.py(170):             for i in range(y.shape[1]))
1.10 multioutput.py(36):     estimator = clone(estimator)
1.10 multioutput.py(37):     if sample_weight is not None:
1.10 multioutput.py(40):         estimator.fit(X, y)
1.10 multioutput.py(41):     return estimator
1.10 multioutput.py(168):             delayed(_fit_estimator)(
1.10 multioutput.py(170):             for i in range(y.shape[1]))
1.10 multioutput.py(36):     estimator = clone(estimator)
1.10 multioutput.py(37):     if sample_weight is not None:
1.10 multioutput.py(40):         estimator.fit(X, y)
1.10 multioutput.py(41):     return estimator
1.10 multioutput.py(168):             delayed(_fit_estimator)(
1.10 multioutput.py(171):         return self
1.10 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.10 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.10 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.10 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.10 multioutput.py(347):         self.classes_ = [estimator.classes_ for estimator in self.estimators_]
1.10 multioutput.py(348):         return self
1.10 multioutput.py(369):         check_is_fitted(self)
1.10 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.10 multioutput.py(371):                     for estimator in self.estimators_]):
1.10 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.10 multioutput.py(371):                     for estimator in self.estimators_]):
1.10 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.10 multioutput.py(371):                     for estimator in self.estimators_]):
1.10 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.10 multioutput.py(371):                     for estimator in self.estimators_]):
1.10 multioutput.py(370):         if not all([hasattr(estimator, "predict_proba")
1.10 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.10 multioutput.py(376):                    self.estimators_]
1.10 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.10 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.10 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.10 multioutput.py(375):         results = [estimator.predict_proba(X) for estimator in
1.10 multioutput.py(377):         return results
=========================== short test summary info ============================
FAILED sklearn/tests/test_coverup_scikit-learn__scikit-learn-14629.py::test_cross_val_predict_with_multioutputclassifier_predict_proba
========================= 1 failed, 1 warning in 0.52s =========================
+ cat coverage.cover
{"/testbed/sklearn/multioutput.py": {"17": 1, "18": 1, "19": 1, "21": 1, "22": 1, "23": 1, "24": 1, "25": 1, "26": 1, "27": 1, "28": 1, "29": 1, "31": 1, "32": 1, "35": 1, "45": 1, "63": 2, "64": 1, "205": 2, "300": 2, "412": 2, "518": 2, "678": 2, "36": 15, "37": 15, "38": 0, "40": 15, "41": 15, "46": 0, "47": 0, "49": 0, "50": 0, "51": 0, "52": 0, "54": 0, "56": 0, "57": 0, "59": 0, "60": 0, "65": 1, "66": 1, "70": 1, "71": 1, "124": 1, "173": 1, "201": 1, "67": 6, "68": 6, "101": 0, "102": 0, "103": 0, "105": 0, "106": 0, "109": 0, "110": 0, "111": 0, "114": 0, "116": 0, "117": 0, "121": 0, "122": 0, "147": 5, "148": 0, "151": 5, "152": 5, "153": 5, "155": 5, "156": 5, "158": 5, "159": 0, "162": 5, "163": 0, "164": 0, "167": 5, "168": 25, "170": 20, "171": 5, "188": 0, "189": 0, "190": 0, "193": 0, "195": 0, "196": 0, "197": 0, "199": 0, "202": 0, "233": 1, "236": 1, "237": 1, "262": 1, "234": 0, "258": 0, "259": 0, "295": 0, "296": 0, "297": 0, "325": 1, "328": 1, "350": 1, "379": 1, "407": 1, "326": 6, "346": 5, "347": 25, "348": 5, "369": 5, "370": 25, "371": 20, "372": 0, "375": 25, "376": 5, "377": 5, "395": 0, "396": 0, "397": 0, "398": 0, "400": 0, "401": 0, "403": 0, "404": 0, "405": 0, "409": 0, "413": 1, "419": 1, "483": 1, "414": 0, "415": 0, "416": 0, "417": 0, "434": 0, "436": 0, "437": 0, "438": 0, "439": 0, "440": 0, "441": 0, "442": 0, "443": 0, "444": 0, "445": 0, "447": 0, "448": 0, "450": 0, "451": 0, "452": 0, "453": 0, "454": 0, "456": 0, "458": 0, "459": 0, "460": 0, "463": 0, "464": 0, "466": 0, "468": 0, "469": 0, "470": 0, "471": 0, "472": 0, "473": 0, "474": 0, "475": 0, "476": 0, "477": 0, "479": 0, "481": 0, "497": 0, "498": 0, "499": 0, "500": 0, "501": 0, "502": 0, "503": 0, "504": 0, "506": 0, "508": 0, "509": 0, "511": 0, "512": 0, "513": 0, "515": 0, "593": 1, "613": 1, "642": 1, "673": 1, "607": 0, "608": 0, "610": 0, "611": 0, "609": 0, "625": 0, "626": 0, "627": 0, "628": 0, "629": 0, "630": 0, "631": 0, "633": 0, "634": 0, "635": 0, "636": 0, "637": 0, "638": 0, "640": 0, "656": 0, "657": 0, "658": 0, "659": 0, "660": 0, "661": 0, "663": 0, "664": 0, "665": 0, "667": 0, "668": 0, "669": 0, "671": 0, "674": 0, "675": 0, "743": 1, "760": 1, "757": 0, "758": 0, "761": 0}}
+ git checkout 4aded39b5663d943f6a4809abacfa9cae3d7fb6a
Note: switching to '4aded39b5663d943f6a4809abacfa9cae3d7fb6a'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 4aded39b56 MAINT Remove the use of assert_raises and assert_raises_regex (#14645)
M	sklearn/multioutput.py
+ git apply /root/pre_state.patch
error: unrecognized input
