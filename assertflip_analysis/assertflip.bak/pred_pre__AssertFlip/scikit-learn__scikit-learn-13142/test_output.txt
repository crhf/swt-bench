+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD 1c8668b0a021832386470ddf740d834e02c66f69
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit 1c8668b0a021832386470ddf740d834e02c66f69
Author: Joel Nothman <joel.nothman@gmail.com>
Date:   Thu Feb 14 13:27:46 2019 +1100

    DOC what's new: Fix class name

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index fc54574145..7355f75b83 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -202,7 +202,7 @@ Support for Python 3.4 and below has been officially dropped.
 ..............................
 
 - |Feature| Classes :class:`~model_selection.GridSearchCV` and
-  :class:`~model_selection.RandomSearchCV` now allow for refit=callable
+  :class:`~model_selection.RandomizedSearchCV` now allow for refit=callable
   to add flexibility in identifying the best
   estimator. An example for this interface has been added.
   :issue:`11354` by :user:`Wenhao Zhang <wenhaoz@ucla.edu>`,
+ git diff 1c8668b0a021832386470ddf740d834e02c66f69
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-sd_99cbi/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.21.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.21.dev0) (1.5.2)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.21.dev0
    Uninstalling scikit-learn-0.21.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.21.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    blas_opt_info:
    blas_mkl_info:
    customize UnixCCompiler
      libraries mkl_rt not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    blis_info:
      libraries blis not found in ['/opt/miniconda3/envs/testbed/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
      NOT AVAILABLE

    openblas_info:
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    creating /tmp/tmpgipy6t46/tmp
    creating /tmp/tmpgipy6t46/tmp/tmpgipy6t46
    compile options: '-c'
    gcc: /tmp/tmpgipy6t46/source.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ /tmp/tmpgipy6t46/tmp/tmpgipy6t46/source.o -L/opt/miniconda3/envs/testbed/lib -lopenblas -o /tmp/tmpgipy6t46/a.out
      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

      FOUND:
        libraries = ['openblas', 'openblas']
        library_dirs = ['/opt/miniconda3/envs/testbed/lib']
        language = c
        define_macros = [('HAVE_CBLAS', None)]

    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means" sources
    building extension "sklearn.datasets._svmlight_format" sources
    building extension "sklearn.decomposition._online_lda" sources
    building extension "sklearn.decomposition.cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.feature_extraction._hashing" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster.expected_mutual_info_fast" sources
    building extension "sklearn.metrics.pairwise_fast" sources
    building extension "sklearn.neighbors.ball_tree" sources
    building extension "sklearn.neighbors.kd_tree" sources
    building extension "sklearn.neighbors.dist_metrics" sources
    building extension "sklearn.neighbors.typedefs" sources
    building extension "sklearn.neighbors.quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.svm.libsvm" sources
    building extension "sklearn.svm.liblinear" sources
    building extension "sklearn.svm.libsvm_sparse" sources
    building extension "sklearn._isotonic" sources
    building extension "sklearn.linear_model.cd_fast" sources
    building extension "sklearn.linear_model.sgd_fast" sources
    building extension "sklearn.linear_model.sag_fast" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.lgamma" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils.fast_dict" sources
    building extension "sklearn.utils.seq_dataset" sources
    building extension "sklearn.utils.weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    resetting extension 'sklearn.svm.liblinear' language from 'c' to 'c++'.
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.21.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.21.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git apply -v -
Checking patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py...
Applied patch sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py cleanly.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(sklearn/mixture/base\.py)' -m pytest --no-header -rA -p no:cacheprovider sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(sklearn/mixture/base\\.py)']
============================= test session starts ==============================
collected 1 item

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py F         [100%]

=================================== FAILURES ===================================
________________ test_gaussian_mixture_fit_predict_discrepancy _________________

    def test_gaussian_mixture_fit_predict_discrepancy():
        # Generate random data with a fixed seed for reproducibility
        rng = np.random.RandomState(42)
        X = rng.randn(1000, 5)
    
        # Initialize GaussianMixture with n_components=5 and n_init=5
        gm = GaussianMixture(n_components=5, n_init=5, random_state=42)
    
        # Fit and predict using fit_predict
        c1 = gm.fit_predict(X)
    
        # Predict using predict
        c2 = gm.predict(X)
    
        # Assert that the results are the same, which is the expected correct behavior
>       assert np.array_equal(c1, c2), "fit_predict and predict should agree when n_init > 1"
E       AssertionError: fit_predict and predict should agree when n_init > 1
E       assert False
E        +  where False = <function array_equal at 0x7f62d982e048>(array([4, 1, 3, 0, 3, 0, 1, 3, 3, 0, 4, 4, 3, 4, 1, 3, 1, 1, 3, 2, 2, 1,\n       2, 4, 0, 3, 2, 3, 3, 4, 3, 1, 0, 1, 2,...4, 4, 4,\n       0, 0, 2, 1, 3, 2, 1, 0, 1, 0, 2, 4, 2, 3, 1, 4, 1, 0, 0, 4, 0, 3,\n       1, 0, 4, 0, 3, 2, 2, 4, 2, 1]), array([1, 4, 1, 1, 4, 2, 4, 3, 1, 1, 0, 0, 3, 2, 1, 1, 1, 4, 4, 1, 3, 4,\n       0, 0, 2, 3, 0, 3, 0, 3, 0, 4, 2, 1, 0,...1, 3, 3,\n       2, 2, 4, 4, 3, 0, 4, 2, 0, 2, 3, 0, 3, 3, 1, 0, 2, 3, 2, 1, 2, 3,\n       1, 1, 3, 2, 4, 0, 4, 2, 0, 1]))
E        +    where <function array_equal at 0x7f62d982e048> = np.array_equal

sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py:20: AssertionError
----------------------------- Captured stdout call -----------------------------
0.84 base.py(74):         self.n_components = n_components
0.84 base.py(75):         self.tol = tol
0.84 base.py(76):         self.reg_covar = reg_covar
0.84 base.py(77):         self.max_iter = max_iter
0.84 base.py(78):         self.n_init = n_init
0.84 base.py(79):         self.init_params = init_params
0.84 base.py(80):         self.random_state = random_state
0.84 base.py(81):         self.warm_start = warm_start
0.84 base.py(82):         self.verbose = verbose
0.84 base.py(83):         self.verbose_interval = verbose_interval
0.84 base.py(217):         X = _check_X(X, self.n_components, ensure_min_samples=2)
0.84 base.py(51):     X = check_array(X, dtype=[np.float64, np.float32],
0.84 base.py(52):                     ensure_min_samples=ensure_min_samples)
0.84 base.py(53):     if n_components is not None and X.shape[0] < n_components:
0.84 base.py(57):     if n_features is not None and X.shape[1] != n_features:
0.84 base.py(61):     return X
0.84 base.py(218):         self._check_initial_parameters(X)
0.84 base.py(92):         if self.n_components < 1:
0.84 base.py(97):         if self.tol < 0.:
0.84 base.py(102):         if self.n_init < 1:
0.84 base.py(107):         if self.max_iter < 1:
0.84 base.py(112):         if self.reg_covar < 0.:
0.84 base.py(119):         self._check_parameters(X)
0.84 base.py(221):         do_init = not(self.warm_start and hasattr(self, 'converged_'))
0.84 base.py(222):         n_init = self.n_init if do_init else 1
0.84 base.py(224):         max_lower_bound = -np.infty
0.84 base.py(225):         self.converged_ = False
0.84 base.py(227):         random_state = check_random_state(self.random_state)
0.84 base.py(229):         n_samples, _ = X.shape
0.84 base.py(230):         for init in range(n_init):
0.84 base.py(231):             self._print_verbose_msg_init_beg(init)
0.84 base.py(512):         if self.verbose == 1:
0.84 base.py(514):         elif self.verbose >= 2:
0.84 base.py(233):             if do_init:
0.84 base.py(234):                 self._initialize_parameters(X, random_state)
0.84 base.py(141):         n_samples, _ = X.shape
0.84 base.py(143):         if self.init_params == 'kmeans':
0.84 base.py(144):             resp = np.zeros((n_samples, self.n_components))
0.84 base.py(145):             label = cluster.KMeans(n_clusters=self.n_components, n_init=1,
0.84 base.py(146):                                    random_state=random_state).fit(X).labels_
0.85 base.py(147):             resp[np.arange(n_samples), label] = 1
0.85 base.py(155):         self._initialize(X, resp)
0.86 base.py(236):             lower_bound = (-np.infty if do_init else self.lower_bound_)
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.86 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.86 base.py(505):         with np.errstate(under='ignore'):
0.86 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.86 base.py(508):         return log_prob_norm, log_resp
0.86 base.py(295):         return np.mean(log_prob_norm), log_resp
0.86 base.py(242):                 self._m_step(X, log_resp)
0.86 base.py(243):                 lower_bound = self._compute_lower_bound(
0.86 base.py(244):                     log_resp, log_prob_norm)
0.86 base.py(246):                 change = lower_bound - prev_lower_bound
0.86 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.86 base.py(521):         if n_iter % self.verbose_interval == 0:
0.86 base.py(249):                 if abs(change) < self.tol:
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.86 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.86 base.py(505):         with np.errstate(under='ignore'):
0.86 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.86 base.py(508):         return log_prob_norm, log_resp
0.86 base.py(295):         return np.mean(log_prob_norm), log_resp
0.86 base.py(242):                 self._m_step(X, log_resp)
0.86 base.py(243):                 lower_bound = self._compute_lower_bound(
0.86 base.py(244):                     log_resp, log_prob_norm)
0.86 base.py(246):                 change = lower_bound - prev_lower_bound
0.86 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.86 base.py(521):         if n_iter % self.verbose_interval == 0:
0.86 base.py(249):                 if abs(change) < self.tol:
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.86 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.86 base.py(505):         with np.errstate(under='ignore'):
0.86 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.86 base.py(508):         return log_prob_norm, log_resp
0.86 base.py(295):         return np.mean(log_prob_norm), log_resp
0.86 base.py(242):                 self._m_step(X, log_resp)
0.86 base.py(243):                 lower_bound = self._compute_lower_bound(
0.86 base.py(244):                     log_resp, log_prob_norm)
0.86 base.py(246):                 change = lower_bound - prev_lower_bound
0.86 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.86 base.py(521):         if n_iter % self.verbose_interval == 0:
0.86 base.py(249):                 if abs(change) < self.tol:
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.86 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.86 base.py(505):         with np.errstate(under='ignore'):
0.86 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.86 base.py(508):         return log_prob_norm, log_resp
0.86 base.py(295):         return np.mean(log_prob_norm), log_resp
0.86 base.py(242):                 self._m_step(X, log_resp)
0.86 base.py(243):                 lower_bound = self._compute_lower_bound(
0.86 base.py(244):                     log_resp, log_prob_norm)
0.86 base.py(246):                 change = lower_bound - prev_lower_bound
0.86 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.86 base.py(521):         if n_iter % self.verbose_interval == 0:
0.86 base.py(249):                 if abs(change) < self.tol:
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.86 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.86 base.py(505):         with np.errstate(under='ignore'):
0.86 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.86 base.py(508):         return log_prob_norm, log_resp
0.86 base.py(295):         return np.mean(log_prob_norm), log_resp
0.86 base.py(242):                 self._m_step(X, log_resp)
0.86 base.py(243):                 lower_bound = self._compute_lower_bound(
0.86 base.py(244):                     log_resp, log_prob_norm)
0.86 base.py(246):                 change = lower_bound - prev_lower_bound
0.86 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.86 base.py(521):         if n_iter % self.verbose_interval == 0:
0.86 base.py(249):                 if abs(change) < self.tol:
0.86 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.86 base.py(239):                 prev_lower_bound = lower_bound
0.86 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.86 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.86 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.86 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(522):             if self.verbose == 1:
0.87 base.py(524):             elif self.verbose >= 2:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.87 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.87 base.py(521):         if n_iter % self.verbose_interval == 0:
0.87 base.py(249):                 if abs(change) < self.tol:
0.87 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.87 base.py(239):                 prev_lower_bound = lower_bound
0.87 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.87 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.87 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.87 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.87 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.87 base.py(505):         with np.errstate(under='ignore'):
0.87 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.87 base.py(508):         return log_prob_norm, log_resp
0.87 base.py(295):         return np.mean(log_prob_norm), log_resp
0.87 base.py(242):                 self._m_step(X, log_resp)
0.87 base.py(243):                 lower_bound = self._compute_lower_bound(
0.87 base.py(244):                     log_resp, log_prob_norm)
0.87 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.88 base.py(239):                 prev_lower_bound = lower_bound
0.88 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.88 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.88 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.88 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.88 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.88 base.py(505):         with np.errstate(under='ignore'):
0.88 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.88 base.py(508):         return log_prob_norm, log_resp
0.88 base.py(295):         return np.mean(log_prob_norm), log_resp
0.88 base.py(242):                 self._m_step(X, log_resp)
0.88 base.py(243):                 lower_bound = self._compute_lower_bound(
0.88 base.py(244):                     log_resp, log_prob_norm)
0.88 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.88 base.py(239):                 prev_lower_bound = lower_bound
0.88 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.88 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.88 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.88 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.88 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.88 base.py(505):         with np.errstate(under='ignore'):
0.88 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.88 base.py(508):         return log_prob_norm, log_resp
0.88 base.py(295):         return np.mean(log_prob_norm), log_resp
0.88 base.py(242):                 self._m_step(X, log_resp)
0.88 base.py(243):                 lower_bound = self._compute_lower_bound(
0.88 base.py(244):                     log_resp, log_prob_norm)
0.88 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.88 base.py(239):                 prev_lower_bound = lower_bound
0.88 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.88 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.88 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.88 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.88 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.88 base.py(505):         with np.errstate(under='ignore'):
0.88 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.88 base.py(508):         return log_prob_norm, log_resp
0.88 base.py(295):         return np.mean(log_prob_norm), log_resp
0.88 base.py(242):                 self._m_step(X, log_resp)
0.88 base.py(243):                 lower_bound = self._compute_lower_bound(
0.88 base.py(244):                     log_resp, log_prob_norm)
0.88 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.88 base.py(239):                 prev_lower_bound = lower_bound
0.88 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.88 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.88 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.88 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.88 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.88 base.py(505):         with np.errstate(under='ignore'):
0.88 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.88 base.py(508):         return log_prob_norm, log_resp
0.88 base.py(295):         return np.mean(log_prob_norm), log_resp
0.88 base.py(242):                 self._m_step(X, log_resp)
0.88 base.py(243):                 lower_bound = self._compute_lower_bound(
0.88 base.py(244):                     log_resp, log_prob_norm)
0.88 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.88 base.py(239):                 prev_lower_bound = lower_bound
0.88 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.88 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.88 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.88 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.88 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.88 base.py(505):         with np.errstate(under='ignore'):
0.88 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.88 base.py(508):         return log_prob_norm, log_resp
0.88 base.py(295):         return np.mean(log_prob_norm), log_resp
0.88 base.py(242):                 self._m_step(X, log_resp)
0.88 base.py(243):                 lower_bound = self._compute_lower_bound(
0.88 base.py(244):                     log_resp, log_prob_norm)
0.88 base.py(246):                 change = lower_bound - prev_lower_bound
0.88 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.88 base.py(521):         if n_iter % self.verbose_interval == 0:
0.88 base.py(249):                 if abs(change) < self.tol:
0.88 base.py(250):                     self.converged_ = True
0.88 base.py(251):                     break
0.88 base.py(253):             self._print_verbose_msg_init_end(lower_bound)
0.88 base.py(532):         if self.verbose == 1:
0.88 base.py(534):         elif self.verbose >= 2:
0.88 base.py(255):             if lower_bound > max_lower_bound:
0.88 base.py(256):                 max_lower_bound = lower_bound
0.88 base.py(257):                 best_params = self._get_parameters()
0.88 base.py(258):                 best_n_iter = n_iter
0.88 base.py(230):         for init in range(n_init):
0.88 base.py(231):             self._print_verbose_msg_init_beg(init)
0.88 base.py(512):         if self.verbose == 1:
0.88 base.py(514):         elif self.verbose >= 2:
0.88 base.py(233):             if do_init:
0.88 base.py(234):                 self._initialize_parameters(X, random_state)
0.88 base.py(141):         n_samples, _ = X.shape
0.88 base.py(143):         if self.init_params == 'kmeans':
0.88 base.py(144):             resp = np.zeros((n_samples, self.n_components))
0.88 base.py(145):             label = cluster.KMeans(n_clusters=self.n_components, n_init=1,
0.88 base.py(146):                                    random_state=random_state).fit(X).labels_
0.89 base.py(147):             resp[np.arange(n_samples), label] = 1
0.89 base.py(155):         self._initialize(X, resp)
0.89 base.py(236):             lower_bound = (-np.infty if do_init else self.lower_bound_)
0.89 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.89 base.py(239):                 prev_lower_bound = lower_bound
0.89 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.89 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.89 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.89 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.89 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.89 base.py(505):         with np.errstate(under='ignore'):
0.89 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.89 base.py(508):         return log_prob_norm, log_resp
0.89 base.py(295):         return np.mean(log_prob_norm), log_resp
0.89 base.py(242):                 self._m_step(X, log_resp)
0.89 base.py(243):                 lower_bound = self._compute_lower_bound(
0.89 base.py(244):                     log_resp, log_prob_norm)
0.89 base.py(246):                 change = lower_bound - prev_lower_bound
0.89 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.89 base.py(521):         if n_iter % self.verbose_interval == 0:
0.89 base.py(249):                 if abs(change) < self.tol:
0.89 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.89 base.py(239):                 prev_lower_bound = lower_bound
0.89 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.89 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.89 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.89 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.89 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.89 base.py(505):         with np.errstate(under='ignore'):
0.89 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.89 base.py(508):         return log_prob_norm, log_resp
0.89 base.py(295):         return np.mean(log_prob_norm), log_resp
0.89 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.90 base.py(243):                 lower_bound = self._compute_lower_bound(
0.90 base.py(244):                     log_resp, log_prob_norm)
0.90 base.py(246):                 change = lower_bound - prev_lower_bound
0.90 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.90 base.py(521):         if n_iter % self.verbose_interval == 0:
0.90 base.py(249):                 if abs(change) < self.tol:
0.90 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.90 base.py(239):                 prev_lower_bound = lower_bound
0.90 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.90 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.90 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.90 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.90 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.90 base.py(505):         with np.errstate(under='ignore'):
0.90 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.90 base.py(508):         return log_prob_norm, log_resp
0.90 base.py(295):         return np.mean(log_prob_norm), log_resp
0.90 base.py(242):                 self._m_step(X, log_resp)
0.91 base.py(243):                 lower_bound = self._compute_lower_bound(
0.91 base.py(244):                     log_resp, log_prob_norm)
0.91 base.py(246):                 change = lower_bound - prev_lower_bound
0.91 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.91 base.py(521):         if n_iter % self.verbose_interval == 0:
0.91 base.py(249):                 if abs(change) < self.tol:
0.91 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.91 base.py(239):                 prev_lower_bound = lower_bound
0.91 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.91 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.91 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.91 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.91 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.91 base.py(505):         with np.errstate(under='ignore'):
0.91 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.91 base.py(508):         return log_prob_norm, log_resp
0.91 base.py(295):         return np.mean(log_prob_norm), log_resp
0.91 base.py(242):                 self._m_step(X, log_resp)
0.91 base.py(243):                 lower_bound = self._compute_lower_bound(
0.91 base.py(244):                     log_resp, log_prob_norm)
0.91 base.py(246):                 change = lower_bound - prev_lower_bound
0.91 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.91 base.py(521):         if n_iter % self.verbose_interval == 0:
0.91 base.py(249):                 if abs(change) < self.tol:
0.91 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.91 base.py(239):                 prev_lower_bound = lower_bound
0.91 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.91 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.91 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.91 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.91 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.91 base.py(505):         with np.errstate(under='ignore'):
0.91 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.91 base.py(508):         return log_prob_norm, log_resp
0.91 base.py(295):         return np.mean(log_prob_norm), log_resp
0.91 base.py(242):                 self._m_step(X, log_resp)
0.91 base.py(243):                 lower_bound = self._compute_lower_bound(
0.91 base.py(244):                     log_resp, log_prob_norm)
0.91 base.py(246):                 change = lower_bound - prev_lower_bound
0.91 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.91 base.py(521):         if n_iter % self.verbose_interval == 0:
0.91 base.py(522):             if self.verbose == 1:
0.91 base.py(524):             elif self.verbose >= 2:
0.91 base.py(249):                 if abs(change) < self.tol:
0.91 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.91 base.py(239):                 prev_lower_bound = lower_bound
0.91 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.91 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.91 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.91 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.91 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.91 base.py(505):         with np.errstate(under='ignore'):
0.91 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.91 base.py(508):         return log_prob_norm, log_resp
0.91 base.py(295):         return np.mean(log_prob_norm), log_resp
0.91 base.py(242):                 self._m_step(X, log_resp)
0.91 base.py(243):                 lower_bound = self._compute_lower_bound(
0.91 base.py(244):                     log_resp, log_prob_norm)
0.91 base.py(246):                 change = lower_bound - prev_lower_bound
0.91 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.91 base.py(521):         if n_iter % self.verbose_interval == 0:
0.91 base.py(249):                 if abs(change) < self.tol:
0.91 base.py(250):                     self.converged_ = True
0.91 base.py(251):                     break
0.91 base.py(253):             self._print_verbose_msg_init_end(lower_bound)
0.91 base.py(532):         if self.verbose == 1:
0.91 base.py(534):         elif self.verbose >= 2:
0.91 base.py(255):             if lower_bound > max_lower_bound:
0.91 base.py(230):         for init in range(n_init):
0.91 base.py(231):             self._print_verbose_msg_init_beg(init)
0.91 base.py(512):         if self.verbose == 1:
0.91 base.py(514):         elif self.verbose >= 2:
0.91 base.py(233):             if do_init:
0.91 base.py(234):                 self._initialize_parameters(X, random_state)
0.91 base.py(141):         n_samples, _ = X.shape
0.91 base.py(143):         if self.init_params == 'kmeans':
0.91 base.py(144):             resp = np.zeros((n_samples, self.n_components))
0.91 base.py(145):             label = cluster.KMeans(n_clusters=self.n_components, n_init=1,
0.91 base.py(146):                                    random_state=random_state).fit(X).labels_
0.92 base.py(147):             resp[np.arange(n_samples), label] = 1
0.92 base.py(155):         self._initialize(X, resp)
0.92 base.py(236):             lower_bound = (-np.infty if do_init else self.lower_bound_)
0.92 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.92 base.py(239):                 prev_lower_bound = lower_bound
0.92 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.92 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.92 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.92 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.92 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.92 base.py(505):         with np.errstate(under='ignore'):
0.92 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.92 base.py(508):         return log_prob_norm, log_resp
0.92 base.py(295):         return np.mean(log_prob_norm), log_resp
0.92 base.py(242):                 self._m_step(X, log_resp)
0.92 base.py(243):                 lower_bound = self._compute_lower_bound(
0.92 base.py(244):                     log_resp, log_prob_norm)
0.92 base.py(246):                 change = lower_bound - prev_lower_bound
0.92 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.92 base.py(521):         if n_iter % self.verbose_interval == 0:
0.92 base.py(249):                 if abs(change) < self.tol:
0.92 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.92 base.py(239):                 prev_lower_bound = lower_bound
0.92 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.92 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.92 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.92 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.92 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.92 base.py(505):         with np.errstate(under='ignore'):
0.92 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.92 base.py(508):         return log_prob_norm, log_resp
0.92 base.py(295):         return np.mean(log_prob_norm), log_resp
0.92 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.93 base.py(243):                 lower_bound = self._compute_lower_bound(
0.93 base.py(244):                     log_resp, log_prob_norm)
0.93 base.py(246):                 change = lower_bound - prev_lower_bound
0.93 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.93 base.py(521):         if n_iter % self.verbose_interval == 0:
0.93 base.py(522):             if self.verbose == 1:
0.93 base.py(524):             elif self.verbose >= 2:
0.93 base.py(249):                 if abs(change) < self.tol:
0.93 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.93 base.py(239):                 prev_lower_bound = lower_bound
0.93 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.93 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.93 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.93 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.93 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.93 base.py(505):         with np.errstate(under='ignore'):
0.93 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.93 base.py(508):         return log_prob_norm, log_resp
0.93 base.py(295):         return np.mean(log_prob_norm), log_resp
0.93 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.94 base.py(505):         with np.errstate(under='ignore'):
0.94 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.94 base.py(508):         return log_prob_norm, log_resp
0.94 base.py(295):         return np.mean(log_prob_norm), log_resp
0.94 base.py(242):                 self._m_step(X, log_resp)
0.94 base.py(243):                 lower_bound = self._compute_lower_bound(
0.94 base.py(244):                     log_resp, log_prob_norm)
0.94 base.py(246):                 change = lower_bound - prev_lower_bound
0.94 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.94 base.py(521):         if n_iter % self.verbose_interval == 0:
0.94 base.py(249):                 if abs(change) < self.tol:
0.94 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.94 base.py(239):                 prev_lower_bound = lower_bound
0.94 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.94 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.94 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.94 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.94 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(522):             if self.verbose == 1:
0.95 base.py(524):             elif self.verbose >= 2:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.95 base.py(243):                 lower_bound = self._compute_lower_bound(
0.95 base.py(244):                     log_resp, log_prob_norm)
0.95 base.py(246):                 change = lower_bound - prev_lower_bound
0.95 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.95 base.py(521):         if n_iter % self.verbose_interval == 0:
0.95 base.py(249):                 if abs(change) < self.tol:
0.95 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.95 base.py(239):                 prev_lower_bound = lower_bound
0.95 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.95 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.95 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.95 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.95 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.95 base.py(505):         with np.errstate(under='ignore'):
0.95 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.95 base.py(508):         return log_prob_norm, log_resp
0.95 base.py(295):         return np.mean(log_prob_norm), log_resp
0.95 base.py(242):                 self._m_step(X, log_resp)
0.96 base.py(243):                 lower_bound = self._compute_lower_bound(
0.96 base.py(244):                     log_resp, log_prob_norm)
0.96 base.py(246):                 change = lower_bound - prev_lower_bound
0.96 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.96 base.py(521):         if n_iter % self.verbose_interval == 0:
0.96 base.py(249):                 if abs(change) < self.tol:
0.96 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.96 base.py(239):                 prev_lower_bound = lower_bound
0.96 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.96 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.96 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.96 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.96 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.96 base.py(505):         with np.errstate(under='ignore'):
0.96 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.96 base.py(508):         return log_prob_norm, log_resp
0.96 base.py(295):         return np.mean(log_prob_norm), log_resp
0.96 base.py(242):                 self._m_step(X, log_resp)
0.96 base.py(243):                 lower_bound = self._compute_lower_bound(
0.96 base.py(244):                     log_resp, log_prob_norm)
0.96 base.py(246):                 change = lower_bound - prev_lower_bound
0.96 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.96 base.py(521):         if n_iter % self.verbose_interval == 0:
0.96 base.py(249):                 if abs(change) < self.tol:
0.96 base.py(250):                     self.converged_ = True
0.96 base.py(251):                     break
0.96 base.py(253):             self._print_verbose_msg_init_end(lower_bound)
0.96 base.py(532):         if self.verbose == 1:
0.96 base.py(534):         elif self.verbose >= 2:
0.96 base.py(255):             if lower_bound > max_lower_bound:
0.96 base.py(256):                 max_lower_bound = lower_bound
0.96 base.py(257):                 best_params = self._get_parameters()
0.96 base.py(258):                 best_n_iter = n_iter
0.96 base.py(230):         for init in range(n_init):
0.96 base.py(231):             self._print_verbose_msg_init_beg(init)
0.96 base.py(512):         if self.verbose == 1:
0.96 base.py(514):         elif self.verbose >= 2:
0.96 base.py(233):             if do_init:
0.96 base.py(234):                 self._initialize_parameters(X, random_state)
0.96 base.py(141):         n_samples, _ = X.shape
0.96 base.py(143):         if self.init_params == 'kmeans':
0.96 base.py(144):             resp = np.zeros((n_samples, self.n_components))
0.96 base.py(145):             label = cluster.KMeans(n_clusters=self.n_components, n_init=1,
0.96 base.py(146):                                    random_state=random_state).fit(X).labels_
0.96 base.py(147):             resp[np.arange(n_samples), label] = 1
0.96 base.py(155):         self._initialize(X, resp)
0.96 base.py(236):             lower_bound = (-np.infty if do_init else self.lower_bound_)
0.96 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.96 base.py(239):                 prev_lower_bound = lower_bound
0.96 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.96 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.96 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.96 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.96 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.96 base.py(505):         with np.errstate(under='ignore'):
0.96 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.96 base.py(508):         return log_prob_norm, log_resp
0.96 base.py(295):         return np.mean(log_prob_norm), log_resp
0.96 base.py(242):                 self._m_step(X, log_resp)
0.96 base.py(243):                 lower_bound = self._compute_lower_bound(
0.96 base.py(244):                     log_resp, log_prob_norm)
0.96 base.py(246):                 change = lower_bound - prev_lower_bound
0.96 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.96 base.py(521):         if n_iter % self.verbose_interval == 0:
0.96 base.py(249):                 if abs(change) < self.tol:
0.96 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.96 base.py(239):                 prev_lower_bound = lower_bound
0.96 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.96 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.96 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.96 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.96 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.96 base.py(505):         with np.errstate(under='ignore'):
0.96 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.96 base.py(508):         return log_prob_norm, log_resp
0.96 base.py(295):         return np.mean(log_prob_norm), log_resp
0.96 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.97 base.py(243):                 lower_bound = self._compute_lower_bound(
0.97 base.py(244):                     log_resp, log_prob_norm)
0.97 base.py(246):                 change = lower_bound - prev_lower_bound
0.97 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.97 base.py(521):         if n_iter % self.verbose_interval == 0:
0.97 base.py(522):             if self.verbose == 1:
0.97 base.py(524):             elif self.verbose >= 2:
0.97 base.py(249):                 if abs(change) < self.tol:
0.97 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.97 base.py(239):                 prev_lower_bound = lower_bound
0.97 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.97 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.97 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.97 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.97 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.97 base.py(505):         with np.errstate(under='ignore'):
0.97 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.97 base.py(508):         return log_prob_norm, log_resp
0.97 base.py(295):         return np.mean(log_prob_norm), log_resp
0.97 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.98 base.py(239):                 prev_lower_bound = lower_bound
0.98 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.98 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.98 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.98 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.98 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.98 base.py(505):         with np.errstate(under='ignore'):
0.98 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.98 base.py(508):         return log_prob_norm, log_resp
0.98 base.py(295):         return np.mean(log_prob_norm), log_resp
0.98 base.py(242):                 self._m_step(X, log_resp)
0.98 base.py(243):                 lower_bound = self._compute_lower_bound(
0.98 base.py(244):                     log_resp, log_prob_norm)
0.98 base.py(246):                 change = lower_bound - prev_lower_bound
0.98 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.98 base.py(521):         if n_iter % self.verbose_interval == 0:
0.98 base.py(249):                 if abs(change) < self.tol:
0.98 base.py(250):                     self.converged_ = True
0.98 base.py(251):                     break
0.98 base.py(253):             self._print_verbose_msg_init_end(lower_bound)
0.98 base.py(532):         if self.verbose == 1:
0.98 base.py(534):         elif self.verbose >= 2:
0.98 base.py(255):             if lower_bound > max_lower_bound:
0.98 base.py(256):                 max_lower_bound = lower_bound
0.98 base.py(257):                 best_params = self._get_parameters()
0.98 base.py(258):                 best_n_iter = n_iter
0.98 base.py(230):         for init in range(n_init):
0.98 base.py(231):             self._print_verbose_msg_init_beg(init)
0.98 base.py(512):         if self.verbose == 1:
0.98 base.py(514):         elif self.verbose >= 2:
0.98 base.py(233):             if do_init:
0.98 base.py(234):                 self._initialize_parameters(X, random_state)
0.98 base.py(141):         n_samples, _ = X.shape
0.98 base.py(143):         if self.init_params == 'kmeans':
0.98 base.py(144):             resp = np.zeros((n_samples, self.n_components))
0.98 base.py(145):             label = cluster.KMeans(n_clusters=self.n_components, n_init=1,
0.98 base.py(146):                                    random_state=random_state).fit(X).labels_
0.99 base.py(147):             resp[np.arange(n_samples), label] = 1
0.99 base.py(155):         self._initialize(X, resp)
0.99 base.py(236):             lower_bound = (-np.infty if do_init else self.lower_bound_)
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
0.99 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
0.99 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
0.99 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
0.99 base.py(505):         with np.errstate(under='ignore'):
0.99 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
0.99 base.py(508):         return log_prob_norm, log_resp
0.99 base.py(295):         return np.mean(log_prob_norm), log_resp
0.99 base.py(242):                 self._m_step(X, log_resp)
0.99 base.py(243):                 lower_bound = self._compute_lower_bound(
0.99 base.py(244):                     log_resp, log_prob_norm)
0.99 base.py(246):                 change = lower_bound - prev_lower_bound
0.99 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
0.99 base.py(521):         if n_iter % self.verbose_interval == 0:
0.99 base.py(249):                 if abs(change) < self.tol:
0.99 base.py(238):             for n_iter in range(1, self.max_iter + 1):
0.99 base.py(239):                 prev_lower_bound = lower_bound
0.99 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
0.99 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
1.00 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
1.00 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
1.00 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
1.00 base.py(505):         with np.errstate(under='ignore'):
1.00 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
1.00 base.py(508):         return log_prob_norm, log_resp
1.00 base.py(295):         return np.mean(log_prob_norm), log_resp
1.00 base.py(242):                 self._m_step(X, log_resp)
1.00 base.py(243):                 lower_bound = self._compute_lower_bound(
1.00 base.py(244):                     log_resp, log_prob_norm)
1.00 base.py(246):                 change = lower_bound - prev_lower_bound
1.00 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
1.00 base.py(521):         if n_iter % self.verbose_interval == 0:
1.00 base.py(249):                 if abs(change) < self.tol:
1.00 base.py(238):             for n_iter in range(1, self.max_iter + 1):
1.00 base.py(239):                 prev_lower_bound = lower_bound
1.00 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
1.00 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
1.00 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
1.00 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
1.00 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
1.00 base.py(505):         with np.errstate(under='ignore'):
1.00 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
1.00 base.py(508):         return log_prob_norm, log_resp
1.00 base.py(295):         return np.mean(log_prob_norm), log_resp
1.00 base.py(242):                 self._m_step(X, log_resp)
1.00 base.py(243):                 lower_bound = self._compute_lower_bound(
1.00 base.py(244):                     log_resp, log_prob_norm)
1.00 base.py(246):                 change = lower_bound - prev_lower_bound
1.00 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
1.00 base.py(521):         if n_iter % self.verbose_interval == 0:
1.00 base.py(249):                 if abs(change) < self.tol:
1.00 base.py(238):             for n_iter in range(1, self.max_iter + 1):
1.00 base.py(239):                 prev_lower_bound = lower_bound
1.00 base.py(241):                 log_prob_norm, log_resp = self._e_step(X)
1.00 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
1.00 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
1.00 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
1.00 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
1.00 base.py(505):         with np.errstate(under='ignore'):
1.00 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
1.00 base.py(508):         return log_prob_norm, log_resp
1.00 base.py(295):         return np.mean(log_prob_norm), log_resp
1.00 base.py(242):                 self._m_step(X, log_resp)
1.00 base.py(243):                 lower_bound = self._compute_lower_bound(
1.00 base.py(244):                     log_resp, log_prob_norm)
1.00 base.py(246):                 change = lower_bound - prev_lower_bound
1.00 base.py(247):                 self._print_verbose_msg_iter_end(n_iter, change)
1.00 base.py(521):         if n_iter % self.verbose_interval == 0:
1.00 base.py(522):             if self.verbose == 1:
1.00 base.py(524):             elif self.verbose >= 2:
1.00 base.py(249):                 if abs(change) < self.tol:
1.00 base.py(250):                     self.converged_ = True
1.00 base.py(251):                     break
1.00 base.py(253):             self._print_verbose_msg_init_end(lower_bound)
1.00 base.py(532):         if self.verbose == 1:
1.00 base.py(534):         elif self.verbose >= 2:
1.00 base.py(255):             if lower_bound > max_lower_bound:
1.00 base.py(230):         for init in range(n_init):
1.00 base.py(263):         _, log_resp = self._e_step(X)
1.00 base.py(294):         log_prob_norm, log_resp = self._estimate_log_prob_resp(X)
1.00 base.py(503):         weighted_log_prob = self._estimate_weighted_log_prob(X)
1.00 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
1.00 base.py(504):         log_prob_norm = logsumexp(weighted_log_prob, axis=1)
1.00 base.py(505):         with np.errstate(under='ignore'):
1.00 base.py(507):             log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]
1.00 base.py(508):         return log_prob_norm, log_resp
1.00 base.py(295):         return np.mean(log_prob_norm), log_resp
1.00 base.py(265):         if not self.converged_:
1.00 base.py(272):         self._set_parameters(best_params)
1.00 base.py(273):         self.n_iter_ = best_n_iter
1.00 base.py(274):         self.lower_bound_ = max_lower_bound
1.00 base.py(276):         return log_resp.argmax(axis=1)
1.00 base.py(372):         self._check_is_fitted()
1.00 base.py(373):         X = _check_X(X, None, self.means_.shape[1])
1.00 base.py(51):     X = check_array(X, dtype=[np.float64, np.float32],
1.00 base.py(52):                     ensure_min_samples=ensure_min_samples)
1.00 base.py(53):     if n_components is not None and X.shape[0] < n_components:
1.00 base.py(57):     if n_features is not None and X.shape[1] != n_features:
1.00 base.py(61):     return X
1.00 base.py(374):         return self._estimate_weighted_log_prob(X).argmax(axis=1)
1.00 base.py(456):         return self._estimate_log_prob(X) + self._estimate_log_weights()
=========================== short test summary info ============================
FAILED sklearn/tests/test_coverup_scikit-learn__scikit-learn-13142.py::test_gaussian_mixture_fit_predict_discrepancy
============================== 1 failed in 0.96s ===============================
+ cat coverage.cover
{"/testbed/sklearn/mixture/base.py": {"7": 1, "8": 1, "9": 1, "11": 1, "13": 1, "14": 1, "15": 1, "16": 1, "17": 1, "18": 1, "21": 1, "38": 1, "64": 2, "32": 0, "33": 0, "34": 0, "35": 0, "51": 2, "52": 2, "53": 2, "54": 0, "56": 0, "57": 2, "58": 0, "60": 0, "61": 2, "71": 1, "85": 1, "121": 1, "131": 1, "157": 1, "169": 1, "194": 1, "278": 1, "297": 1, "311": 1, "315": 1, "319": 1, "323": 1, "342": 1, "358": 1, "376": 1, "396": 1, "445": 1, "458": 1, "468": 1, "484": 1, "510": 1, "519": 1, "530": 1, "74": 1, "75": 1, "76": 1, "77": 1, "78": 1, "79": 1, "80": 1, "81": 1, "82": 1, "83": 1, "92": 1, "93": 0, "95": 0, "97": 1, "98": 0, "100": 0, "102": 1, "103": 0, "105": 0, "107": 1, "108": 0, "110": 0, "112": 1, "113": 0, "116": 0, "119": 1, "129": 0, "141": 5, "143": 5, "144": 5, "145": 5, "146": 5, "147": 5, "148": 0, "149": 0, "150": 0, "152": 0, "153": 0, "155": 5, "167": 0, "191": 0, "192": 0, "217": 1, "218": 1, "221": 1, "222": 1, "224": 1, "225": 1, "227": 1, "229": 1, "230": 6, "231": 5, "233": 5, "234": 5, "236": 5, "238": 82, "239": 82, "241": 82, "242": 82, "243": 82, "244": 82, "246": 82, "247": 82, "249": 82, "250": 5, "251": 5, "253": 5, "255": 5, "256": 3, "257": 3, "258": 3, "263": 1, "265": 1, "266": 0, "270": 0, "272": 1, "273": 1, "274": 1, "276": 1, "294": 83, "295": 83, "309": 0, "313": 0, "317": 0, "321": 0, "337": 0, "338": 0, "340": 0, "356": 0, "372": 1, "373": 1, "374": 1, "391": 0, "392": 0, "393": 0, "394": 0, "413": 0, "415": 0, "416": 0, "417": 0, "418": 0, "420": 0, "421": 0, "422": 0, "424": 0, "425": 0, "426": 0, "427": 0, "428": 0, "429": 0, "430": 0, "431": 0, "432": 0, "433": 0, "435": 0, "436": 0, "437": 0, "438": 0, "440": 0, "441": 0, "443": 0, "456": 84, "466": 0, "482": 0, "503": 83, "504": 83, "505": 83, "507": 83, "508": 83, "512": 5, "513": 0, "514": 5, "515": 0, "516": 0, "517": 0, "521": 82, "522": 6, "523": 0, "524": 6, "525": 0, "526": 0, "527": 0, "528": 0, "532": 5, "533": 0, "534": 5, "535": 0, "536": 0}}
+ git checkout 1c8668b0a021832386470ddf740d834e02c66f69
Note: switching to '1c8668b0a021832386470ddf740d834e02c66f69'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 1c8668b0a0 DOC what's new: Fix class name
+ git apply /root/pre_state.patch
error: unrecognized input
