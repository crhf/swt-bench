+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh
+++ '[' -n '' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh
+++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/gdal ']'
+++ export GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ export GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ '[' '!' -d /opt/miniconda3/envs/testbed/lib/gdalplugins ']'
+++ export CPL_ZIP_ENCODING=UTF-8
+++ CPL_ZIP_ENCODING=UTF-8
+++ '[' -n '5.1.16(1)-release' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo ']'
+++ source /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo
++++ function_exists _get_comp_words_by_ref
++++ declare -f -F _get_comp_words_by_ref
++++ return 1
++++ return 0
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/epsg_csv ']'
+++ '[' -d /opt/miniconda3/envs/testbed/Library/share/epsg_csv ']'
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh
+++ '[' -n '' ']'
+++ _la_log 'Beginning libarrow activation.'
+++ '[' '' = 1 ']'
+++ _la_gdb_prefix=/opt/miniconda3/envs/testbed/share/gdb/auto-load
+++ '[' '!' -w /opt/miniconda3/envs/testbed/share/gdb/auto-load ']'
+++ _la_placeholder=replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX
+++ _la_symlink_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib
+++ _la_orig_install_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
+++ _la_log '          _la_gdb_prefix: /opt/miniconda3/envs/testbed/share/gdb/auto-load'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_placeholder: replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_symlink_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib'
+++ '[' '' = 1 ']'
+++ _la_log '    _la_orig_install_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib'
+++ '[' '' = 1 ']'
+++ _la_log '  content of that folder:'
+++ '[' '' = 1 ']'
++++ ls -al /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
++++ sed 's/^/      /'
+++ _la_log '      total 12
      drwxr-xr-x 2 root root 4096 Aug 25 05:38 .
      drwxr-xr-x 3 root root 4096 Aug 25 05:38 ..
      -rw-r--r-- 1 root root  971 Aug 25 05:38 libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ for _la_target in "$_la_orig_install_dir/"*.py
+++ '[' '!' -e /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ basename /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_symlink=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_log '   _la_target: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ _la_log '  _la_symlink: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ '[' -L /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ readlink /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ '[' /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py = /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
+++ _la_log 'symlink $_la_symlink already exists and points to $_la_target, skipping.'
+++ '[' '' = 1 ']'
+++ continue
+++ _la_log 'Libarrow activation complete.'
+++ '[' '' = 1 ']'
+++ unset _la_gdb_prefix
+++ unset _la_log
+++ unset _la_orig_install_dir
+++ unset _la_placeholder
+++ unset _la_symlink
+++ unset _la_symlink_dir
+++ unset _la_target
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/opt/miniconda3/envs/testbed
+++ for pre in ${rem}
+++ test '' = /opt/miniconda3/envs/testbed
+++ conda_catalog_files=/opt/miniconda3/envs/testbed
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/proj ']'
+++ export PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ '[' -f /opt/miniconda3/envs/testbed/share/proj/copyright_and_licenses.csv ']'
+++ export PROJ_NETWORK=ON
+++ PROJ_NETWORK=ON
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/udunits ']'
+++ export UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+++ UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git diff HEAD 118f4d996e7711c9aced916e6049af9f28d5ec66
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
nothing to commit, working tree clean
+ git show
commit 118f4d996e7711c9aced916e6049af9f28d5ec66
Author: Maximilian Roos <5635139+max-sixty@users.noreply.github.com>
Date:   Fri Jul 19 13:52:42 2019 -0400

    missing 'about' field (#3146)

diff --git a/.github/ISSUE_TEMPLATE/bug_report.md b/.github/ISSUE_TEMPLATE/bug_report.md
index 105a9b02..f24884c6 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.md
+++ b/.github/ISSUE_TEMPLATE/bug_report.md
@@ -1,6 +1,6 @@
 ---
 name: Bug report / Feature request
-about: ''
+about: 'Post a problem or idea'
 title: ''
 labels: ''
 assignees: ''
+ git diff 118f4d996e7711c9aced916e6049af9f28d5ec66
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval '. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/udunits2-deactivate.sh
++++ unset UDUNITS2_XML_PATH
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/proj4-deactivate.sh
++++ unset PROJ_DATA
++++ unset PROJ_NETWORK
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/libxml2_deactivate.sh
++++ test -n ''
++++ unset XML_CATALOG_FILES
++++ unset xml_catalog_files_libxml2
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/geotiff-deactivate.sh
++++ unset GEOTIFF_CSV
++++ '[' -n '' ']'
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/gdal-deactivate.sh
++++ unset GDAL_DATA
++++ '[' -n '' ']'
++++ unset GDAL_DRIVER_PATH
++++ '[' -n '' ']'
++++ unset CPL_ZIP_ENCODING
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmpy-deactivate.sh
++++ unset ESMFMKFILE
++++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
++++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++++ unset _CONDA_SET_ESMFMKFILE
+++ . /opt/miniconda3/envs/testbed/etc/conda/deactivate.d/esmf-deactivate.sh
++++ unset ESMFMKFILE
++++ '[' -n '' ']'
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\''
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh"
. "/opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh"'
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmf-activate.sh
+++ '[' -n '' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/esmpy-activate.sh
+++ '[' -n /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ _CONDA_SET_ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ '[' -f /opt/miniconda3/envs/testbed/lib/esmf.mk ']'
+++ export ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
+++ ESMFMKFILE=/opt/miniconda3/envs/testbed/lib/esmf.mk
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/gdal-activate.sh
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/gdal ']'
+++ export GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ GDAL_DATA=/opt/miniconda3/envs/testbed/share/gdal
+++ export GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ GDAL_DRIVER_PATH=/opt/miniconda3/envs/testbed/lib/gdalplugins
+++ '[' '!' -d /opt/miniconda3/envs/testbed/lib/gdalplugins ']'
+++ export CPL_ZIP_ENCODING=UTF-8
+++ CPL_ZIP_ENCODING=UTF-8
+++ '[' -n '5.1.16(1)-release' ']'
+++ '[' -f /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo ']'
+++ source /opt/miniconda3/envs/testbed/share/bash-completion/completions/gdalinfo
++++ function_exists _get_comp_words_by_ref
++++ declare -f -F _get_comp_words_by_ref
++++ return 1
++++ return 0
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/geotiff-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/epsg_csv ']'
+++ '[' -d /opt/miniconda3/envs/testbed/Library/share/epsg_csv ']'
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libarrow_activate.sh
+++ '[' -n '' ']'
+++ _la_log 'Beginning libarrow activation.'
+++ '[' '' = 1 ']'
+++ _la_gdb_prefix=/opt/miniconda3/envs/testbed/share/gdb/auto-load
+++ '[' '!' -w /opt/miniconda3/envs/testbed/share/gdb/auto-load ']'
+++ _la_placeholder=replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX
+++ _la_symlink_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib
+++ _la_orig_install_dir=/opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
+++ _la_log '          _la_gdb_prefix: /opt/miniconda3/envs/testbed/share/gdb/auto-load'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_placeholder: replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX'
+++ '[' '' = 1 ']'
+++ _la_log '         _la_symlink_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib'
+++ '[' '' = 1 ']'
+++ _la_log '    _la_orig_install_dir: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib'
+++ '[' '' = 1 ']'
+++ _la_log '  content of that folder:'
+++ '[' '' = 1 ']'
++++ ls -al /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib
++++ sed 's/^/      /'
+++ _la_log '      total 12
      drwxr-xr-x 2 root root 4096 Aug 25 05:38 .
      drwxr-xr-x 3 root root 4096 Aug 25 05:38 ..
      -rw-r--r-- 1 root root  971 Aug 25 05:38 libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ for _la_target in "$_la_orig_install_dir/"*.py
+++ '[' '!' -e /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ basename /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_symlink=/opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ _la_log '   _la_target: /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ _la_log '  _la_symlink: /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py'
+++ '[' '' = 1 ']'
+++ '[' -L /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py ']'
++++ readlink /opt/miniconda3/envs/testbed/share/gdb/auto-load//opt/miniconda3/envs/testbed/lib/libarrow.so.2100.0.0-gdb.py
+++ '[' /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py = /opt/miniconda3/envs/testbed/share/gdb/auto-load/replace_this_section_with_absolute_slashed_path_to_CONDA_PREFIX/lib/libarrow.so.2100.0.0-gdb.py ']'
+++ _la_log 'symlink $_la_symlink already exists and points to $_la_target, skipping.'
+++ '[' '' = 1 ']'
+++ continue
+++ _la_log 'Libarrow activation complete.'
+++ '[' '' = 1 ']'
+++ unset _la_gdb_prefix
+++ unset _la_log
+++ unset _la_orig_install_dir
+++ unset _la_placeholder
+++ unset _la_symlink
+++ unset _la_symlink_dir
+++ unset _la_target
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/opt/miniconda3/envs/testbed
+++ for pre in ${rem}
+++ test '' = /opt/miniconda3/envs/testbed
+++ conda_catalog_files=/opt/miniconda3/envs/testbed
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///opt/miniconda3/envs/testbed/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/proj4-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/proj ']'
+++ export PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ PROJ_DATA=/opt/miniconda3/envs/testbed/share/proj
+++ '[' -f /opt/miniconda3/envs/testbed/share/proj/copyright_and_licenses.csv ']'
+++ export PROJ_NETWORK=ON
+++ PROJ_NETWORK=ON
++ . /opt/miniconda3/envs/testbed/etc/conda/activate.d/udunits2-activate.sh
+++ '[' -n '' ']'
+++ '[' -d /opt/miniconda3/envs/testbed/share/udunits ']'
+++ export UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+++ UDUNITS2_XML_PATH=/opt/miniconda3/envs/testbed/share/udunits/udunits2.xml
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -e .
Obtaining file:///testbed
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: numpy>=1.12 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.12.3+21.g118f4d99) (1.23.0)
Requirement already satisfied: pandas>=0.19.2 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.12.3+21.g118f4d99) (1.5.3)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.19.2->xarray==0.12.3+21.g118f4d99) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.19.2->xarray==0.12.3+21.g118f4d99) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.19.2->xarray==0.12.3+21.g118f4d99) (1.16.0)
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.12.3+21.g118f4d99
    Uninstalling xarray-0.12.3+21.g118f4d99:
      Successfully uninstalled xarray-0.12.3+21.g118f4d99
  DEPRECATION: Legacy editable install of xarray==0.12.3+21.g118f4d99 from file:///testbed (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457
  Running setup.py develop for xarray
Successfully installed xarray
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
+ git apply -v -
Checking patch xarray/tests/test_coverup_pydata__xarray-3151.py...
<stdin>:38: new blank line at EOF.
+
Applied patch xarray/tests/test_coverup_pydata__xarray-3151.py cleanly.
warning: 1 line adds whitespace errors.
+ python3 /root/trace.py --timing --trace --count -C coverage.cover --include-pattern '/testbed/(xarray/core/combine\.py)' -m pytest --no-header -rA -p no:cacheprovider xarray/tests/test_coverup_pydata__xarray-3151.py
['--timing', '--trace', '--count', '-C', 'coverage.cover', '--include-pattern', '/testbed/(xarray/core/combine\\.py)']
============================= test session starts ==============================
collected 1 item

xarray/tests/test_coverup_pydata__xarray-3151.py F                       [100%]

=================================== FAILURES ===================================
____________ test_combine_by_coords_non_monotonic_identical_coords _____________

    def test_combine_by_coords_non_monotonic_identical_coords():
        # Setup datasets with non-monotonic identical coordinates
        yCoord = ['a', 'c', 'b']  # Non-monotonic order
        ds1 = xr.Dataset(
            data_vars=dict(
                data=(['x', 'y'], np.random.rand(3, 3))
            ),
            coords=dict(
                x=[1, 2, 3],
                y=yCoord
            )
        )
        ds2 = xr.Dataset(
            data_vars=dict(
                data=(['x', 'y'], np.random.rand(4, 3))
            ),
            coords=dict(
                x=[4, 5, 6, 7],
                y=yCoord
            )
        )
    
        # Attempt to combine datasets and expect no error
        try:
>           xr.combine_by_coords((ds1, ds2))

xarray/tests/test_coverup_pydata__xarray-3151.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

datasets = (<xarray.Dataset>
Dimensions:  (x: 3, y: 3)
Coordinates:
  * x        (x) int64 1 2 3
  * y        (y) <U1 'a' 'c' 'b'...  (y) <U1 'a' 'c' 'b'
Data variables:
    data     (x, y) float64 0.3622 0.8561 0.9111 0.449 ... 0.8036 0.6143 0.05962)
compat = 'no_conflicts', data_vars = 'all', coords = 'different'
fill_value = <NA>

    def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',
                          coords='different', fill_value=dtypes.NA):
        """
        Attempt to auto-magically combine the given datasets into one by using
        dimension coordinates.
    
        This method attempts to combine a group of datasets along any number of
        dimensions into a single entity by inspecting coords and metadata and using
        a combination of concat and merge.
    
        Will attempt to order the datasets such that the values in their dimension
        coordinates are monotonic along all dimensions. If it cannot determine the
        order in which to concatenate the datasets, it will raise a ValueError.
        Non-coordinate dimensions will be ignored, as will any coordinate
        dimensions which do not vary between each dataset.
    
        Aligns coordinates, but different variables on datasets can cause it
        to fail under some scenarios. In complex cases, you may need to clean up
        your data and use concat/merge explicitly (also see `manual_combine`).
    
        Works well if, for example, you have N years of data and M data variables,
        and each combination of a distinct time period and set of data variables is
        saved as its own dataset. Also useful for if you have a simulation which is
        parallelized in multiple dimensions, but has global coordinates saved in
        each file specifying the positions of points within the global domain.
    
        Parameters
        ----------
        datasets : sequence of xarray.Dataset
            Dataset objects to combine.
        compat : {'identical', 'equals', 'broadcast_equals',
                  'no_conflicts'}, optional
            String indicating how to compare variables of the same name for
            potential conflicts:
    
            - 'broadcast_equals': all values must be equal when variables are
              broadcast against each other to ensure common dimensions.
            - 'equals': all values and dimensions must be the same.
            - 'identical': all values, dimensions and attributes must be the
              same.
            - 'no_conflicts': only values which are not null in both datasets
              must be equal. The returned dataset then contains the combination
              of all non-null values.
        data_vars : {'minimal', 'different', 'all' or list of str}, optional
            Details are in the documentation of concat
        coords : {'minimal', 'different', 'all' or list of str}, optional
            Details are in the documentation of concat
        fill_value : scalar, optional
            Value to use for newly missing values
    
        Returns
        -------
        combined : xarray.Dataset
    
        See also
        --------
        concat
        merge
        combine_nested
    
        Examples
        --------
    
        Combining two datasets using their common dimension coordinates. Notice
        they are concatenated based on the values in their dimension coordinates,
        not on their position in the list passed to `combine_by_coords`.
    
        >>> x1
        <xarray.Dataset>
        Dimensions:         (x: 3)
        Coords:
          * position        (x) int64   0 1 2
        Data variables:
            temperature     (x) float64 11.04 23.57 20.77 ...
    
        >>> x2
        <xarray.Dataset>
        Dimensions:         (x: 3)
        Coords:
          * position        (x) int64   3 4 5
        Data variables:
            temperature     (x) float64 6.97 8.13 7.42 ...
    
        >>> combined = xr.combine_by_coords([x2, x1])
        <xarray.Dataset>
        Dimensions:         (x: 6)
        Coords:
          * position        (x) int64   0 1 2 3 4 5
        Data variables:
            temperature     (x) float64 11.04 23.57 20.77 ...
        """
    
        # Group by data vars
        sorted_datasets = sorted(datasets, key=vars_as_keys)
        grouped_by_vars = itertools.groupby(sorted_datasets, key=vars_as_keys)
    
        # Perform the multidimensional combine on each group of data variables
        # before merging back together
        concatenated_grouped_by_data_vars = []
        for vars, datasets_with_same_vars in grouped_by_vars:
            combined_ids, concat_dims = _infer_concat_order_from_coords(
                list(datasets_with_same_vars))
    
            _check_shape_tile_ids(combined_ids)
    
            # Concatenate along all of concat_dims one by one to create single ds
            concatenated = _combine_nd(combined_ids, concat_dims=concat_dims,
                                       data_vars=data_vars, coords=coords,
                                       fill_value=fill_value)
    
            # Check the overall coordinates are monotonically increasing
            for dim in concatenated.dims:
                if dim in concatenated:
                    indexes = concatenated.indexes.get(dim)
                    if not (indexes.is_monotonic_increasing
                            or indexes.is_monotonic_decreasing):
>                       raise ValueError("Resulting object does not have monotonic"
                                         " global indexes along dimension {}"
                                         .format(dim))
E                       ValueError: Resulting object does not have monotonic global indexes along dimension y

xarray/core/combine.py:509: ValueError

During handling of the above exception, another exception occurred:

    def test_combine_by_coords_non_monotonic_identical_coords():
        # Setup datasets with non-monotonic identical coordinates
        yCoord = ['a', 'c', 'b']  # Non-monotonic order
        ds1 = xr.Dataset(
            data_vars=dict(
                data=(['x', 'y'], np.random.rand(3, 3))
            ),
            coords=dict(
                x=[1, 2, 3],
                y=yCoord
            )
        )
        ds2 = xr.Dataset(
            data_vars=dict(
                data=(['x', 'y'], np.random.rand(4, 3))
            ),
            coords=dict(
                x=[4, 5, 6, 7],
                y=yCoord
            )
        )
    
        # Attempt to combine datasets and expect no error
        try:
            xr.combine_by_coords((ds1, ds2))
        except ValueError as e:
>           pytest.fail(f"combine_by_coords raised ValueError unexpectedly: {e}")
E           Failed: combine_by_coords raised ValueError unexpectedly: Resulting object does not have monotonic global indexes along dimension y

xarray/tests/test_coverup_pydata__xarray-3151.py:31: Failed
----------------------------- Captured stdout call -----------------------------
3.26 combine.py(486):     sorted_datasets = sorted(datasets, key=vars_as_keys)
3.26 combine.py(390):     return tuple(sorted(ds))
3.26 combine.py(390):     return tuple(sorted(ds))
3.26 combine.py(487):     grouped_by_vars = itertools.groupby(sorted_datasets, key=vars_as_keys)
3.26 combine.py(491):     concatenated_grouped_by_data_vars = []
3.26 combine.py(492):     for vars, datasets_with_same_vars in grouped_by_vars:
3.26 combine.py(390):     return tuple(sorted(ds))
3.26 combine.py(493):         combined_ids, concat_dims = _infer_concat_order_from_coords(
3.26 combine.py(494):             list(datasets_with_same_vars))
3.26 combine.py(390):     return tuple(sorted(ds))
3.26 combine.py(493):         combined_ids, concat_dims = _infer_concat_order_from_coords(
3.26 combine.py(53):     concat_dims = []
3.26 combine.py(54):     tile_ids = [() for ds in datasets]
3.26 combine.py(54):     tile_ids = [() for ds in datasets]
3.26 combine.py(54):     tile_ids = [() for ds in datasets]
3.26 combine.py(54):     tile_ids = [() for ds in datasets]
3.26 combine.py(57):     ds0 = datasets[0]
3.26 combine.py(58):     for dim in ds0.dims:
3.26 combine.py(61):         if dim in ds0:
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(71):             if not all(index.equals(indexes[0]) for index in indexes[1:]):
3.26 combine.py(71):             if not all(index.equals(indexes[0]) for index in indexes[1:]):
3.26 combine.py(74):                 concat_dims.append(dim)
3.26 combine.py(76):                 if all(index.is_monotonic_increasing for index in indexes):
3.26 combine.py(76):                 if all(index.is_monotonic_increasing for index in indexes):
3.26 combine.py(76):                 if all(index.is_monotonic_increasing for index in indexes):
3.26 combine.py(76):                 if all(index.is_monotonic_increasing for index in indexes):
3.26 combine.py(77):                     ascending = True
3.26 combine.py(88):                 if any(index.size == 0 for index in indexes):
3.26 combine.py(88):                 if any(index.size == 0 for index in indexes):
3.26 combine.py(88):                 if any(index.size == 0 for index in indexes):
3.26 combine.py(88):                 if any(index.size == 0 for index in indexes):
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(91):                                         for index in indexes])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(91):                                         for index in indexes])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(91):                                         for index in indexes])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(90):                 first_items = pd.Index([index.take([0])
3.26 combine.py(97):                 series = first_items.to_series()
3.26 combine.py(98):                 rank = series.rank(method='dense', ascending=ascending)
3.26 combine.py(99):                 order = rank.astype(int).values - 1
3.26 combine.py(103):                 tile_ids = [tile_id + (position,) for tile_id, position
3.26 combine.py(104):                             in zip(tile_ids, order)]
3.26 combine.py(103):                 tile_ids = [tile_id + (position,) for tile_id, position
3.26 combine.py(103):                 tile_ids = [tile_id + (position,) for tile_id, position
3.26 combine.py(103):                 tile_ids = [tile_id + (position,) for tile_id, position
3.26 combine.py(103):                 tile_ids = [tile_id + (position,) for tile_id, position
3.26 combine.py(58):     for dim in ds0.dims:
3.26 combine.py(61):         if dim in ds0:
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(64):             indexes = [ds.indexes.get(dim) for ds in datasets]
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(65):             if any(index is None for index in indexes):
3.26 combine.py(71):             if not all(index.equals(indexes[0]) for index in indexes[1:]):
3.26 combine.py(71):             if not all(index.equals(indexes[0]) for index in indexes[1:]):
3.26 combine.py(71):             if not all(index.equals(indexes[0]) for index in indexes[1:]):
3.26 combine.py(58):     for dim in ds0.dims:
3.26 combine.py(106):     if len(datasets) > 1 and not concat_dims:
3.26 combine.py(110):     combined_ids = OrderedDict(zip(tile_ids, datasets))
3.26 combine.py(112):     return combined_ids, concat_dims
3.26 combine.py(496):         _check_shape_tile_ids(combined_ids)
3.26 combine.py(116):     tile_ids = combined_tile_ids.keys()
3.26 combine.py(120):     nesting_depths = [len(tile_id) for tile_id in tile_ids]
3.26 combine.py(120):     nesting_depths = [len(tile_id) for tile_id in tile_ids]
3.26 combine.py(120):     nesting_depths = [len(tile_id) for tile_id in tile_ids]
3.26 combine.py(120):     nesting_depths = [len(tile_id) for tile_id in tile_ids]
3.26 combine.py(121):     if not nesting_depths:
3.26 combine.py(123):     if not set(nesting_depths) == {nesting_depths[0]}:
3.26 combine.py(128):     for dim in range(nesting_depths[0]):
3.26 combine.py(129):         indices_along_dim = [tile_id[dim] for tile_id in tile_ids]
3.26 combine.py(129):         indices_along_dim = [tile_id[dim] for tile_id in tile_ids]
3.26 combine.py(129):         indices_along_dim = [tile_id[dim] for tile_id in tile_ids]
3.26 combine.py(129):         indices_along_dim = [tile_id[dim] for tile_id in tile_ids]
3.26 combine.py(130):         occurrences = Counter(indices_along_dim)
3.26 combine.py(131):         if len(set(occurrences.values())) != 1:
3.26 combine.py(128):     for dim in range(nesting_depths[0]):
3.26 combine.py(499):         concatenated = _combine_nd(combined_ids, concat_dims=concat_dims,
3.26 combine.py(500):                                    data_vars=data_vars, coords=coords,
3.26 combine.py(501):                                    fill_value=fill_value)
3.26 combine.py(499):         concatenated = _combine_nd(combined_ids, concat_dims=concat_dims,
3.26 combine.py(163):     example_tile_id = next(iter(combined_ids.keys()))
3.26 combine.py(165):     n_dims = len(example_tile_id)
3.26 combine.py(166):     if len(concat_dims) != n_dims:
3.26 combine.py(174):     for concat_dim in concat_dims:
3.26 combine.py(175):         combined_ids = _combine_all_along_first_dim(combined_ids,
3.26 combine.py(176):                                                     dim=concat_dim,
3.26 combine.py(177):                                                     data_vars=data_vars,
3.26 combine.py(178):                                                     coords=coords,
3.26 combine.py(179):                                                     compat=compat,
3.26 combine.py(180):                                                     fill_value=fill_value)
3.26 combine.py(175):         combined_ids = _combine_all_along_first_dim(combined_ids,
3.26 combine.py(191):     combined_ids = OrderedDict(sorted(combined_ids.items(), key=_new_tile_id))
3.26 combine.py(231):     tile_id, ds = single_id_ds_pair
3.26 combine.py(232):     return tile_id[1:]
3.26 combine.py(231):     tile_id, ds = single_id_ds_pair
3.26 combine.py(232):     return tile_id[1:]
3.26 combine.py(192):     grouped = itertools.groupby(combined_ids.items(), key=_new_tile_id)
3.26 combine.py(195):     new_combined_ids = {}
3.26 combine.py(196):     for new_id, group in grouped:
3.26 combine.py(231):     tile_id, ds = single_id_ds_pair
3.26 combine.py(232):     return tile_id[1:]
3.26 combine.py(197):         combined_ids = OrderedDict(sorted(group))
3.26 combine.py(231):     tile_id, ds = single_id_ds_pair
3.26 combine.py(232):     return tile_id[1:]
3.26 combine.py(198):         datasets = combined_ids.values()
3.26 combine.py(199):         new_combined_ids[new_id] = _combine_1d(datasets, dim, compat,
3.26 combine.py(200):                                                data_vars, coords, fill_value)
3.26 combine.py(199):         new_combined_ids[new_id] = _combine_1d(datasets, dim, compat,
3.26 combine.py(211):     if concat_dim is not None:
3.26 combine.py(212):         try:
3.26 combine.py(213):             combined = concat(datasets, dim=concat_dim, data_vars=data_vars,
3.26 combine.py(214):                               coords=coords, fill_value=fill_value)
3.26 combine.py(213):             combined = concat(datasets, dim=concat_dim, data_vars=data_vars,
3.27 combine.py(227):     return combined
3.27 combine.py(196):     for new_id, group in grouped:
3.27 combine.py(201):     return new_combined_ids
3.27 combine.py(174):     for concat_dim in concat_dims:
3.27 combine.py(181):     (combined_ds,) = combined_ids.values()
3.27 combine.py(182):     return combined_ds
3.27 combine.py(504):         for dim in concatenated.dims:
3.27 combine.py(505):             if dim in concatenated:
3.27 combine.py(506):                 indexes = concatenated.indexes.get(dim)
3.27 combine.py(507):                 if not (indexes.is_monotonic_increasing
3.27 combine.py(504):         for dim in concatenated.dims:
3.27 combine.py(505):             if dim in concatenated:
3.27 combine.py(506):                 indexes = concatenated.indexes.get(dim)
3.27 combine.py(507):                 if not (indexes.is_monotonic_increasing
3.27 combine.py(508):                         or indexes.is_monotonic_decreasing):
3.27 combine.py(507):                 if not (indexes.is_monotonic_increasing
3.27 combine.py(509):                     raise ValueError("Resulting object does not have monotonic"
3.27 combine.py(511):                                      .format(dim))
3.27 combine.py(509):                     raise ValueError("Resulting object does not have monotonic"
=============================== warnings summary ===============================
xarray/core/dask_array_ops.py:11
xarray/core/dask_array_ops.py:11
  /testbed/xarray/core/dask_array_ops.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask.__version__) <= LooseVersion('0.18.2'):

xarray/core/npcompat.py:135
xarray/core/npcompat.py:135
  /testbed/xarray/core/npcompat.py:135: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(np.__version__) >= LooseVersion('1.13'):

xarray/core/dask_array_compat.py:43
xarray/core/dask_array_compat.py:43
  /testbed/xarray/core/dask_array_compat.py:43: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) > LooseVersion('0.19.2'):

xarray/plot/utils.py:17
xarray/plot/utils.py:17
  /testbed/xarray/plot/utils.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(nc_time_axis.__version__) < LooseVersion('1.2.0'):

xarray/plot/plot.py:243
  /testbed/xarray/plot/plot.py:243: SyntaxWarning: "is" with a literal. Did you mean "=="?
    if args is ():

xarray/core/pdcompat.py:46
  /testbed/xarray/core/pdcompat.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) < '0.25.0':

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

xarray/tests/__init__.py:57: 15 warnings
  /testbed/xarray/tests/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    return version.LooseVersion(vstring)

xarray/tests/test_coverup_pydata__xarray-3151.py: 28 warnings
  /testbed/xarray/core/formatting.py:147: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    elif isinstance(x, (float, np.float)):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED xarray/tests/test_coverup_pydata__xarray-3151.py::test_combine_by_coords_non_monotonic_identical_coords
======================== 1 failed, 55 warnings in 4.44s ========================
+ cat coverage.cover
{"/testbed/xarray/core/combine.py": {"1": 1, "2": 1, "3": 1, "4": 1, "6": 1, "8": 1, "9": 1, "10": 1, "11": 1, "12": 1, "15": 1, "20": 1, "51": 1, "115": 1, "137": 2, "138": 1, "139": 1, "186": 1, "185": 1, "204": 2, "205": 1, "230": 1, "236": 1, "235": 1, "261": 2, "262": 1, "389": 1, "393": 2, "394": 1, "522": 1, "525": 2, "526": 1, "527": 1, "636": 1, "658": 1, "671": 2, "672": 1, "673": 1, "674": 1, "691": 2, "692": 1, "16": 0, "17": 0, "42": 0, "43": 0, "44": 0, "45": 0, "46": 0, "48": 0, "53": 1, "54": 4, "57": 1, "58": 3, "61": 2, "64": 8, "65": 8, "66": 0, "71": 5, "74": 1, "76": 4, "77": 1, "78": 0, "79": 0, "81": 0, "84": 0, "88": 4, "89": 0, "90": 7, "91": 3, "97": 1, "98": 1, "99": 1, "103": 5, "104": 1, "106": 1, "107": 0, "110": 1, "112": 1, "116": 1, "120": 4, "121": 1, "122": 0, "123": 1, "124": 0, "128": 2, "129": 4, "130": 1, "131": 1, "132": 0, "134": 0, "163": 1, "165": 1, "166": 1, "167": 0, "169": 0, "174": 2, "175": 2, "176": 1, "177": 1, "178": 1, "179": 1, "180": 1, "181": 1, "182": 1, "191": 1, "192": 1, "195": 1, "196": 2, "197": 1, "198": 1, "199": 2, "200": 1, "201": 1, "211": 1, "212": 1, "213": 2, "214": 1, "227": 1, "215": 0, "216": 0, "217": 0, "223": 0, "225": 0, "231": 4, "232": 4, "238": 0, "239": 0, "243": 0, "246": 0, "249": 0, "252": 0, "255": 0, "256": 0, "257": 0, "258": 0, "380": 0, "381": 0, "384": 0, "385": 0, "386": 0, "390": 4, "486": 1, "487": 1, "491": 1, "492": 1, "493": 2, "494": 1, "496": 1, "499": 2, "500": 1, "501": 1, "504": 2, "505": 2, "506": 2, "507": 3, "508": 1, "509": 2, "511": 1, "512": 0, "514": 0, "515": 0, "586": 0, "587": 0, "590": 0, "592": 0, "593": 0, "594": 0, "596": 0, "602": 0, "603": 0, "612": 0, "618": 0, "619": 0, "620": 0, "627": 0, "629": 0, "631": 0, "632": 0, "633": 0, "643": 0, "644": 0, "648": 0, "649": 0, "650": 0, "651": 0, "652": 0, "655": 0, "665": 0, "666": 0, "668": 0, "675": 0, "676": 0, "678": 0, "679": 0, "681": 0, "684": 0, "686": 0, "687": 0, "688": 0, "682": 0, "683": 0, "693": 0, "695": 0, "697": 0, "698": 0, "699": 0, "700": 0, "701": 0, "702": 0, "703": 0, "704": 0, "705": 0, "707": 0, "708": 0, "709": 0, "710": 0, "711": 0, "714": 0, "715": 0, "716": 0, "706": 0}}
+ git checkout 118f4d996e7711c9aced916e6049af9f28d5ec66
Note: switching to '118f4d996e7711c9aced916e6049af9f28d5ec66'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 118f4d99 missing 'about' field (#3146)
+ git apply /root/pre_state.patch
error: unrecognized input
